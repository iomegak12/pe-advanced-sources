{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424054b5",
   "metadata": {},
   "source": [
    "# LAB 4: LANGCHAIN RAG SYSTEMS - COMPLETE GUIDE\n",
    "\n",
    "**Course:** Advanced Prompt Engineering Training  \n",
    "**Session:** Session 3 - RAG & Advanced Retrieval (Day 2)  \n",
    "**Duration:** 150 minutes (2.5 hours)  \n",
    "**Type:** LangChain-Based RAG Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06e22e",
   "metadata": {},
   "source": [
    "## LAB OVERVIEW\n",
    "\n",
    "This comprehensive lab teaches you to build **production-grade RAG (Retrieval-Augmented Generation) systems using LangChain**. You'll progress through five interconnected modules:\n",
    "\n",
    "1. **Document Loading & Chunking** - LangChain text splitters and document loaders\n",
    "2. **Embeddings & Search** - OpenAIEmbeddings and similarity search\n",
    "3. **Vector Store** - LangChain Chroma integration\n",
    "4. **Complete RAG Pipeline** - LCEL-based RAG chains\n",
    "5. **Advanced Patterns** - MultiQuery, Contextual Compression, Re-ranking\n",
    "\n",
    "**Scenario:** You're building an AI-powered knowledge base for a bank's internal documentation - policies, procedures, compliance guidelines, and product information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4dfe29",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb80464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 4: LangChain RAG Systems\n",
    "# Advanced Prompt Engineering Training - Session 3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# LangChain core\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# LangChain OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# LangChain text splitters\n",
    "from langchain_classic.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "\n",
    "# LangChain vector stores\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# LangChain retrievers\n",
    "from langchain_classic.retrievers import (\n",
    "    MultiQueryRetriever,\n",
    "    ContextualCompressionRetriever\n",
    ")\n",
    "from langchain_classic.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(\"✓ LangChain RAG components ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5a4ce",
   "metadata": {},
   "source": [
    "### Step 2: Configure LangChain Models and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "GPT4_MODEL = os.environ.get(\"MODEL_NAME\", \"gpt-4o\")\n",
    "GPT35_MODEL = os.environ.get(\"FAST_MODEL_NAME\", \"gpt-3.5-turbo\")\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# Initialize LangChain models\n",
    "llm_gpt4 = ChatOpenAI(\n",
    "    model=GPT4_MODEL,\n",
    "    temperature=0,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "llm_gpt35 = ChatOpenAI(\n",
    "    model=GPT35_MODEL,\n",
    "    temperature=0,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "print(f\"✓ LLM models configured: {GPT4_MODEL}, {GPT35_MODEL}\")\n",
    "print(f\"✓ Embeddings model: {EMBEDDING_MODEL}\")\n",
    "print(f\"✓ LangChain RAG stack ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b3abb",
   "metadata": {},
   "source": [
    "### Step 3: Load Sample Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17de5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample bank knowledge base documents\n",
    "BANK_KNOWLEDGE_BASE = {\n",
    "    \"hr_policies\": \"\"\"\n",
    "HUMAN RESOURCES POLICIES - CONSOLIDATED HANDBOOK\n",
    "\n",
    "Section 1: Paid Time Off (PTO) Policy\n",
    "\n",
    "Employees are entitled to paid time off for rest and personal needs. Our PTO policy is designed to promote work-life balance while ensuring business continuity.\n",
    "\n",
    "PTO Accrual:\n",
    "- Full-time employees accrue 20 days (160 hours) of PTO annually\n",
    "- PTO accrual begins after successful completion of 90-day probationary period\n",
    "- PTO accrues at a rate of 1.67 days per month\n",
    "- Part-time employees accrue PTO on a pro-rated basis\n",
    "- Maximum PTO bank: 30 days (240 hours); excess is forfeited\n",
    "\n",
    "Usage Guidelines:\n",
    "- PTO requests must be submitted at least 2 weeks in advance for periods longer than 3 days\n",
    "- Manager approval required for all PTO requests\n",
    "- Holiday periods (Thanksgiving, Christmas, New Year) require 30-day advance notice\n",
    "- Unused PTO does not roll over to the following year\n",
    "- PTO cannot be cashed out except upon termination\n",
    "\n",
    "Section 2: Health Insurance Coverage\n",
    "\n",
    "We offer comprehensive health insurance plans to eligible employees and their dependents.\n",
    "\n",
    "Eligibility:\n",
    "- Full-time employees (30+ hours/week) are eligible\n",
    "- Coverage begins on the first day of the month following 30 days of employment\n",
    "- Eligible dependents include spouse and children under 26\n",
    "\n",
    "Plan Options:\n",
    "- PPO Plan: $250 deductible, 80/20 coinsurance, $3,000 out-of-pocket max\n",
    "- HMO Plan: $100 deductible, 90/10 coinsurance, $2,000 out-of-pocket max\n",
    "- HSA-eligible HDHP: $1,500 deductible, 100% after deductible, $4,000 max\n",
    "\n",
    "Section 3: Remote Work Policy\n",
    "\n",
    "Our hybrid work model allows flexibility while maintaining collaboration and culture.\n",
    "\n",
    "Eligibility:\n",
    "- Employees must complete 6 months of employment before becoming eligible\n",
    "- Manager approval required\n",
    "- Position must be suitable for remote work\n",
    "- Performance must meet or exceed expectations\n",
    "\n",
    "Requirements:\n",
    "- Employees must work from primary residence within the United States\n",
    "- Dedicated workspace with reliable internet (minimum 25 Mbps)\n",
    "- Available during core hours (10 AM - 3 PM local time)\n",
    "- Attend all required in-person meetings and events\n",
    "\"\"\",\n",
    "    \n",
    "    \"loan_products\": \"\"\"\n",
    "LOAN PRODUCTS GUIDE - CONSUMER LENDING\n",
    "\n",
    "Product 1: Personal Loans\n",
    "\n",
    "Personal loans provide flexible funding for debt consolidation, home improvements, major purchases, or other personal needs.\n",
    "\n",
    "Loan Amounts: $5,000 to $50,000\n",
    "Terms: 12, 24, 36, 48, or 60 months\n",
    "Interest Rates: 7.99% - 18.99% APR (based on creditworthiness)\n",
    "\n",
    "Eligibility Requirements:\n",
    "- Minimum credit score: 650\n",
    "- Minimum annual income: $35,000\n",
    "- Debt-to-income ratio: Maximum 43%\n",
    "- Employment: Minimum 2 years current job or 3 years in same field\n",
    "- U.S. citizen or permanent resident\n",
    "\n",
    "Fees:\n",
    "- Origination fee: 1-5% of loan amount\n",
    "- Late payment fee: $35 or 5% of payment (whichever is greater)\n",
    "- Returned payment fee: $35\n",
    "- No prepayment penalty\n",
    "\n",
    "Product 2: Home Mortgage Loans\n",
    "\n",
    "We offer competitive mortgage products for home purchase and refinancing.\n",
    "\n",
    "Conventional Mortgages:\n",
    "- Loan amounts up to $726,200 (conforming limits)\n",
    "- Down payment: Minimum 5% (20% to avoid PMI)\n",
    "- Terms: 15, 20, or 30 years\n",
    "- Interest rates: 6.50% - 8.25% (based on credit, LTV, term)\n",
    "\n",
    "Qualification Guidelines:\n",
    "- Credit score: Minimum 620 (conventional), 580 (FHA)\n",
    "- DTI ratio: Maximum 43% (some exceptions to 50%)\n",
    "- Employment verification: 2 years history\n",
    "- Down payment must be from acceptable sources\n",
    "- Property must appraise at or above purchase price\n",
    "\n",
    "Product 3: Auto Loans\n",
    "\n",
    "Competitive financing for new and used vehicle purchases.\n",
    "\n",
    "New Vehicle Loans:\n",
    "- Loan amounts: $5,000 to $100,000\n",
    "- Terms: 24, 36, 48, 60, or 72 months\n",
    "- Rates: 4.99% - 9.99% APR\n",
    "- Maximum LTV: 125%\n",
    "\n",
    "Used Vehicle Loans:\n",
    "- Vehicle age: Up to 8 years old\n",
    "- Mileage: Maximum 100,000 miles\n",
    "- Terms: 24, 36, 48, or 60 months\n",
    "- Rates: 5.99% - 11.99% APR\n",
    "\"\"\",\n",
    "\n",
    "    \"compliance_guidelines\": \"\"\"\n",
    "COMPLIANCE AND REGULATORY GUIDELINES\n",
    "\n",
    "Anti-Money Laundering (AML) Requirements\n",
    "\n",
    "Our AML program ensures compliance with the Bank Secrecy Act and USA PATRIOT Act.\n",
    "\n",
    "Customer Due Diligence (CDD):\n",
    "- All new customers must be verified using government-issued ID\n",
    "- Collect: Full legal name, date of birth, physical address, SSN/TIN\n",
    "- Document type and ID number must be recorded\n",
    "- Verification must occur before account opening\n",
    "\n",
    "Transaction Monitoring:\n",
    "- All transactions over $10,000 must be reported (CTR)\n",
    "- Structured transactions must be identified and reported (SAR)\n",
    "- Wire transfers require additional screening\n",
    "- Daily monitoring of all accounts for unusual patterns\n",
    "\n",
    "Suspicious Activity Reporting (SAR):\n",
    "- File within 30 days of detecting suspicious activity\n",
    "- Threshold: $5,000 for most violations\n",
    "- Customer must not be notified of SAR filing\n",
    "- Maintain SAR confidentiality\n",
    "\n",
    "Know Your Customer (KYC) Program\n",
    "\n",
    "Ongoing customer monitoring to assess risk and detect changes.\n",
    "\n",
    "Risk Categories:\n",
    "- Low Risk: Employed individuals, small balances, low transaction volume\n",
    "- Medium Risk: Self-employed, moderate balances, regular transactions\n",
    "- High Risk: Cash businesses, high balances, frequent international activity\n",
    "\n",
    "Review Frequency:\n",
    "- Low risk: Annual review\n",
    "- Medium risk: Semi-annual review\n",
    "- High risk: Quarterly review or continuous monitoring\n",
    "\n",
    "Privacy and Data Protection\n",
    "\n",
    "Safeguarding customer information is paramount.\n",
    "\n",
    "Gramm-Leach-Bliley Act (GLBA) Compliance:\n",
    "- Provide privacy notice at account opening\n",
    "- Annual privacy notice required\n",
    "- Opt-out must be offered for information sharing\n",
    "\n",
    "Information Security:\n",
    "- Encrypt all sensitive data at rest and in transit\n",
    "- Access controls: minimum necessary principle\n",
    "- Password requirements: 12+ characters, MFA enabled\n",
    "- Log and monitor all access to customer data\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Convert to LangChain Document objects\n",
    "documents = []\n",
    "for doc_type, content in BANK_KNOWLEDGE_BASE.items():\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            \"type\": doc_type,\n",
    "            \"source\": \"bank_knowledge_base\",\n",
    "            \"created_at\": datetime.now().isoformat()\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"✓ Loaded {len(documents)} knowledge base documents\")\n",
    "print(f\"✓ Total characters: {sum(len(doc.page_content) for doc in documents):,}\")\n",
    "print(f\"✓ Document types: {[doc.metadata['type'] for doc in documents]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70ea35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 1: DOCUMENT CHUNKING WITH LANGCHAIN (Lab 4.1)\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Use LangChain text splitters for optimal chunking\n",
    "\n",
    "### Theory: LangChain Text Splitters\n",
    "\n",
    "LangChain provides multiple text splitter strategies:\n",
    "\n",
    "- **RecursiveCharacterTextSplitter**: Smartest - splits on natural boundaries\n",
    "- **CharacterTextSplitter**: Simple - splits on single separator\n",
    "- **TokenTextSplitter**: Precise - splits by token count\n",
    "\n",
    "**Advantages:**\n",
    "- Pre-built, tested implementations\n",
    "- Consistent with LangChain ecosystem\n",
    "- Metadata preservation\n",
    "- Easy to configure and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5baf4",
   "metadata": {},
   "source": [
    "### Challenge 1.1: RecursiveCharacterTextSplitter (10 minutes)\n",
    "\n",
    "**Strategy:** Split on multiple separators in order (paragraph → sentence → word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RecursiveCharacterTextSplitter\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RECURSIVE CHARACTER TEXT SPLITTER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Split all documents\n",
    "recursive_chunks = recursive_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total chunks created: {len(recursive_chunks)}\")\n",
    "print(f\"\\nChunks per document:\")\n",
    "for doc_type in BANK_KNOWLEDGE_BASE.keys():\n",
    "    doc_chunks = [c for c in recursive_chunks if c.metadata['type'] == doc_type]\n",
    "    print(f\"  {doc_type}: {len(doc_chunks)} chunks\")\n",
    "\n",
    "# Show sample chunk\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Metadata: {recursive_chunks[0].metadata}\")\n",
    "print(f\"Content ({len(recursive_chunks[0].page_content)} chars):\")\n",
    "print(recursive_chunks[0].page_content[:300] + \"...\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9477096",
   "metadata": {},
   "source": [
    "### Challenge 1.2: CharacterTextSplitter (5 minutes)\n",
    "\n",
    "**Strategy:** Split on a single separator (e.g., double newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CharacterTextSplitter\n",
    "character_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=80,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHARACTER TEXT SPLITTER (Paragraph-based)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Split documents\n",
    "character_chunks = character_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total chunks created: {len(character_chunks)}\")\n",
    "print(f\"Avg chunk size: {np.mean([len(c.page_content) for c in character_chunks]):.0f} chars\")\n",
    "print(f\"Min size: {min(len(c.page_content) for c in character_chunks)}\")\n",
    "print(f\"Max size: {max(len(c.page_content) for c in character_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6c71f",
   "metadata": {},
   "source": [
    "### Challenge 1.3: TokenTextSplitter (5 minutes)\n",
    "\n",
    "**Strategy:** Split by exact token count for precise control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TokenTextSplitter\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOKEN TEXT SPLITTER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Split documents\n",
    "token_chunks = token_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total chunks created: {len(token_chunks)}\")\n",
    "print(f\"Target tokens per chunk: 300\")\n",
    "print(f\"\\nNote: TokenTextSplitter ensures precise token counts for API limits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f2f2c",
   "metadata": {},
   "source": [
    "### Challenge 1.4: Chunking Strategy Comparison (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ba4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all strategies\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHUNKING STRATEGY COMPARISON\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "comparison_data = [\n",
    "    {\n",
    "        \"Strategy\": \"RecursiveCharacter\",\n",
    "        \"Chunks\": len(recursive_chunks),\n",
    "        \"Avg Size\": int(np.mean([len(c.page_content) for c in recursive_chunks])),\n",
    "        \"Min\": min(len(c.page_content) for c in recursive_chunks),\n",
    "        \"Max\": max(len(c.page_content) for c in recursive_chunks),\n",
    "        \"Std Dev\": int(np.std([len(c.page_content) for c in recursive_chunks]))\n",
    "    },\n",
    "    {\n",
    "        \"Strategy\": \"Character\",\n",
    "        \"Chunks\": len(character_chunks),\n",
    "        \"Avg Size\": int(np.mean([len(c.page_content) for c in character_chunks])),\n",
    "        \"Min\": min(len(c.page_content) for c in character_chunks),\n",
    "        \"Max\": max(len(c.page_content) for c in character_chunks),\n",
    "        \"Std Dev\": int(np.std([len(c.page_content) for c in character_chunks]))\n",
    "    },\n",
    "    {\n",
    "        \"Strategy\": \"Token\",\n",
    "        \"Chunks\": len(token_chunks),\n",
    "        \"Avg Size\": int(np.mean([len(c.page_content) for c in token_chunks])),\n",
    "        \"Min\": min(len(c.page_content) for c in token_chunks),\n",
    "        \"Max\": max(len(c.page_content) for c in token_chunks),\n",
    "        \"Std Dev\": int(np.std([len(c.page_content) for c in token_chunks]))\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n✓ RecursiveCharacterTextSplitter: Best for general use (smart boundaries)\")\n",
    "print(f\"✓ CharacterTextSplitter: Good for paragraph-based content\")\n",
    "print(f\"✓ TokenTextSplitter: Best for precise token control\")\n",
    "\n",
    "# Use recursive chunks for rest of lab\n",
    "chunks_to_use = recursive_chunks\n",
    "print(f\"\\n✓ Using RecursiveCharacterTextSplitter chunks ({len(chunks_to_use)} chunks) for the rest of the lab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc06b1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 2: EMBEDDINGS WITH LANGCHAIN (Lab 4.2)\n",
    "\n",
    "**Duration:** 20 minutes  \n",
    "**Objective:** Use OpenAIEmbeddings for vector representations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86241dc",
   "metadata": {},
   "source": [
    "### Challenge 2.1: Generate Embeddings (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GENERATING EMBEDDINGS WITH OPENAIEMBEDDINGS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test single embedding\n",
    "test_text = \"What is the PTO policy for employees?\"\n",
    "test_embedding = embeddings.embed_query(test_text)\n",
    "\n",
    "print(f\"Test query: '{test_text}'\")\n",
    "print(f\"Embedding dimensions: {len(test_embedding)}\")\n",
    "print(f\"First 10 values: {test_embedding[:10]}\")\n",
    "print(f\"\\n✓ OpenAIEmbeddings working correctly\")\n",
    "\n",
    "# Generate embeddings for sample chunks\n",
    "print(f\"\\nGenerating embeddings for {len(chunks_to_use[:5])} sample chunks...\")\n",
    "sample_texts = [chunk.page_content for chunk in chunks_to_use[:5]]\n",
    "sample_embeddings = embeddings.embed_documents(sample_texts)\n",
    "\n",
    "print(f\"✓ Generated {len(sample_embeddings)} embeddings\")\n",
    "print(f\"✓ Each embedding has {len(sample_embeddings[0])} dimensions\")\n",
    "\n",
    "print(f\"\\nNote: Full embedding generation happens during vector store creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589aaed5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 3: VECTOR STORE WITH LANGCHAIN CHROMA (Lab 4.3)\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Build scalable vector store using LangChain's Chroma integration\n",
    "\n",
    "### Theory: LangChain Chroma Integration\n",
    "\n",
    "**Advantages of LangChain's Chroma:**\n",
    "- Automatic embedding generation\n",
    "- Metadata filtering support\n",
    "- Similarity and MMR search\n",
    "- Easy persistence and loading\n",
    "- Seamless integration with retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14e57e",
   "metadata": {},
   "source": [
    "### Challenge 3.1: Create Vector Store (15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CREATING VECTOR STORE WITH LANGCHAIN CHROMA\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create Chroma vector store from documents\n",
    "print(f\"Creating vector store with {len(chunks_to_use)} chunks...\")\n",
    "print(f\"This includes automatic embedding generation...\\n\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks_to_use,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"bank_knowledge_base\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Vector store created successfully\")\n",
    "print(f\"✓ Collection: bank_knowledge_base\")\n",
    "print(f\"✓ Total chunks indexed: {len(chunks_to_use)}\")\n",
    "print(f\"✓ Embedding model: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc9cdd",
   "metadata": {},
   "source": [
    "### Challenge 3.2: Similarity Search (15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMILARITY SEARCH TESTING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "test_queries = [\n",
    "    \"How many vacation days do employees get?\",\n",
    "    \"What is the minimum credit score for a personal loan?\",\n",
    "    \"What are the AML requirements for new customers?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Similarity search\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i}:\")\n",
    "        print(f\"Source: {doc.metadata['type']}\")\n",
    "        print(f\"Content preview: {doc.page_content[:200]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae19f18",
   "metadata": {},
   "source": [
    "### Challenge 3.3: Similarity Search with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b726011",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMILARITY SEARCH WITH RELEVANCE SCORES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "query = \"What documentation is needed to open an account?\"\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Similarity search with scores\n",
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=5)\n",
    "\n",
    "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "    print(f\"\\nResult {i} (distance: {score:.3f}):\")\n",
    "    print(f\"Source: {doc.metadata['type']}\")\n",
    "    print(f\"Content: {doc.page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Note: Lower distance = more similar (L2 distance)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c1440",
   "metadata": {},
   "source": [
    "### Challenge 3.4: Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ac089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METADATA FILTERING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "query = \"What are the requirements?\"\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"Filter: Only 'compliance_guidelines' documents\\n\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Search with metadata filter\n",
    "filtered_results = vectorstore.similarity_search(\n",
    "    query,\n",
    "    k=3,\n",
    "    filter={\"type\": \"compliance_guidelines\"}\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(filtered_results, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"Source: {doc.metadata['type']}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bba70b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 4: RAG PIPELINE WITH LCEL (Lab 4.4)\n",
    "\n",
    "**Duration:** 40 minutes  \n",
    "**Objective:** Build end-to-end RAG using LangChain Expression Language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a75ea",
   "metadata": {},
   "source": [
    "### Challenge 4.1: Basic RAG Chain (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever from vector store\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# Create RAG prompt template\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant answering questions about bank policies and products. Use ONLY the provided context to answer questions. If the context doesn't contain enough information, say so.\"),\n",
    "    (\"user\", \"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a concise, accurate answer based ONLY on the context above. Cite which source (HR policies, loan products, or compliance) you used.\"\"\")\n",
    "])\n",
    "\n",
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format documents for context\"\"\"\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        formatted.append(f\"[Source {i} - {doc.metadata['type']}]\\n{doc.page_content}\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# Build RAG chain using LCEL\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm_gpt4\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✓ RAG chain created with LCEL\")\n",
    "print(\"✓ Components: Retriever → Format → Prompt → LLM → Parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG chain\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING BASIC RAG CHAIN\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "test_questions = [\n",
    "    \"How many vacation days do full-time employees get per year?\",\n",
    "    \"What is the minimum credit score needed for a personal loan?\",\n",
    "    \"What are the customer verification requirements for new accounts?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    answer = rag_chain.invoke(question)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nAnswer:\\n{answer}\")\n",
    "    print(f\"\\nTime: {elapsed:.2f}s\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8520156",
   "metadata": {},
   "source": [
    "### Challenge 4.2: RAG with Source Citations (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced RAG with source tracking\n",
    "def format_docs_with_sources(docs):\n",
    "    \"\"\"Format documents and track sources\"\"\"\n",
    "    formatted = []\n",
    "    sources = []\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        formatted.append(f\"[Source {i}]\\n{doc.page_content}\")\n",
    "        sources.append({\n",
    "            \"number\": i,\n",
    "            \"type\": doc.metadata['type'],\n",
    "            \"preview\": doc.page_content[:100]\n",
    "        })\n",
    "    \n",
    "    return {\"context\": \"\\n\\n\".join(formatted), \"sources\": sources}\n",
    "\n",
    "# RAG chain that returns both answer and sources\n",
    "rag_with_sources_chain = (\n",
    "    {\"retrieved_docs\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"formatted\": format_docs_with_sources(x[\"retrieved_docs\"]),\n",
    "        \"question\": x[\"question\"]\n",
    "    })\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"answer\": (rag_prompt | llm_gpt4 | StrOutputParser()).invoke({\n",
    "            \"context\": x[\"formatted\"][\"context\"],\n",
    "            \"question\": x[\"question\"]\n",
    "        }),\n",
    "        \"sources\": x[\"formatted\"][\"sources\"]\n",
    "    })\n",
    ")\n",
    "\n",
    "print(\"✓ Enhanced RAG chain with source tracking created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test enhanced RAG\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING RAG WITH SOURCE CITATIONS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "question = \"Can employees work from home and what are the requirements?\"\n",
    "print(f\"Question: {question}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "result = rag_with_sources_chain.invoke(question)\n",
    "\n",
    "print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "\n",
    "print(f\"\\n\\nSources Used:\")\n",
    "for source in result['sources']:\n",
    "    print(f\"  [{source['number']}] {source['type']}: {source['preview']}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608a1cb",
   "metadata": {},
   "source": [
    "### Challenge 4.3: Streaming RAG (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test streaming\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STREAMING RAG DEMO\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "question = \"What fees are associated with personal loans?\"\n",
    "print(f\"Question: {question}\")\n",
    "print(\"\\nAnswer (streaming):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Stream the answer\n",
    "for chunk in rag_chain.stream(question):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"\\n✓ Streaming complete\")\n",
    "print(\"\\nNote: In production web apps, each chunk is sent to client immediately\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7f761",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 5: ADVANCED RAG PATTERNS (Lab 4.5)\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Implement production-grade RAG enhancements with LangChain\n",
    "\n",
    "### Advanced Retrievers:\n",
    "\n",
    "- **MultiQueryRetriever**: Generates multiple queries to improve recall\n",
    "- **ContextualCompressionRetriever**: Filters retrieved content for precision\n",
    "- **EnsembleRetriever**: Combines multiple retrieval methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3924991",
   "metadata": {},
   "source": [
    "### Challenge 5.1: MultiQueryRetriever (15 minutes)\n",
    "\n",
    "**Objective:** Improve recall by generating multiple query variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MultiQueryRetriever\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=retriever,\n",
    "    llm=llm_gpt35  # Use faster model for query generation\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTIQUERY RETRIEVER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(\"✓ MultiQueryRetriever created\")\n",
    "print(\"✓ Automatically generates multiple query variations\")\n",
    "print(\"✓ Combines results for better recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MultiQueryRetriever\n",
    "import logging\n",
    "\n",
    "# Enable logging to see generated queries\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING MULTIQUERY RETRIEVER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "question = \"What do I need to qualify for a home loan?\"\n",
    "print(f\"Original question: {question}\\n\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Generated query variations and retrieval:\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "# This will print the generated query variations\n",
    "multiquery_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "print(f\"\\n✓ Retrieved {len(multiquery_docs)} unique documents\")\n",
    "print(f\"\\nTop 3 results:\")\n",
    "for i, doc in enumerate(multiquery_docs[:3], 1):\n",
    "    print(f\"\\n[{i}] Source: {doc.metadata['type']}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531cda76",
   "metadata": {},
   "source": [
    "### Challenge 5.2: Contextual Compression (15 minutes)\n",
    "\n",
    "**Objective:** Filter retrieved content to only relevant parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f02be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compressor\n",
    "compressor = LLMChainExtractor.from_llm(llm_gpt35)\n",
    "\n",
    "# Create ContextualCompressionRetriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONTEXTUAL COMPRESSION RETRIEVER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(\"✓ ContextualCompressionRetriever created\")\n",
    "print(\"✓ Uses LLM to extract only relevant parts\")\n",
    "print(\"✓ Improves precision and reduces token usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare regular vs compressed retrieval\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARING REGULAR VS COMPRESSED RETRIEVAL\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "question = \"What is the origination fee for personal loans?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "# Regular retrieval\n",
    "print(\"Regular Retrieval:\")\n",
    "print(\"-\" * 80)\n",
    "regular_docs = retriever.invoke(question)\n",
    "print(f\"Documents: {len(regular_docs)}\")\n",
    "print(f\"Total characters: {sum(len(doc.page_content) for doc in regular_docs)}\")\n",
    "print(f\"Sample: {regular_docs[0].page_content[:300]}...\\n\")\n",
    "\n",
    "# Compressed retrieval\n",
    "print(\"Compressed Retrieval:\")\n",
    "print(\"-\" * 80)\n",
    "compressed_docs = compression_retriever.invoke(question)\n",
    "print(f\"Documents: {len(compressed_docs)}\")\n",
    "print(f\"Total characters: {sum(len(doc.page_content) for doc in compressed_docs)}\")\n",
    "print(f\"Sample: {compressed_docs[0].page_content}\\n\")\n",
    "\n",
    "# Calculate compression ratio\n",
    "original_chars = sum(len(doc.page_content) for doc in regular_docs)\n",
    "compressed_chars = sum(len(doc.page_content) for doc in compressed_docs)\n",
    "compression_ratio = compressed_chars / original_chars if original_chars > 0 else 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Compression ratio: {compression_ratio:.1%}\")\n",
    "print(f\"Token savings: ~{(1-compression_ratio)*100:.0f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc9704",
   "metadata": {},
   "source": [
    "### Challenge 5.3: Enhanced RAG with Advanced Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32fe697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build enhanced RAG with compression\n",
    "enhanced_rag_chain = (\n",
    "    {\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm_gpt4\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENHANCED RAG WITH COMPRESSION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "question = \"What documentation is required for a mortgage application?\"\n",
    "print(f\"Question: {question}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare basic vs enhanced\n",
    "print(\"\\nBasic RAG Answer:\")\n",
    "print(\"-\" * 80)\n",
    "basic_answer = rag_chain.invoke(question)\n",
    "print(basic_answer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nEnhanced RAG Answer (with compression):\")\n",
    "print(\"-\" * 80)\n",
    "enhanced_answer = enhanced_rag_chain.invoke(question)\n",
    "print(enhanced_answer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ Enhanced RAG provides more focused, relevant answers\")\n",
    "print(\"✓ Uses fewer tokens while maintaining accuracy\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbc4e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CAPSTONE: PRODUCTION RAG SYSTEM\n",
    "\n",
    "**Objective:** Complete production system with all LangChain best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionRAGSystem:\n",
    "    \"\"\"\n",
    "    Production-grade RAG system using LangChain:\n",
    "    - Multiple retrieval strategies\n",
    "    - Contextual compression\n",
    "    - Source tracking\n",
    "    - Metrics and logging\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore: Chroma, llm: ChatOpenAI):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        \n",
    "        # Create retrievers\n",
    "        self.base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "        \n",
    "        # MultiQuery for better recall\n",
    "        self.multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "            retriever=self.base_retriever,\n",
    "            llm=llm_gpt35\n",
    "        )\n",
    "        \n",
    "        # Compression for better precision\n",
    "        compressor = LLMChainExtractor.from_llm(llm_gpt35)\n",
    "        self.compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=self.base_retriever\n",
    "        )\n",
    "        \n",
    "        # Build RAG chain\n",
    "        self.rag_chain = self._build_rag_chain()\n",
    "        \n",
    "        self.query_history = []\n",
    "    \n",
    "    def _build_rag_chain(self):\n",
    "        \"\"\"Build LCEL RAG chain\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a helpful assistant for bank employees. Answer questions accurately using the provided context. Always cite your sources.\"),\n",
    "            (\"user\", \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nProvide a clear, concise answer with source citations.\")\n",
    "        ])\n",
    "        \n",
    "        return (\n",
    "            {\"context\": self.compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    def query(self, question: str, use_multiquery: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Query the RAG system\n",
    "        \n",
    "        Args:\n",
    "            question: User question\n",
    "            use_multiquery: Whether to use MultiQueryRetriever\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with answer, sources, and metrics\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Select retriever\n",
    "        retriever = self.multiquery_retriever if use_multiquery else self.compression_retriever\n",
    "        \n",
    "        # Retrieve documents\n",
    "        docs = retriever.invoke(question)\n",
    "        retrieval_time = time.time() - start_time\n",
    "        \n",
    "        # Generate answer\n",
    "        gen_start = time.time()\n",
    "        answer = self.rag_chain.invoke(question)\n",
    "        generation_time = time.time() - gen_start\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Track query\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"sources\": [\n",
    "                {\"type\": doc.metadata['type'], \"preview\": doc.page_content[:100]}\n",
    "                for doc in docs\n",
    "            ],\n",
    "            \"metrics\": {\n",
    "                \"retrieval_time\": retrieval_time,\n",
    "                \"generation_time\": generation_time,\n",
    "                \"total_time\": total_time,\n",
    "                \"docs_retrieved\": len(docs),\n",
    "                \"retriever_type\": \"multiquery\" if use_multiquery else \"compression\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.query_history.append(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get system statistics\"\"\"\n",
    "        if not self.query_history:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            \"total_queries\": len(self.query_history),\n",
    "            \"avg_retrieval_time\": np.mean([q[\"metrics\"][\"retrieval_time\"] for q in self.query_history]),\n",
    "            \"avg_generation_time\": np.mean([q[\"metrics\"][\"generation_time\"] for q in self.query_history]),\n",
    "            \"avg_total_time\": np.mean([q[\"metrics\"][\"total_time\"] for q in self.query_history]),\n",
    "            \"avg_docs_retrieved\": np.mean([q[\"metrics\"][\"docs_retrieved\"] for q in self.query_history])\n",
    "        }\n",
    "\n",
    "print(\"✓ ProductionRAGSystem class created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f73228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize production system\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRODUCTION RAG SYSTEM TESTING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "prod_rag = ProductionRAGSystem(vectorstore, llm_gpt4)\n",
    "\n",
    "# Test queries\n",
    "test_questions = [\n",
    "    \"How many PTO days do full-time employees get?\",\n",
    "    \"What credit score is needed for a personal loan?\",\n",
    "    \"What are the AML customer verification requirements?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    result = prod_rag.query(question)\n",
    "    \n",
    "    print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "    \n",
    "    print(f\"\\nMetrics:\")\n",
    "    for key, value in result['metrics'].items():\n",
    "        if 'time' in key:\n",
    "            print(f\"  {key}: {value:.3f}s\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nSources: {len(result['sources'])} documents\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Display statistics\n",
    "stats = prod_rag.get_statistics()\n",
    "print(\"SYSTEM STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "for key, value in stats.items():\n",
    "    if 'time' in key:\n",
    "        print(f\"{key}: {value:.3f}s\")\n",
    "    else:\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
