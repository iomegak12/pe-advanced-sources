{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00579d5",
   "metadata": {},
   "source": [
    "# LAB 3: PROMPT FLOW & ORCHESTRATION - COMPLETE GUIDE\n",
    "\n",
    "**Course:** Advanced Prompt Engineering Training  \n",
    "**Session:** Session 3 - RAG & Advanced Retrieval (Day 2)  \n",
    "**Duration:** 120 minutes (2 hours)  \n",
    "**Type:** Comprehensive Orchestration Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e82d4",
   "metadata": {},
   "source": [
    "## LAB OVERVIEW\n",
    "\n",
    "This comprehensive lab teaches you to build **production-grade orchestrated AI workflows**. You'll progress through four interconnected modules:\n",
    "\n",
    "1. **Sequential Chains** - Linear multi-step workflows\n",
    "2. **Parallel Processing** - Concurrent execution for speed\n",
    "3. **Conditional Workflows** - Dynamic routing based on data\n",
    "4. **Production Orchestration** - Error handling, monitoring, deployment\n",
    "\n",
    "**Scenario:** You're building an AI-powered loan processing system for a bank. Starting with simple sequential workflows, you'll evolve to a production-ready system handling thousands of applications daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b922d1",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 3: Prompt Flow & Orchestration\n",
    "# Advanced Prompt Engineering Training - Session 3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional, Any, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from enum import Enum\n",
    "import traceback\n",
    "\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92339b",
   "metadata": {},
   "source": [
    "### Step 2: Configure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c9e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Model configurations\n",
    "GPT4 = os.environ.get(\"MODEL_NAME\", \"gpt-4o\")\n",
    "GPT35 = os.environ.get(\"FAST_MODEL_NAME\", \"gpt-3.5-turbo\")\n",
    "\n",
    "# Default settings\n",
    "DEFAULT_TEMPERATURE = 0\n",
    "DEFAULT_MAX_TOKENS = 2000\n",
    "\n",
    "print(f\"✓ OpenAI client configured\")\n",
    "print(f\"✓ Primary model: {GPT4}\")\n",
    "print(f\"✓ Fast model: {GPT35}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a554e",
   "metadata": {},
   "source": [
    "### Step 3: Create Core Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a902a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LLMResponse:\n",
    "    \"\"\"Standard response format for all LLM calls\"\"\"\n",
    "    content: str\n",
    "    model: str\n",
    "    tokens: int\n",
    "    latency: float\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            \"content\": self.content,\n",
    "            \"model\": self.model,\n",
    "            \"tokens\": self.tokens,\n",
    "            \"latency\": self.latency,\n",
    "            \"timestamp\": self.timestamp\n",
    "        }\n",
    "\n",
    "def call_llm(\n",
    "    prompt: str,\n",
    "    system_prompt: str = \"You are a helpful AI assistant.\",\n",
    "    model: str = GPT4,\n",
    "    temperature: float = DEFAULT_TEMPERATURE,\n",
    "    max_tokens: int = DEFAULT_MAX_TOKENS\n",
    ") -> LLMResponse:\n",
    "    \"\"\"\n",
    "    Unified LLM calling function with metrics tracking\n",
    "    \n",
    "    Args:\n",
    "        prompt: User prompt\n",
    "        system_prompt: System instructions\n",
    "        model: Model to use (GPT4 or GPT35)\n",
    "        temperature: Sampling temperature\n",
    "        max_tokens: Maximum response tokens\n",
    "    \n",
    "    Returns:\n",
    "        LLMResponse with content and metadata\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        \n",
    "        latency = time.time() - start_time\n",
    "        \n",
    "        return LLMResponse(\n",
    "            content=response.choices[0].message.content,\n",
    "            model=model,\n",
    "            tokens=response.usage.total_tokens,\n",
    "            latency=latency\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        latency = time.time() - start_time\n",
    "        return LLMResponse(\n",
    "            content=f\"Error: {str(e)}\",\n",
    "            model=model,\n",
    "            tokens=0,\n",
    "            latency=latency\n",
    "        )\n",
    "\n",
    "def print_response(response: LLMResponse, title: str = \"Response\"):\n",
    "    \"\"\"Pretty print LLM response with metrics\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Model: {response.model}\")\n",
    "    print(f\"Latency: {response.latency:.2f}s\")\n",
    "    print(f\"Tokens: {response.tokens}\")\n",
    "    print(f\"\\nContent:\\n{response.content}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Test the setup\n",
    "test_response = call_llm(\"Say 'Setup complete!' if you receive this.\", model=GPT35)\n",
    "print_response(test_response, \"Setup Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd43456",
   "metadata": {},
   "source": [
    "### Step 4: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample loan application data for the lab\n",
    "SAMPLE_LOAN_APPLICATION = \"\"\"\n",
    "LOAN APPLICATION #LA-2024-5821\n",
    "\n",
    "Applicant Information:\n",
    "- Name: Sarah Johnson\n",
    "- Age: 34\n",
    "- Employment: Senior Software Engineer at TechCorp\n",
    "- Annual Income: $145,000\n",
    "- Employment Duration: 6 years\n",
    "- Credit Score: 750\n",
    "\n",
    "Loan Details:\n",
    "- Loan Type: Home Mortgage\n",
    "- Loan Amount: $485,000\n",
    "- Property Value: $620,000\n",
    "- Down Payment: $135,000 (22%)\n",
    "- Loan Term: 30 years\n",
    "\n",
    "Financial Information:\n",
    "- Monthly Gross Income: $12,083\n",
    "- Existing Debts: \n",
    "  * Car Loan: $425/month (12 months remaining)\n",
    "  * Student Loan: $280/month (24 months remaining)\n",
    "  * Credit Card: $150/month average\n",
    "- Total Monthly Debt: $855\n",
    "\n",
    "Property Information:\n",
    "- Property Address: 245 Oak Street, San Francisco, CA\n",
    "- Property Type: Single-family home\n",
    "- Year Built: 2018\n",
    "- Square Footage: 2,100 sq ft\n",
    "- Condition: Excellent\n",
    "\n",
    "Supporting Documents:\n",
    "- 2 years tax returns: Provided\n",
    "- 3 months pay stubs: Provided\n",
    "- Bank statements: Provided\n",
    "- Employment verification: Verified\n",
    "- Property appraisal: $620,000\n",
    "\"\"\"\n",
    "\n",
    "# Additional test applications for later exercises\n",
    "SMALL_LOAN_APP = \"\"\"\n",
    "LOAN APPLICATION #LA-2024-5822\n",
    "Applicant: Mike Chen\n",
    "Loan Type: Personal Loan\n",
    "Amount: $15,000\n",
    "Income: $65,000\n",
    "Credit Score: 720\n",
    "Employment: 3 years\n",
    "\"\"\"\n",
    "\n",
    "LARGE_LOAN_APP = \"\"\"\n",
    "LOAN APPLICATION #LA-2024-5823\n",
    "Applicant: Jennifer Martinez\n",
    "Loan Type: Commercial Real Estate\n",
    "Amount: $2,500,000\n",
    "Business Revenue: $8,000,000/year\n",
    "Credit Score: 780\n",
    "Business Age: 12 years\n",
    "Collateral: Commercial property valued at $3,200,000\n",
    "\"\"\"\n",
    "\n",
    "print(\"✓ Sample data loaded\")\n",
    "print(f\"✓ Main application: {SAMPLE_LOAN_APPLICATION.split()[3]}\")\n",
    "print(f\"✓ Test applications: 2 additional scenarios ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d877dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 1: SEQUENTIAL CHAINS (Lab 3.1)\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Build linear multi-step workflows where each step depends on the previous\n",
    "\n",
    "### Theory: Sequential Chain Pattern\n",
    "\n",
    "**Concept:** Output of Step N becomes input to Step N+1\n",
    "\n",
    "```\n",
    "Input → [Step 1] → Result1 → [Step 2] → Result2 → [Step 3] → Final Output\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Steps have clear dependencies\n",
    "- Linear workflow makes sense\n",
    "- Need to inspect intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66dec3",
   "metadata": {},
   "source": [
    "### Challenge 1.1: Basic Sequential Chain (10 minutes)\n",
    "\n",
    "**Scenario:** Process a loan application through 3 steps:\n",
    "1. Extract key information\n",
    "2. Calculate financial ratios\n",
    "3. Generate summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract Information\n",
    "def step1_extract_info(application: str) -> LLMResponse:\n",
    "    \"\"\"Extract key applicant and loan information\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Extract the following information from this loan application and return as JSON:\n",
    "    \n",
    "    Required fields:\n",
    "    - applicant_name\n",
    "    - loan_amount (number only)\n",
    "    - annual_income (number only)\n",
    "    - credit_score (number only)\n",
    "    - monthly_debt (total monthly debt payments, number only)\n",
    "    - loan_type\n",
    "    - property_value (if applicable, number only)\n",
    "    - down_payment (if applicable, number only)\n",
    "    \n",
    "    Loan Application:\n",
    "    {application}\n",
    "    \n",
    "    Return ONLY valid JSON, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"You are a data extraction specialist. Always return valid JSON.\"\n",
    "    \n",
    "    return call_llm(prompt, system_prompt, model=GPT35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate Financial Ratios\n",
    "def step2_calculate_ratios(extracted_data: str) -> LLMResponse:\n",
    "    \"\"\"Calculate financial ratios from extracted data\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Given this extracted loan application data, calculate these financial metrics:\n",
    "    \n",
    "    Extracted Data:\n",
    "    {extracted_data}\n",
    "    \n",
    "    Calculate:\n",
    "    1. DTI (Debt-to-Income Ratio): (monthly_debt / monthly_income) × 100\n",
    "       - monthly_income = annual_income / 12\n",
    "       - Express as percentage\n",
    "    \n",
    "    2. LTV (Loan-to-Value Ratio): (loan_amount / property_value) × 100\n",
    "       - If property_value exists\n",
    "       - Express as percentage\n",
    "    \n",
    "    3. Estimated Monthly Payment: Rough estimate for 30-year mortgage at 7% interest\n",
    "       - Use formula: P = L[c(1 + c)^n]/[(1 + c)^n - 1]\n",
    "       - Where L = loan amount, c = monthly interest rate, n = number of payments\n",
    "    \n",
    "    Return as JSON with:\n",
    "    {{\n",
    "        \"dti_ratio\": <percentage>,\n",
    "        \"dti_assessment\": \"<Good/Fair/Poor based on: <28% = Good, 28-36% = Fair, >36% = Poor>\",\n",
    "        \"ltv_ratio\": <percentage or null>,\n",
    "        \"ltv_assessment\": \"<Good/Fair/Poor based on: <80% = Good, 80-90% = Fair, >90% = Poor>\",\n",
    "        \"estimated_monthly_payment\": <amount>,\n",
    "        \"affordability_check\": \"<Can afford based on 28% housing ratio rule>\"\n",
    "    }}\n",
    "    \n",
    "    Return ONLY valid JSON.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"You are a financial analyst. Always return valid JSON with accurate calculations.\"\n",
    "    \n",
    "    return call_llm(prompt, system_prompt, model=GPT35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9465b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate Executive Summary\n",
    "def step3_generate_summary(extracted_data: str, ratios: str) -> LLMResponse:\n",
    "    \"\"\"Generate executive summary with recommendation\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Create an executive summary for this loan application.\n",
    "    \n",
    "    Applicant Data:\n",
    "    {extracted_data}\n",
    "    \n",
    "    Financial Analysis:\n",
    "    {ratios}\n",
    "    \n",
    "    Write a concise executive summary (3-4 paragraphs) covering:\n",
    "    \n",
    "    1. Applicant Overview\n",
    "       - Name, income, credit score\n",
    "       - Employment stability\n",
    "    \n",
    "    2. Financial Strength\n",
    "       - DTI and LTV ratios\n",
    "       - Overall financial health\n",
    "    \n",
    "    3. Risk Assessment\n",
    "       - Key strengths\n",
    "       - Potential concerns\n",
    "    \n",
    "    4. Recommendation\n",
    "       - APPROVE: Strong application, low risk\n",
    "       - REVIEW: Acceptable but needs senior review\n",
    "       - DENY: High risk, does not meet criteria\n",
    "    \n",
    "    Be professional and concise. Focus on facts and ratios.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"You are a senior loan officer writing executive summaries for the credit committee.\"\n",
    "    \n",
    "    return call_llm(prompt, system_prompt, model=GPT4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the 3-Step Sequential Chain\n",
    "def sequential_chain_basic(application: str) -> Dict[str, LLMResponse]:\n",
    "    \"\"\"\n",
    "    Execute 3-step sequential loan processing chain\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results from each step plus total metrics\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    results = {}\n",
    "    \n",
    "    print(\"Starting Sequential Chain...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Step 1: Extract Information\n",
    "    print(\"\\n[1/3] Extracting information...\")\n",
    "    step1_result = step1_extract_info(application)\n",
    "    results['step1_extraction'] = step1_result\n",
    "    print(f\"✓ Completed in {step1_result.latency:.2f}s ({step1_result.tokens} tokens)\")\n",
    "    \n",
    "    # Step 2: Calculate Ratios (uses Step 1 output)\n",
    "    print(\"\\n[2/3] Calculating financial ratios...\")\n",
    "    step2_result = step2_calculate_ratios(step1_result.content)\n",
    "    results['step2_ratios'] = step2_result\n",
    "    print(f\"✓ Completed in {step2_result.latency:.2f}s ({step2_result.tokens} tokens)\")\n",
    "    \n",
    "    # Step 3: Generate Summary (uses Step 1 and Step 2 outputs)\n",
    "    print(\"\\n[3/3] Generating executive summary...\")\n",
    "    step3_result = step3_generate_summary(step1_result.content, step2_result.content)\n",
    "    results['step3_summary'] = step3_result\n",
    "    print(f\"✓ Completed in {step3_result.latency:.2f}s ({step3_result.tokens} tokens)\")\n",
    "    \n",
    "    # Calculate total metrics\n",
    "    total_time = time.time() - start_time\n",
    "    total_tokens = sum(r.tokens for r in results.values())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SEQUENTIAL CHAIN COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total Time: {total_time:.2f}s\")\n",
    "    print(f\"Total Tokens: {total_tokens}\")\n",
    "    print(f\"Steps Executed: {len(results)}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Store totals\n",
    "    results['_metadata'] = {\n",
    "        'total_time': total_time,\n",
    "        'total_tokens': total_tokens,\n",
    "        'steps': len(results) - 1\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Execute the chain\n",
    "print(\"Testing Sequential Chain with Sample Loan Application\\n\")\n",
    "results = sequential_chain_basic(SAMPLE_LOAN_APPLICATION)\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(results['step3_summary'].content)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69d37f",
   "metadata": {},
   "source": [
    "### Challenge 1.2: Enhanced Sequential Chain with State (10 minutes)\n",
    "\n",
    "**Objective:** Add state management and intermediate result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LoanProcessingContext:\n",
    "    \"\"\"Context object that accumulates state across workflow\"\"\"\n",
    "    application_id: str\n",
    "    application_text: str\n",
    "    extracted_data: Optional[Dict] = None\n",
    "    financial_ratios: Optional[Dict] = None\n",
    "    risk_assessment: Optional[str] = None\n",
    "    recommendation: Optional[str] = None\n",
    "    processing_log: List[str] = field(default_factory=list)\n",
    "    total_tokens: int = 0\n",
    "    total_latency: float = 0.0\n",
    "    \n",
    "    def log(self, message: str):\n",
    "        \"\"\"Add timestamped log entry\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "        self.processing_log.append(f\"[{timestamp}] {message}\")\n",
    "        print(f\"[{timestamp}] {message}\")\n",
    "    \n",
    "    def add_metrics(self, response: LLMResponse):\n",
    "        \"\"\"Track cumulative metrics\"\"\"\n",
    "        self.total_tokens += response.tokens\n",
    "        self.total_latency += response.latency\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"Convert to dictionary\"\"\"\n",
    "        return {\n",
    "            \"application_id\": self.application_id,\n",
    "            \"extracted_data\": self.extracted_data,\n",
    "            \"financial_ratios\": self.financial_ratios,\n",
    "            \"risk_assessment\": self.risk_assessment,\n",
    "            \"recommendation\": self.recommendation,\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"total_latency\": self.total_latency,\n",
    "            \"processing_log\": self.processing_log\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97aa795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stateful_sequential_workflow(application: str, app_id: str) -> LoanProcessingContext:\n",
    "    \"\"\"\n",
    "    Process loan application with full state tracking and error handling\n",
    "    \"\"\"\n",
    "    context = LoanProcessingContext(\n",
    "        application_id=app_id,\n",
    "        application_text=application\n",
    "    )\n",
    "    \n",
    "    context.log(f\"Started processing application {app_id}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract Data\n",
    "        context.log(\"Step 1/3: Extracting information...\")\n",
    "        response1 = step1_extract_info(application)\n",
    "        context.add_metrics(response1)\n",
    "        \n",
    "        # Parse and store extracted data\n",
    "        try:\n",
    "            context.extracted_data = json.loads(response1.content)\n",
    "            context.log(f\"✓ Extracted data for {context.extracted_data.get('applicant_name', 'Unknown')}\")\n",
    "        except json.JSONDecodeError:\n",
    "            context.log(\"⚠ Warning: Could not parse extraction JSON, using raw content\")\n",
    "            context.extracted_data = {\"raw\": response1.content}\n",
    "        \n",
    "        # Step 2: Calculate Ratios\n",
    "        context.log(\"Step 2/3: Calculating financial ratios...\")\n",
    "        response2 = step2_calculate_ratios(response1.content)\n",
    "        context.add_metrics(response2)\n",
    "        \n",
    "        # Parse and store ratios\n",
    "        try:\n",
    "            context.financial_ratios = json.loads(response2.content)\n",
    "            dti = context.financial_ratios.get('dti_ratio', 'N/A')\n",
    "            context.log(f\"✓ Calculated DTI: {dti}%\")\n",
    "        except json.JSONDecodeError:\n",
    "            context.log(\"⚠ Warning: Could not parse ratios JSON, using raw content\")\n",
    "            context.financial_ratios = {\"raw\": response2.content}\n",
    "        \n",
    "        # Step 3: Generate Recommendation\n",
    "        context.log(\"Step 3/3: Generating recommendation...\")\n",
    "        response3 = step3_generate_summary(response1.content, response2.content)\n",
    "        context.add_metrics(response3)\n",
    "        \n",
    "        context.risk_assessment = response3.content\n",
    "        \n",
    "        # Extract recommendation from summary\n",
    "        content_upper = response3.content.upper()\n",
    "        if \"RECOMMEND: APPROVE\" in content_upper or \"RECOMMENDATION: APPROVE\" in content_upper:\n",
    "            context.recommendation = \"APPROVE\"\n",
    "        elif \"RECOMMEND: DENY\" in content_upper or \"RECOMMENDATION: DENY\" in content_upper:\n",
    "            context.recommendation = \"DENY\"\n",
    "        else:\n",
    "            context.recommendation = \"REVIEW\"\n",
    "        \n",
    "        context.log(f\"✓ Recommendation: {context.recommendation}\")\n",
    "        context.log(f\"Processing complete - {context.total_tokens} tokens, {context.total_latency:.2f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        context.log(f\"✗ Error during processing: {str(e)}\")\n",
    "        context.recommendation = \"ERROR\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "# Test stateful workflow\n",
    "print(\"=\"*80)\n",
    "print(\"STATEFUL SEQUENTIAL WORKFLOW TEST\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "context = stateful_sequential_workflow(SAMPLE_LOAN_APPLICATION, \"LA-2024-5821\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING CONTEXT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Application ID: {context.application_id}\")\n",
    "print(f\"Applicant: {context.extracted_data.get('applicant_name', 'N/A') if context.extracted_data else 'N/A'}\")\n",
    "print(f\"Recommendation: {context.recommendation}\")\n",
    "print(f\"Total Tokens: {context.total_tokens}\")\n",
    "print(f\"Total Latency: {context.total_latency:.2f}s\")\n",
    "print(\"\\nProcessing Log:\")\n",
    "for log_entry in context.processing_log:\n",
    "    print(f\"  {log_entry}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f927a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 2: PARALLEL PROCESSING (Lab 3.2)\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Execute independent tasks concurrently to reduce latency\n",
    "\n",
    "### Theory: Parallel Pattern\n",
    "\n",
    "**Concept:** Fork into independent tasks, execute concurrently, then join results\n",
    "\n",
    "```\n",
    "Input → Fork → [Task A]\n",
    "              [Task B] → Join → Synthesize → Output\n",
    "              [Task C]\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Tasks are independent (no dependencies)\n",
    "- Speed/latency matters\n",
    "- Can afford higher compute costs\n",
    "\n",
    "**Expected speedup:** ~3x for 3 parallel tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4c03b",
   "metadata": {},
   "source": [
    "### Challenge 2.1: Parallel Credit Checks (15 minutes)\n",
    "\n",
    "**Scenario:** Verify loan application across 3 independent sources:\n",
    "1. Credit bureau check\n",
    "2. Employment verification\n",
    "3. Identity verification\n",
    "\n",
    "All can run in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_credit_bureau(applicant_data: Dict) -> LLMResponse:\n",
    "    \"\"\"Simulate credit bureau verification\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Perform credit bureau verification for this applicant:\n",
    "    \n",
    "    Applicant Data:\n",
    "    {json.dumps(applicant_data, indent=2)}\n",
    "    \n",
    "    Verify and return JSON with:\n",
    "    {{\n",
    "        \"credit_score\": <number>,\n",
    "        \"credit_score_valid\": <true/false>,\n",
    "        \"payment_history\": \"<Excellent/Good/Fair/Poor>\",\n",
    "        \"outstanding_debts\": <total amount>,\n",
    "        \"bankruptcy_history\": <true/false>,\n",
    "        \"verification_status\": \"VERIFIED\" or \"FAILED\",\n",
    "        \"notes\": \"<any concerns or all clear>\"\n",
    "    }}\n",
    "    \n",
    "    Simulate realistic credit bureau response. Use the credit score from applicant_data.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"You are a credit bureau API returning verification results.\"\n",
    "    \n",
    "    return call_llm(prompt, system_prompt, model=GPT35)\n",
    "\n",
    "\n",
    "def verify_employment(applicant_data: Dict) -> LLMResponse:\n",
    "    \"\"\"Simulate employment verification\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Verify employment for this applicant:\n",
    "    \n",
    "    Applicant Data:\n",
    "    {json.dumps(applicant_data, indent=2)}\n",
    "    \n",
    "    Return JSON with:\n",
    "    {{\n",
    "        \"employer\": \"<company name>\",\n",
    "        \"position\": \"<job title>\",\n",
    "        \"employment_verified\": <true/false>,\n",
    "        \"tenure_years\": <number>,\n",
    "        \"annual_income_verified\": <number>,\n",
    "        \"income_matches_stated\": <true/false>,\n",
    "        \"employment_stable\": <true/false>,\n",
    "        \"verification_status\": \"VERIFIED\" or \"FAILED\",\n",
    "        \"notes\": \"<any discrepancies or all clear>\"\n",
    "    }}\n",
    "    \n",
    "    Use data from applicant_data. Simulate realistic employment verification.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"You are an employment verification service API.\"\n",
    "    \n",
    "    return call_llm(prompt, system_prompt, model=GPT35)\n",
    "\n",
    "\n",
    "def verify_identity(applicant_data: Dict) -> LLMResponse:\n",
    "    \"\"\"Simulate identity verification\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Verify identity for this applicant:\n",
    "    \n",
    "    Applicant Data:\n",
    "    {json.dumps(applicant_data, indent=2)}\n",
    "    \n",
    "    Return JSON with:\n",
    "    {{\n",
    "        \"identity_verified\": <true/false>,\n",
    "        \"name_matches\": <true/false>,\n",
    "        \"address_verified\": <true/false>,\n",
    "        \"fraud_flags\": <number of flags, 0 = none>,\n",
    "        \"risk_level\": \"<LOW/MEDIUM/HIGH>\",\n",
    "        \"verification_status\": \"VERIFIED\" or \"FAILED\",\n",
    "        \"notes\": \"<any red flags or all clear>\"\n",
    "    }}\n",
    "    \n",
    "    Simulate realistic identity verification check.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"You are an identity verification service API.\"\n",
    "    \n",
    "    return call_llm(prompt, system_prompt, model=GPT35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e422bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_verification_checks(applicant_data: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Execute all three verification checks in parallel\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results from each check and performance metrics\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    results = {}\n",
    "    \n",
    "    print(\"Starting Parallel Verification Checks...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Define tasks\n",
    "    tasks = {\n",
    "        'credit_bureau': check_credit_bureau,\n",
    "        'employment': verify_employment,\n",
    "        'identity': verify_identity\n",
    "    }\n",
    "    \n",
    "    # Execute in parallel using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_name = {\n",
    "            executor.submit(func, applicant_data): name \n",
    "            for name, func in tasks.items()\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_name):\n",
    "            task_name = future_to_name[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results[task_name] = result\n",
    "                print(f\"✓ {task_name.replace('_', ' ').title()}: {result.latency:.2f}s ({result.tokens} tokens)\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ {task_name} failed: {str(e)}\")\n",
    "                results[task_name] = LLMResponse(f\"Error: {str(e)}\", GPT35, 0, 0.0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_time = time.time() - start_time\n",
    "    total_tokens = sum(r.tokens for r in results.values() if isinstance(r, LLMResponse))\n",
    "    sequential_time = sum(r.latency for r in results.values() if isinstance(r, LLMResponse))\n",
    "    speedup = sequential_time / total_time if total_time > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PARALLEL VERIFICATION COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Wall Clock Time: {total_time:.2f}s\")\n",
    "    print(f\"Sequential Time (if run in series): {sequential_time:.2f}s\")\n",
    "    print(f\"Speedup: {speedup:.2f}x\")\n",
    "    print(f\"Total Tokens: {total_tokens}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results['_metadata'] = {\n",
    "        'wall_clock_time': total_time,\n",
    "        'sequential_time': sequential_time,\n",
    "        'speedup': speedup,\n",
    "        'total_tokens': total_tokens\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Test parallel verification\n",
    "test_applicant = {\n",
    "    \"name\": \"Sarah Johnson\",\n",
    "    \"annual_income\": 145000,\n",
    "    \"credit_score\": 750,\n",
    "    \"employer\": \"TechCorp\",\n",
    "    \"position\": \"Senior Software Engineer\",\n",
    "    \"employment_years\": 6,\n",
    "    \"address\": \"245 Oak Street, San Francisco, CA\"\n",
    "}\n",
    "\n",
    "verification_results = parallel_verification_checks(test_applicant)\n",
    "\n",
    "# Parse and display verification results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for check_name, result in verification_results.items():\n",
    "    if check_name != '_metadata':\n",
    "        print(f\"\\n{check_name.replace('_', ' ').title()}:\")\n",
    "        try:\n",
    "            parsed = json.loads(result.content)\n",
    "            for key, value in parsed.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "        except:\n",
    "            print(f\"  {result.content[:200]}...\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8397737",
   "metadata": {},
   "source": [
    "### Challenge 2.2: Combine Sequential + Parallel (15 minutes)\n",
    "\n",
    "**Objective:** Build hybrid workflow combining both patterns\n",
    "\n",
    "```\n",
    "Step 1: Extract data (sequential)\n",
    "    ↓\n",
    "Step 2: Fork into parallel checks → Join\n",
    "    ↓\n",
    "Step 3: Synthesize results (sequential)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b586303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_loan_processing(application: str, app_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Comprehensive loan processing combining sequential and parallel patterns\n",
    "    \n",
    "    Workflow:\n",
    "    1. Sequential: Extract applicant data\n",
    "    2. Parallel: Run verification checks\n",
    "    3. Sequential: Synthesize final decision\n",
    "    \"\"\"\n",
    "    overall_start = time.time()\n",
    "    results = {}\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"HYBRID WORKFLOW: Application {app_id}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # STEP 1: Extract Data (Sequential - must happen first)\n",
    "    print(\"[Step 1/3] Extracting applicant data...\")\n",
    "    step1_start = time.time()\n",
    "    \n",
    "    extraction = step1_extract_info(application)\n",
    "    try:\n",
    "        applicant_data = json.loads(extraction.content)\n",
    "    except:\n",
    "        applicant_data = {\"error\": \"Could not parse extraction\"}\n",
    "    \n",
    "    step1_time = time.time() - step1_start\n",
    "    results['extraction'] = extraction\n",
    "    print(f\"✓ Extraction complete: {step1_time:.2f}s\\n\")\n",
    "    \n",
    "    # STEP 2: Parallel Verification Checks\n",
    "    print(\"[Step 2/3] Running parallel verification checks...\")\n",
    "    step2_start = time.time()\n",
    "    \n",
    "    verification_results = parallel_verification_checks(applicant_data)\n",
    "    \n",
    "    step2_time = time.time() - step2_start\n",
    "    results['verifications'] = verification_results\n",
    "    print(f\"\\n✓ Verifications complete: {step2_time:.2f}s\\n\")\n",
    "    \n",
    "    # STEP 3: Synthesize Final Decision (Sequential - needs all previous data)\n",
    "    print(\"[Step 3/3] Synthesizing final decision...\")\n",
    "    step3_start = time.time()\n",
    "    \n",
    "    synthesis_prompt = f\"\"\"\n",
    "    Based on the following loan application data and verification results, \n",
    "    provide a final credit decision.\n",
    "    \n",
    "    Applicant Data:\n",
    "    {json.dumps(applicant_data, indent=2)}\n",
    "    \n",
    "    Verification Results:\n",
    "    - Credit Bureau: {verification_results.get('credit_bureau', LLMResponse('', '', 0, 0)).content[:500]}\n",
    "    - Employment: {verification_results.get('employment', LLMResponse('', '', 0, 0)).content[:500]}\n",
    "    - Identity: {verification_results.get('identity', LLMResponse('', '', 0, 0)).content[:500]}\n",
    "    \n",
    "    Provide final decision in this format:\n",
    "    \n",
    "    DECISION: [APPROVE/DENY/MANUAL_REVIEW]\n",
    "    \n",
    "    CONFIDENCE: [HIGH/MEDIUM/LOW]\n",
    "    \n",
    "    KEY FACTORS:\n",
    "    - [List 3-5 key factors influencing this decision]\n",
    "    \n",
    "    REASONING:\n",
    "    [2-3 sentences explaining the decision]\n",
    "    \n",
    "    CONDITIONS (if applicable):\n",
    "    [Any conditions for approval, or N/A]\n",
    "    \"\"\"\n",
    "    \n",
    "    final_decision = call_llm(synthesis_prompt, \n",
    "                             \"You are a senior credit officer making final loan decisions.\",\n",
    "                             model=GPT4)\n",
    "    \n",
    "    step3_time = time.time() - step3_start\n",
    "    results['final_decision'] = final_decision\n",
    "    print(f\"✓ Decision complete: {step3_time:.2f}s\\n\")\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    total_time = time.time() - overall_start\n",
    "    total_tokens = (extraction.tokens + \n",
    "                   verification_results['_metadata']['total_tokens'] + \n",
    "                   final_decision.tokens)\n",
    "    \n",
    "    # Estimate sequential time (if everything ran in sequence)\n",
    "    est_sequential = (step1_time + \n",
    "                     verification_results['_metadata']['sequential_time'] + \n",
    "                     step3_time)\n",
    "    \n",
    "    speedup = est_sequential / total_time\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"HYBRID WORKFLOW COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total Wall Clock Time: {total_time:.2f}s\")\n",
    "    print(f\"Estimated Sequential Time: {est_sequential:.2f}s\")\n",
    "    print(f\"Overall Speedup: {speedup:.2f}x\")\n",
    "    print(f\"Total Tokens: {total_tokens}\")\n",
    "    print(\"\\nTiming Breakdown:\")\n",
    "    print(f\"  Step 1 (Sequential): {step1_time:.2f}s\")\n",
    "    print(f\"  Step 2 (Parallel): {step2_time:.2f}s\")\n",
    "    print(f\"  Step 3 (Sequential): {step3_time:.2f}s\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results['_metadata'] = {\n",
    "        'total_time': total_time,\n",
    "        'estimated_sequential_time': est_sequential,\n",
    "        'speedup': speedup,\n",
    "        'total_tokens': total_tokens,\n",
    "        'step_times': {\n",
    "            'extraction': step1_time,\n",
    "            'verification': step2_time,\n",
    "            'decision': step3_time\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Execute hybrid workflow\n",
    "hybrid_results = hybrid_loan_processing(SAMPLE_LOAN_APPLICATION, \"LA-2024-5821\")\n",
    "\n",
    "# Display final decision\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL CREDIT DECISION\")\n",
    "print(\"=\"*80)\n",
    "print(hybrid_results['final_decision'].content)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3280f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 3: CONDITIONAL WORKFLOWS (Lab 3.3)\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Build dynamic workflows that route based on data\n",
    "\n",
    "### Theory: Conditional Pattern\n",
    "\n",
    "**Concept:** Different inputs take different processing paths\n",
    "\n",
    "```\n",
    "Input → [Classify] → Decision Point\n",
    "                         ├─ Path A (simple processing)\n",
    "                         ├─ Path B (standard processing)\n",
    "                         └─ Path C (enhanced processing)\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Different inputs need different handling\n",
    "- Want to optimize processing (don't over-process simple cases)\n",
    "- Clear decision criteria exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763a460",
   "metadata": {},
   "source": [
    "### Challenge 3.1: Risk-Based Routing (20 minutes)\n",
    "\n",
    "**Scenario:** Route loans to different approval workflows based on amount:\n",
    "- **Small loans** (<$100K): Fast-track approval (2 steps)\n",
    "- **Medium loans** ($100K-$500K): Standard review (4 steps)\n",
    "- **Large loans** (>$500K): Enhanced due diligence (6 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanRouter:\n",
    "    \"\"\"Intelligent loan routing based on amount and risk\"\"\"\n",
    "    \n",
    "    SMALL_LOAN_THRESHOLD = 100000\n",
    "    LARGE_LOAN_THRESHOLD = 500000\n",
    "    \n",
    "    @staticmethod\n",
    "    def classify_loan(loan_amount: float) -> str:\n",
    "        \"\"\"Classify loan into size category\"\"\"\n",
    "        if loan_amount < LoanRouter.SMALL_LOAN_THRESHOLD:\n",
    "            return \"SMALL\"\n",
    "        elif loan_amount < LoanRouter.LARGE_LOAN_THRESHOLD:\n",
    "            return \"MEDIUM\"\n",
    "        else:\n",
    "            return \"LARGE\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_small_loan(application: str, loan_amount: float) -> Dict:\n",
    "        \"\"\"Fast-track processing for small loans (<$100K)\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"SMALL LOAN FAST-TRACK WORKFLOW (${loan_amount:,.0f})\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        \n",
    "        # Step 1: Quick credit check\n",
    "        print(\"[1/2] Quick credit assessment...\")\n",
    "        step1_prompt = f\"\"\"\n",
    "        Perform quick credit assessment for small loan:\n",
    "        \n",
    "        Application:\n",
    "        {application}\n",
    "        \n",
    "        Provide quick decision based on:\n",
    "        - Credit score (must be >650)\n",
    "        - Income stability\n",
    "        - Basic debt check\n",
    "        \n",
    "        Return JSON:\n",
    "        {{\n",
    "            \"credit_acceptable\": <true/false>,\n",
    "            \"quick_decision\": \"<APPROVE/DENY/NEEDS_REVIEW>\",\n",
    "            \"reason\": \"<brief explanation>\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        credit_check = call_llm(step1_prompt, \n",
    "                               \"You are a fast-track credit assessor for small loans.\",\n",
    "                               model=GPT35)\n",
    "        results['credit_check'] = credit_check\n",
    "        print(f\"✓ Credit check complete ({credit_check.latency:.2f}s)\")\n",
    "        \n",
    "        # Step 2: Auto-decision\n",
    "        print(\"[2/2] Generating auto-decision...\")\n",
    "        try:\n",
    "            credit_data = json.loads(credit_check.content)\n",
    "            decision = credit_data.get('quick_decision', 'NEEDS_REVIEW')\n",
    "        except:\n",
    "            decision = \"NEEDS_REVIEW\"\n",
    "        \n",
    "        results['final_decision'] = decision\n",
    "        results['workflow_type'] = \"FAST_TRACK\"\n",
    "        results['processing_time'] = time.time() - start_time\n",
    "        \n",
    "        print(f\"✓ Decision: {decision}\")\n",
    "        print(f\"\\nTotal processing time: {results['processing_time']:.2f}s\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_medium_loan(application: str, loan_amount: float) -> Dict:\n",
    "        \"\"\"Standard processing for medium loans ($100K-$500K)\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"MEDIUM LOAN STANDARD WORKFLOW (${loan_amount:,.0f})\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        \n",
    "        # Step 1: Extract data\n",
    "        print(\"[1/4] Extracting application data...\")\n",
    "        extraction = step1_extract_info(application)\n",
    "        results['extraction'] = extraction\n",
    "        print(f\"✓ Complete ({extraction.latency:.2f}s)\")\n",
    "        \n",
    "        # Step 2: Credit & Employment (parallel)\n",
    "        print(\"[2/4] Running credit and employment verification...\")\n",
    "        try:\n",
    "            applicant_data = json.loads(extraction.content)\n",
    "        except:\n",
    "            applicant_data = {}\n",
    "        \n",
    "        verification_start = time.time()\n",
    "        with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "            credit_future = executor.submit(check_credit_bureau, applicant_data)\n",
    "            employment_future = executor.submit(verify_employment, applicant_data)\n",
    "            \n",
    "            credit_result = credit_future.result()\n",
    "            employment_result = employment_future.result()\n",
    "        \n",
    "        verification_time = time.time() - verification_start\n",
    "        results['verification'] = {\n",
    "            'credit': credit_result,\n",
    "            'employment': employment_result,\n",
    "            'time': verification_time\n",
    "        }\n",
    "        print(f\"✓ Verifications complete ({verification_time:.2f}s)\")\n",
    "        \n",
    "        # Step 3: Calculate ratios\n",
    "        print(\"[3/4] Calculating financial ratios...\")\n",
    "        ratios = step2_calculate_ratios(extraction.content)\n",
    "        results['ratios'] = ratios\n",
    "        print(f\"✓ Complete ({ratios.latency:.2f}s)\")\n",
    "        \n",
    "        # Step 4: Generate recommendation\n",
    "        print(\"[4/4] Generating recommendation...\")\n",
    "        recommendation = step3_generate_summary(extraction.content, ratios.content)\n",
    "        results['recommendation'] = recommendation\n",
    "        print(f\"✓ Complete ({recommendation.latency:.2f}s)\")\n",
    "        \n",
    "        results['workflow_type'] = \"STANDARD\"\n",
    "        results['processing_time'] = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nTotal processing time: {results['processing_time']:.2f}s\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_large_loan(application: str, loan_amount: float) -> Dict:\n",
    "        \"\"\"Enhanced due diligence for large loans (>$500K)\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"LARGE LOAN ENHANCED DUE DILIGENCE (${loan_amount:,.0f})\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        \n",
    "        # Step 1: Extract comprehensive data\n",
    "        print(\"[1/6] Comprehensive data extraction...\")\n",
    "        extraction = step1_extract_info(application)\n",
    "        results['extraction'] = extraction\n",
    "        print(f\"✓ Complete ({extraction.latency:.2f}s)\")\n",
    "        \n",
    "        # Step 2: Full parallel verifications\n",
    "        print(\"[2/6] Running comprehensive verification suite...\")\n",
    "        try:\n",
    "            applicant_data = json.loads(extraction.content)\n",
    "        except:\n",
    "            applicant_data = {}\n",
    "        \n",
    "        full_verification = parallel_verification_checks(applicant_data)\n",
    "        results['verification'] = full_verification\n",
    "        print(f\"✓ All verifications complete\")\n",
    "        \n",
    "        # Step 3: Advanced financial analysis\n",
    "        print(\"[3/6] Advanced financial analysis...\")\n",
    "        analysis_prompt = f\"\"\"\n",
    "        Perform advanced financial analysis for large commercial loan:\n",
    "        \n",
    "        Application Data:\n",
    "        {extraction.content}\n",
    "        \n",
    "        Provide comprehensive analysis including:\n",
    "        - All standard ratios (DTI, LTV, DSCR)\n",
    "        - Cash flow analysis\n",
    "        - Collateral assessment\n",
    "        - Market risk factors\n",
    "        - Stress testing scenarios\n",
    "        \n",
    "        Return detailed JSON with all metrics and assessments.\n",
    "        \"\"\"\n",
    "        \n",
    "        financial_analysis = call_llm(analysis_prompt,\n",
    "                                     \"You are a senior financial analyst for large loans.\",\n",
    "                                     model=GPT4)\n",
    "        results['financial_analysis'] = financial_analysis\n",
    "        print(f\"✓ Complete ({financial_analysis.latency:.2f}s)\")\n",
    "        \n",
    "        # Step 4: Risk modeling\n",
    "        print(\"[4/6] Risk modeling and scenario analysis...\")\n",
    "        risk_prompt = f\"\"\"\n",
    "        Perform risk modeling for this large loan:\n",
    "        \n",
    "        Analysis:\n",
    "        {financial_analysis.content[:1000]}\n",
    "        \n",
    "        Model risk scenarios:\n",
    "        - Best case\n",
    "        - Base case\n",
    "        - Stress case\n",
    "        - Default probability\n",
    "        - Expected loss\n",
    "        \n",
    "        Return JSON with risk assessment.\n",
    "        \"\"\"\n",
    "        \n",
    "        risk_model = call_llm(risk_prompt,\n",
    "                             \"You are a risk modeling specialist.\",\n",
    "                             model=GPT4)\n",
    "        results['risk_model'] = risk_model\n",
    "        print(f\"✓ Complete ({risk_model.latency:.2f}s)\")\n",
    "        \n",
    "        # Step 5: Senior review requirements\n",
    "        print(\"[5/6] Preparing senior review package...\")\n",
    "        review_prep = call_llm(\n",
    "            f\"Prepare executive summary for credit committee review of ${loan_amount:,.0f} loan. Include all key risks and recommendations.\",\n",
    "            \"You are preparing materials for senior credit committee.\",\n",
    "            model=GPT4\n",
    "        )\n",
    "        results['review_package'] = review_prep\n",
    "        print(f\"✓ Complete ({review_prep.latency:.2f}s)\")\n",
    "        \n",
    "        # Step 6: Committee decision requirements\n",
    "        print(\"[6/6] Generating committee decision framework...\")\n",
    "        committee_prep = call_llm(\n",
    "            f\"Create decision framework for credit committee. What questions should they ask? What additional diligence is needed?\",\n",
    "            \"You are a credit committee advisor.\",\n",
    "            model=GPT4\n",
    "        )\n",
    "        results['committee_framework'] = committee_prep\n",
    "        print(f\"✓ Complete ({committee_prep.latency:.2f}s)\")\n",
    "        \n",
    "        results['workflow_type'] = \"ENHANCED_DD\"\n",
    "        results['processing_time'] = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nTotal processing time: {results['processing_time']:.2f}s\")\n",
    "        print(f\"Requires: SENIOR REVIEW + COMMITTEE APPROVAL\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    @classmethod\n",
    "    def route_and_process(cls, application: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Main routing function: classify loan and route to appropriate workflow\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CONDITIONAL LOAN ROUTING SYSTEM\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Extract loan amount for routing decision\n",
    "        extraction_prompt = f\"\"\"\n",
    "        Extract only the loan amount from this application.\n",
    "        Return as JSON: {{\"loan_amount\": <number>}}\n",
    "        \n",
    "        Application:\n",
    "        {application}\n",
    "        \"\"\"\n",
    "        \n",
    "        amount_extraction = call_llm(extraction_prompt, \n",
    "                                    \"You extract loan amounts.\",\n",
    "                                    model=GPT35)\n",
    "        \n",
    "        try:\n",
    "            loan_amount = json.loads(amount_extraction.content)['loan_amount']\n",
    "        except:\n",
    "            # Fallback: try to find amount in text\n",
    "            amounts = re.findall(r'\\$([\\d,]+)', application)\n",
    "            loan_amount = float(amounts[0].replace(',', '')) if amounts else 100000\n",
    "        \n",
    "        # Classify\n",
    "        category = cls.classify_loan(loan_amount)\n",
    "        \n",
    "        print(f\"\\nLoan Amount: ${loan_amount:,.0f}\")\n",
    "        print(f\"Category: {category}\")\n",
    "        print(f\"Routing to: {category} loan workflow...\\n\")\n",
    "        \n",
    "        # Route to appropriate workflow\n",
    "        if category == \"SMALL\":\n",
    "            result = cls.process_small_loan(application, loan_amount)\n",
    "        elif category == \"MEDIUM\":\n",
    "            result = cls.process_medium_loan(application, loan_amount)\n",
    "        else:  # LARGE\n",
    "            result = cls.process_large_loan(application, loan_amount)\n",
    "        \n",
    "        # Add routing metadata\n",
    "        result['loan_amount'] = loan_amount\n",
    "        result['category'] = category\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59120c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the conditional router with different loan sizes\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING CONDITIONAL ROUTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Small loan\n",
    "print(\"\\n### TEST 1: SMALL LOAN ###\")\n",
    "small_result = LoanRouter.route_and_process(SMALL_LOAN_APP)\n",
    "\n",
    "# Test 2: Medium loan  \n",
    "print(\"\\n### TEST 2: MEDIUM LOAN ###\")\n",
    "medium_result = LoanRouter.route_and_process(SAMPLE_LOAN_APPLICATION)\n",
    "\n",
    "# Test 3: Large loan\n",
    "print(\"\\n### TEST 3: LARGE LOAN ###\")\n",
    "large_result = LoanRouter.route_and_process(LARGE_LOAN_APP)\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ROUTING EFFICIENCY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Small Loan:  {small_result['processing_time']:.2f}s ({small_result['workflow_type']})\")\n",
    "print(f\"Medium Loan: {medium_result['processing_time']:.2f}s ({medium_result['workflow_type']})\")\n",
    "print(f\"Large Loan:  {large_result['processing_time']:.2f}s ({large_result['workflow_type']})\")\n",
    "print(\"\\nConditional routing optimizes processing based on risk!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49770612",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 4: PRODUCTION ORCHESTRATION (Lab 3.4)\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Add production-grade features: error handling, retries, monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196699c",
   "metadata": {},
   "source": [
    "### Challenge 4.1: Production-Ready Orchestration (30 minutes)\n",
    "\n",
    "**Objective:** Build enterprise-grade orchestration with all production features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowStatus(Enum):\n",
    "    \"\"\"Workflow execution status\"\"\"\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    PARTIAL = \"partial\"  # Some steps succeeded, some failed\n",
    "\n",
    "@dataclass\n",
    "class StepResult:\n",
    "    \"\"\"Result from individual workflow step\"\"\"\n",
    "    step_name: str\n",
    "    status: str  # success, failed, skipped\n",
    "    response: Optional[LLMResponse] = None\n",
    "    error: Optional[str] = None\n",
    "    retry_count: int = 0\n",
    "    start_time: float = 0.0\n",
    "    end_time: float = 0.0\n",
    "    \n",
    "    @property\n",
    "    def duration(self) -> float:\n",
    "        return self.end_time - self.start_time if self.end_time > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2563fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionOrchestrator:\n",
    "    \"\"\"\n",
    "    Production-grade workflow orchestration with:\n",
    "    - Error handling and retries\n",
    "    - Comprehensive logging\n",
    "    - Metrics tracking\n",
    "    - Graceful degradation\n",
    "    - Health monitoring\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries: int = 3, retry_delay: float = 1.0):\n",
    "        self.max_retries = max_retries\n",
    "        self.retry_delay = retry_delay\n",
    "        self.execution_log: List[str] = []\n",
    "        self.metrics: Dict[str, Any] = {}\n",
    "        \n",
    "    def log(self, message: str, level: str = \"INFO\"):\n",
    "        \"\"\"Add timestamped log entry\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "        log_entry = f\"[{timestamp}] [{level}] {message}\"\n",
    "        self.execution_log.append(log_entry)\n",
    "        print(log_entry)\n",
    "    \n",
    "    def execute_step_with_retry(\n",
    "        self,\n",
    "        step_name: str,\n",
    "        step_func: Callable,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> StepResult:\n",
    "        \"\"\"\n",
    "        Execute a single step with retry logic\n",
    "        \"\"\"\n",
    "        result = StepResult(\n",
    "            step_name=step_name,\n",
    "            status=\"pending\",\n",
    "            start_time=time.time()\n",
    "        )\n",
    "        \n",
    "        for attempt in range(1, self.max_retries + 1):\n",
    "            try:\n",
    "                self.log(f\"Executing {step_name} (attempt {attempt}/{self.max_retries})\")\n",
    "                response = step_func(*args, **kwargs)\n",
    "                \n",
    "                result.response = response\n",
    "                result.status = \"success\"\n",
    "                result.retry_count = attempt - 1\n",
    "                result.end_time = time.time()\n",
    "                \n",
    "                self.log(f\"✓ {step_name} completed successfully ({result.duration:.2f}s)\", \"SUCCESS\")\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                self.log(f\"✗ {step_name} failed: {error_msg}\", \"ERROR\")\n",
    "                \n",
    "                if attempt < self.max_retries:\n",
    "                    delay = self.retry_delay * (2 ** (attempt - 1))  # Exponential backoff\n",
    "                    self.log(f\"Retrying in {delay:.1f}s...\", \"WARNING\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    result.status = \"failed\"\n",
    "                    result.error = error_msg\n",
    "                    result.retry_count = attempt\n",
    "                    result.end_time = time.time()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def execute_workflow(\n",
    "        self,\n",
    "        workflow_name: str,\n",
    "        steps: List[Tuple[str, Callable, tuple, dict]],\n",
    "        fail_fast: bool = False\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute complete workflow with monitoring\n",
    "        \n",
    "        Args:\n",
    "            workflow_name: Name of workflow\n",
    "            steps: List of (step_name, function, args, kwargs) tuples\n",
    "            fail_fast: Stop on first failure if True\n",
    "        \n",
    "        Returns:\n",
    "            Complete workflow results with metrics\n",
    "        \"\"\"\n",
    "        workflow_start = time.time()\n",
    "        \n",
    "        self.log(\"=\"*80)\n",
    "        self.log(f\"Starting workflow: {workflow_name}\")\n",
    "        self.log(\"=\"*80)\n",
    "        \n",
    "        results = {\n",
    "            'workflow_name': workflow_name,\n",
    "            'status': WorkflowStatus.RUNNING.value,\n",
    "            'steps': {},\n",
    "            'metrics': {},\n",
    "            'logs': []\n",
    "        }\n",
    "        \n",
    "        successful_steps = 0\n",
    "        failed_steps = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for step_name, step_func, args, kwargs in steps:\n",
    "            step_result = self.execute_step_with_retry(step_name, step_func, *args, **kwargs)\n",
    "            \n",
    "            results['steps'][step_name] = {\n",
    "                'status': step_result.status,\n",
    "                'duration': step_result.duration,\n",
    "                'retry_count': step_result.retry_count,\n",
    "                'tokens': step_result.response.tokens if step_result.response else 0,\n",
    "                'error': step_result.error\n",
    "            }\n",
    "            \n",
    "            if step_result.status == \"success\":\n",
    "                successful_steps += 1\n",
    "                if step_result.response:\n",
    "                    total_tokens += step_result.response.tokens\n",
    "            else:\n",
    "                failed_steps += 1\n",
    "                if fail_fast:\n",
    "                    self.log(f\"Fail-fast enabled. Stopping workflow.\", \"ERROR\")\n",
    "                    break\n",
    "        \n",
    "        # Determine final status\n",
    "        if failed_steps == 0:\n",
    "            final_status = WorkflowStatus.COMPLETED.value\n",
    "        elif successful_steps == 0:\n",
    "            final_status = WorkflowStatus.FAILED.value\n",
    "        else:\n",
    "            final_status = WorkflowStatus.PARTIAL.value\n",
    "        \n",
    "        total_duration = time.time() - workflow_start\n",
    "        \n",
    "        results['status'] = final_status\n",
    "        results['metrics'] = {\n",
    "            'total_duration': total_duration,\n",
    "            'successful_steps': successful_steps,\n",
    "            'failed_steps': failed_steps,\n",
    "            'total_steps': len(steps),\n",
    "            'success_rate': successful_steps / len(steps) if steps else 0,\n",
    "            'total_tokens': total_tokens\n",
    "        }\n",
    "        results['logs'] = self.execution_log.copy()\n",
    "        \n",
    "        self.log(\"=\"*80)\n",
    "        self.log(f\"Workflow {workflow_name} completed: {final_status}\")\n",
    "        self.log(f\"Duration: {total_duration:.2f}s | Success: {successful_steps}/{len(steps)}\")\n",
    "        self.log(\"=\"*80)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696310bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test production orchestrator\n",
    "orchestrator = ProductionOrchestrator(max_retries=2, retry_delay=0.5)\n",
    "\n",
    "# Define workflow steps\n",
    "workflow_steps = [\n",
    "    (\"extract_data\", step1_extract_info, (SAMPLE_LOAN_APPLICATION,), {}),\n",
    "    (\"verify_credit\", check_credit_bureau, ({\"name\": \"Test\", \"credit_score\": 750},), {}),\n",
    "    (\"verify_employment\", verify_employment, ({\"employer\": \"TechCorp\", \"income\": 145000},), {}),\n",
    "]\n",
    "\n",
    "# Execute workflow\n",
    "production_results = orchestrator.execute_workflow(\n",
    "    workflow_name=\"Loan Processing Pipeline\",\n",
    "    steps=workflow_steps,\n",
    "    fail_fast=False\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WORKFLOW METRICS DASHBOARD\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Status: {production_results['status']}\")\n",
    "print(f\"Duration: {production_results['metrics']['total_duration']:.2f}s\")\n",
    "print(f\"Success Rate: {production_results['metrics']['success_rate']*100:.1f}%\")\n",
    "print(f\"Total Tokens: {production_results['metrics']['total_tokens']}\")\n",
    "print(\"\\nStep-by-Step Results:\")\n",
    "for step_name, step_info in production_results['steps'].items():\n",
    "    status_icon = \"✓\" if step_info['status'] == \"success\" else \"✗\"\n",
    "    print(f\"  {status_icon} {step_name}: {step_info['duration']:.2f}s \"\n",
    "          f\"({step_info['tokens']} tokens, {step_info['retry_count']} retries)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cbd16e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CAPSTONE CHALLENGE: ENTERPRISE LOAN PROCESSING SYSTEM\n",
    "\n",
    "**Objective:** Build complete production system combining all patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456697f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnterpriseLoanProcessor:\n",
    "    \"\"\"\n",
    "    Complete production loan processing system combining:\n",
    "    - Conditional routing\n",
    "    - Parallel processing\n",
    "    - Sequential workflows\n",
    "    - Error handling\n",
    "    - Monitoring\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.orchestrator = ProductionOrchestrator(max_retries=3)\n",
    "        self.router = LoanRouter()\n",
    "        self.processing_stats = {\n",
    "            'total_processed': 0,\n",
    "            'approved': 0,\n",
    "            'denied': 0,\n",
    "            'review': 0,\n",
    "            'total_time': 0.0,\n",
    "            'total_tokens': 0\n",
    "        }\n",
    "    \n",
    "    def process_application(self, application: str, app_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process single loan application through complete system\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ENTERPRISE LOAN PROCESSOR - Application {app_id}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Route to appropriate workflow\n",
    "        result = self.router.route_and_process(application)\n",
    "        \n",
    "        # Update statistics\n",
    "        processing_time = time.time() - start_time\n",
    "        self.processing_stats['total_processed'] += 1\n",
    "        self.processing_stats['total_time'] += processing_time\n",
    "        \n",
    "        decision = result.get('final_decision', 'REVIEW')\n",
    "        if decision == 'APPROVE':\n",
    "            self.processing_stats['approved'] += 1\n",
    "        elif decision == 'DENY':\n",
    "            self.processing_stats['denied'] += 1\n",
    "        else:\n",
    "            self.processing_stats['review'] += 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return processing statistics\"\"\"\n",
    "        avg_time = (self.processing_stats['total_time'] / \n",
    "                   self.processing_stats['total_processed'] \n",
    "                   if self.processing_stats['total_processed'] > 0 else 0)\n",
    "        \n",
    "        return {\n",
    "            'total_processed': self.processing_stats['total_processed'],\n",
    "            'approved': self.processing_stats['approved'],\n",
    "            'denied': self.processing_stats['denied'],\n",
    "            'needs_review': self.processing_stats['review'],\n",
    "            'average_processing_time': avg_time,\n",
    "            'total_tokens': self.processing_stats['total_tokens']\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize enterprise processor\n",
    "processor = EnterpriseLoanProcessor()\n",
    "\n",
    "# Process multiple applications\n",
    "applications = [\n",
    "    (SMALL_LOAN_APP, \"LA-2024-001\"),\n",
    "    (SAMPLE_LOAN_APPLICATION, \"LA-2024-002\"),\n",
    "    (LARGE_LOAN_APP, \"LA-2024-003\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "for app, app_id in applications:\n",
    "    result = processor.process_application(app, app_id)\n",
    "    results.append(result)\n",
    "    time.sleep(0.5)  # Brief pause between applications\n",
    "\n",
    "# Display final statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENTERPRISE PROCESSING STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "stats = processor.get_statistics()\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f016f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## LAB SUMMARY\n",
    "\n",
    "### Patterns Mastered\n",
    "\n",
    "| Pattern | Use Case | Key Benefit | Typical Speedup |\n",
    "|---------|----------|-------------|------------------|\n",
    "| **Sequential** | Dependent steps | Clear logic, debuggable | 1x (baseline) |\n",
    "| **Parallel** | Independent tasks | Reduced latency | 2-3x |\n",
    "| **Conditional** | Different processing paths | Optimized cost/speed | Varies (2-10x for simple cases) |\n",
    "| **Hybrid** | Complex workflows | Best of all patterns | 2-4x |\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "Before deploying orchestrated workflows:\n",
    "\n",
    "- [ ] Error handling for each step\n",
    "- [ ] Retry logic with exponential backoff\n",
    "- [ ] Comprehensive logging\n",
    "- [ ] Metrics collection (latency, tokens, success rate)\n",
    "- [ ] Graceful degradation paths\n",
    "- [ ] Health monitoring\n",
    "- [ ] Cost tracking\n",
    "- [ ] Performance SLAs defined\n",
    "- [ ] Testing with edge cases\n",
    "- [ ] Documentation\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "✓ **Sequential chains** execute steps in order with clear dependencies  \n",
    "✓ **Parallel processing** reduces wall-clock time significantly (~2.7x speedup)  \n",
    "✓ **Conditional routing** optimizes cost and speed based on input characteristics  \n",
    "✓ **Hybrid workflows** combine patterns for optimal performance  \n",
    "✓ **Production features** (error handling, retries, monitoring) are essential  \n",
    "\n",
    "---\n",
    "\n",
    "**End of Lab 3: Prompt Flow & Orchestration**\n",
    "\n",
    "**Next Lab:** RAG Implementation (Document Chunking, Embeddings, Vector Search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
