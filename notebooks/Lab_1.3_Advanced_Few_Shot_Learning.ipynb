{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755f71a6",
   "metadata": {},
   "source": [
    "# LAB 1.3: ADVANCED FEW-SHOT LEARNING\n",
    "\n",
    "**Course:** Advanced Prompt Engineering Training  \n",
    "**Session:** Session 1 - Prompt Engineering Fundamentals Review  \n",
    "**Duration:** 50 minutes  \n",
    "**Type:** Hands-on Pattern Learning & Example Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfaf92",
   "metadata": {},
   "source": [
    "## LAB OVERVIEW\n",
    "\n",
    "This lab explores **advanced few-shot learning techniques** for BFSI applications. You'll learn how to:\n",
    "\n",
    "- Design effective few-shot examples that teach models patterns\n",
    "- Select optimal examples dynamically based on input\n",
    "- Use contrastive learning (positive and negative examples)\n",
    "- Balance example quality vs. quantity\n",
    "- Apply few-shot learning to complex classification tasks\n",
    "\n",
    "**Scenario:** You're building an AI system for a bank's customer service department. The system must classify customer intents, assess loan risk from unstructured text, and categorize financial documents. Few-shot learning allows you to teach the model these patterns without fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2411475",
   "metadata": {},
   "source": [
    "## LEARNING OBJECTIVES\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "âœ“ Design high-quality few-shot examples that teach clear patterns  \n",
    "âœ“ Apply contrastive learning (positive + negative examples)  \n",
    "âœ“ Implement dynamic example selection based on input similarity  \n",
    "âœ“ Optimize example count for accuracy and token efficiency  \n",
    "âœ“ Create domain-specific few-shot libraries for BFSI  \n",
    "âœ“ Measure and improve few-shot learning effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d633607",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c0b325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Lab 1.3: Advanced Few-Shot Learning\n",
    "# Advanced Prompt Engineering Training - Session 1\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"âœ“ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d7bde",
   "metadata": {},
   "source": [
    "### Step 2: Configure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c6168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model: gpt-4o\n",
      "âœ“ Temperature: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configuration\n",
    "MODEL = os.getenv(\"MODEL_NAME\")\n",
    "TEMPERATURE = 0  # Deterministic for consistent debugging\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found. Please set it in .env file\")\n",
    "\n",
    "if not MODEL:\n",
    "    raise ValueError(\"MODEL_NAME not found. Please set it in .env file\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(f\"âœ“ Model: {MODEL}\")\n",
    "print(f\"âœ“ Temperature: {TEMPERATURE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bf8b9",
   "metadata": {},
   "source": [
    "### Step 3: Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748ec1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Helper functions created\n"
     ]
    }
   ],
   "source": [
    "def call_gpt4(prompt, system_prompt=\"You are a helpful AI assistant.\", temperature=0):\n",
    "    \"\"\"\n",
    "    Wrapper for GPT-4 API calls\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): User prompt\n",
    "        system_prompt (str): System prompt\n",
    "        temperature (float): Sampling temperature\n",
    "    \n",
    "    Returns:\n",
    "        dict: Response with content and metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"total_tokens\": response.usage.total_tokens\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": f\"Error: {str(e)}\",\n",
    "            \"total_tokens\": 0\n",
    "        }\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get text embedding for similarity comparison\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to embed\n",
    "    \n",
    "    Returns:\n",
    "        List[float]: Embedding vector\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding error: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two texts\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): First text\n",
    "        text2 (str): Second text\n",
    "    \n",
    "    Returns:\n",
    "        float: Similarity score (0-1)\n",
    "    \"\"\"\n",
    "    emb1 = get_embedding(text1)\n",
    "    emb2 = get_embedding(text2)\n",
    "    \n",
    "    if not emb1 or not emb2:\n",
    "        return 0.0\n",
    "    \n",
    "    similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "    return float(similarity)\n",
    "\n",
    "def evaluate_classification(predictions: List[str], ground_truth: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate classification accuracy metrics\n",
    "    \n",
    "    Args:\n",
    "        predictions (List[str]): Predicted labels\n",
    "        ground_truth (List[str]): True labels\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Accuracy metrics\n",
    "    \"\"\"\n",
    "    correct = sum(1 for pred, true in zip(predictions, ground_truth) if pred.strip().upper() == true.strip().upper())\n",
    "    total = len(predictions)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"correct\": correct,\n",
    "        \"total\": total,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"accuracy_pct\": accuracy * 100\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Helper functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7154fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between loan queries: 0.5692\n",
      "Similarity between loan and balance queries: 0.2500\n",
      "Similarity between similar risk assessments: 0.6678\n",
      "Similarity between risk and fraud texts: 0.2934\n"
     ]
    }
   ],
   "source": [
    "# Example: Calculate similarity between two customer queries\n",
    "query1 = \"I want to apply for a personal loan\"\n",
    "query2 = \"How can I get a home loan?\"\n",
    "query3 = \"What is my account balance?\"\n",
    "\n",
    "# Calculate similarity between similar queries (both about loans)\n",
    "similarity_score_1 = calculate_similarity(query1, query2)\n",
    "print(f\"Similarity between loan queries: {similarity_score_1:.4f}\")\n",
    "\n",
    "# Calculate similarity between dissimilar queries\n",
    "similarity_score_2 = calculate_similarity(query1, query3)\n",
    "print(f\"Similarity between loan and balance queries: {similarity_score_2:.4f}\")\n",
    "\n",
    "# Example with financial documents\n",
    "doc1 = \"This customer has a stable income and good credit history\"\n",
    "doc2 = \"The applicant shows consistent earnings and excellent credit score\"\n",
    "doc3 = \"The transaction was flagged for potential fraud\"\n",
    "\n",
    "similarity_score_3 = calculate_similarity(doc1, doc2)\n",
    "print(f\"Similarity between similar risk assessments: {similarity_score_3:.4f}\")\n",
    "\n",
    "similarity_score_4 = calculate_similarity(doc1, doc3)\n",
    "print(f\"Similarity between risk and fraud texts: {similarity_score_4:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa76feb",
   "metadata": {},
   "source": [
    "### Step 4: Test Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a680b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection and embedding function\n",
    "test = call_gpt4(\"Say 'Ready for few-shot learning' if you receive this.\")\n",
    "print(f\"Response: {test['content']}\")\n",
    "\n",
    "# Test embedding\n",
    "test_embedding = get_embedding(\"test sentence\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "print(\"\\nâœ“ Connection verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eb3937",
   "metadata": {},
   "source": [
    "## FEW-SHOT LEARNING THEORY\n",
    "\n",
    "### What is Few-Shot Learning?\n",
    "\n",
    "Few-shot learning teaches the model a task by providing examples in the prompt. Instead of explaining rules, you **show** the pattern through examples.\n",
    "\n",
    "**Zero-shot (No examples):**\n",
    "```\n",
    "Classify this email as URGENT or ROUTINE:\n",
    "\"Meeting at 3pm tomorrow\"\n",
    "```\n",
    "\n",
    "**Few-shot (With examples):**\n",
    "```\n",
    "Classify emails as URGENT or ROUTINE:\n",
    "\n",
    "Example 1: \"Server down, customers affected\" â†’ URGENT\n",
    "Example 2: \"Meeting at 3pm tomorrow\" â†’ ROUTINE\n",
    "Example 3: \"Data breach detected\" â†’ URGENT\n",
    "\n",
    "Now classify: \"Weekly report available\"\n",
    "```\n",
    "\n",
    "### Why Few-Shot Learning Matters for BFSI\n",
    "\n",
    "1. **Domain-specific patterns** - Banking/finance has unique terminology\n",
    "2. **No fine-tuning needed** - Fast deployment, no ML expertise required\n",
    "3. **Adaptable** - Easy to update examples as requirements change\n",
    "4. **Explainable** - Examples serve as documentation\n",
    "5. **Token-efficient** - Better than long rule descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac756c3c",
   "metadata": {},
   "source": [
    "## CHALLENGE 1: BASIC FEW-SHOT PATTERNS\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Learn fundamental few-shot pattern construction\n",
    "\n",
    "### Background\n",
    "\n",
    "The bank needs to classify customer service inquiries into categories to route them to the right department. Currently using rule-based keywords, but it's failing on edge cases.\n",
    "\n",
    "### Categories\n",
    "\n",
    "- **CARD_SERVICES**: Credit/debit card issues, PIN, ATM, card activation\n",
    "- **LENDING**: Loans, mortgages, credit applications\n",
    "- **FRAUD**: Suspicious activity, unauthorized transactions\n",
    "- **ACCOUNT_INQUIRY**: Balance, statements, transaction history\n",
    "- **GENERAL**: Everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec8c03",
   "metadata": {},
   "source": [
    "### Current Approach (Rule-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE: Rule-based keyword matching (what they're replacing)\n",
    "\n",
    "def rule_based_classifier(text: str) -> str:\n",
    "    \"\"\"Simple keyword-based classification\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    if any(word in text_lower for word in [\"card\", \"atm\", \"pin\", \"chip\"]):\n",
    "        return \"CARD_SERVICES\"\n",
    "    elif any(word in text_lower for word in [\"loan\", \"mortgage\", \"credit\"]):\n",
    "        return \"LENDING\"\n",
    "    elif any(word in text_lower for word in [\"fraud\", \"suspicious\", \"unauthorized\"]):\n",
    "        return \"FRAUD\"\n",
    "    elif any(word in text_lower for word in [\"balance\", \"statement\", \"transaction\"]):\n",
    "        return \"ACCOUNT_INQUIRY\"\n",
    "    else:\n",
    "        return \"GENERAL\"\n",
    "\n",
    "# Test cases\n",
    "test_queries = [\n",
    "    \"My card was declined at the store\",\n",
    "    \"I want to apply for a home loan\",\n",
    "    \"There's a charge I don't recognize\",\n",
    "    \"What's my current balance?\",\n",
    "    \"Can I get a credit limit increase?\"\n",
    "]\n",
    "\n",
    "print(\"RULE-BASED CLASSIFICATION:\")\n",
    "print(\"=\" * 80)\n",
    "for query in test_queries:\n",
    "    result = rule_based_classifier(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Classification: {result}\\n\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327068c4",
   "metadata": {},
   "source": [
    "**Problems with rule-based:**\n",
    "- âŒ Last query: \"credit limit increase\" â†’ classified as LENDING (wrong, should be CARD_SERVICES)\n",
    "- âŒ Doesn't handle variations or context\n",
    "- âŒ Requires manual keyword list maintenance\n",
    "- âŒ Brittle - breaks on unexpected phrasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b75cd8d",
   "metadata": {},
   "source": [
    "### Student Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a few-shot classification prompt\n",
    "# Requirements:\n",
    "# - Include 2-3 examples per category\n",
    "# - Clear, diverse examples\n",
    "# - Consistent format\n",
    "\n",
    "few_shot_prompt = \"\"\"\n",
    "[WRITE YOUR FEW-SHOT PROMPT HERE]\n",
    "\n",
    "Now classify: {query}\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Test your prompt\n",
    "# for query in test_queries:\n",
    "#     response = call_gpt4(few_shot_prompt.format(query=query))\n",
    "#     print(f\"Query: {query}\")\n",
    "#     print(f\"Classification: {response['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf82b6",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da25ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Well-structured few-shot prompt\n",
    "\n",
    "few_shot_prompt_v1 = \"\"\"\n",
    "Classify customer service inquiries into these categories:\n",
    "- CARD_SERVICES: Credit/debit card issues\n",
    "- LENDING: Loans, mortgages, credit applications  \n",
    "- FRAUD: Suspicious or unauthorized activity\n",
    "- ACCOUNT_INQUIRY: Balance, statements, transactions\n",
    "- GENERAL: Other inquiries\n",
    "\n",
    "Examples:\n",
    "\n",
    "Input: \"My card was declined at the grocery store\"\n",
    "Output: CARD_SERVICES\n",
    "\n",
    "Input: \"I forgot my PIN number\"\n",
    "Output: CARD_SERVICES\n",
    "\n",
    "Input: \"I want to apply for a mortgage\"\n",
    "Output: LENDING\n",
    "\n",
    "Input: \"What interest rate can I get on a car loan?\"\n",
    "Output: LENDING\n",
    "\n",
    "Input: \"There's a $500 charge I didn't make\"\n",
    "Output: FRAUD\n",
    "\n",
    "Input: \"Someone tried to use my card in another country\"\n",
    "Output: FRAUD\n",
    "\n",
    "Input: \"What's my account balance?\"\n",
    "Output: ACCOUNT_INQUIRY\n",
    "\n",
    "Input: \"Can I download my last 3 months of statements?\"\n",
    "Output: ACCOUNT_INQUIRY\n",
    "\n",
    "Input: \"What are your branch hours?\"\n",
    "Output: GENERAL\n",
    "\n",
    "Now classify this inquiry:\n",
    "Input: {query}\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_v1 = \"You are a customer service inquiry classifier. Output only the category name.\"\n",
    "\n",
    "# Test the few-shot prompt\n",
    "print(\"FEW-SHOT CLASSIFICATION:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for query in test_queries:\n",
    "    response = call_gpt4(few_shot_prompt_v1.format(query=query), system_prompt_v1)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Classification: {response['content']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96b1d9",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a49627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare rule-based vs few-shot\n",
    "\n",
    "ground_truth = [\"CARD_SERVICES\", \"LENDING\", \"FRAUD\", \"ACCOUNT_INQUIRY\", \"CARD_SERVICES\"]\n",
    "\n",
    "# Rule-based predictions\n",
    "rule_predictions = [rule_based_classifier(q) for q in test_queries]\n",
    "\n",
    "# Few-shot predictions\n",
    "few_shot_predictions = []\n",
    "for query in test_queries:\n",
    "    response = call_gpt4(few_shot_prompt_v1.format(query=query), system_prompt_v1)\n",
    "    few_shot_predictions.append(response['content'].strip())\n",
    "\n",
    "# Evaluate\n",
    "rule_metrics = evaluate_classification(rule_predictions, ground_truth)\n",
    "few_shot_metrics = evaluate_classification(few_shot_predictions, ground_truth)\n",
    "\n",
    "print(\"\\nCOMPARISON:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Rule-based accuracy: {rule_metrics['accuracy_pct']:.1f}% ({rule_metrics['correct']}/{rule_metrics['total']})\")\n",
    "print(f\"Few-shot accuracy: {few_shot_metrics['accuracy_pct']:.1f}% ({few_shot_metrics['correct']}/{few_shot_metrics['total']})\")\n",
    "print(f\"Improvement: +{few_shot_metrics['accuracy_pct'] - rule_metrics['accuracy_pct']:.1f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e2939",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "âœ“ **Examples teach patterns** - Model learns from demonstrations  \n",
    "âœ“ **Consistent format** - Use same Input/Output structure  \n",
    "âœ“ **Coverage** - Include examples for each category  \n",
    "âœ“ **Clarity** - Examples should be unambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012e31b",
   "metadata": {},
   "source": [
    "## CHALLENGE 2: EXAMPLE SELECTION STRATEGY\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Learn which examples matter most\n",
    "\n",
    "### Background\n",
    "\n",
    "You have 50+ example customer inquiries. Including all of them would exceed token limits. How do you choose the BEST examples to include?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb998e",
   "metadata": {},
   "source": [
    "### Example Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large library of labeled examples\n",
    "example_library = [\n",
    "    # CARD_SERVICES examples\n",
    "    {\"text\": \"My card was declined\", \"label\": \"CARD_SERVICES\"},\n",
    "    {\"text\": \"I lost my credit card\", \"label\": \"CARD_SERVICES\"},\n",
    "    {\"text\": \"My chip isn't working\", \"label\": \"CARD_SERVICES\"},\n",
    "    {\"text\": \"I need to activate my new card\", \"label\": \"CARD_SERVICES\"},\n",
    "    {\"text\": \"ATM didn't give me cash but charged my account\", \"label\": \"CARD_SERVICES\"},\n",
    "    {\"text\": \"Can I increase my credit limit?\", \"label\": \"CARD_SERVICES\"},\n",
    "    {\"text\": \"My card expired, when will I get a new one?\", \"label\": \"CARD_SERVICES\"},\n",
    "    \n",
    "    # LENDING examples\n",
    "    {\"text\": \"I want to apply for a mortgage\", \"label\": \"LENDING\"},\n",
    "    {\"text\": \"What's the interest rate on personal loans?\", \"label\": \"LENDING\"},\n",
    "    {\"text\": \"How much can I borrow for a car?\", \"label\": \"LENDING\"},\n",
    "    {\"text\": \"I want to refinance my home\", \"label\": \"LENDING\"},\n",
    "    {\"text\": \"What documents do I need for a business loan?\", \"label\": \"LENDING\"},\n",
    "    {\"text\": \"Can I get pre-approved for a mortgage?\", \"label\": \"LENDING\"},\n",
    "    \n",
    "    # FRAUD examples\n",
    "    {\"text\": \"I see charges I didn't make\", \"label\": \"FRAUD\"},\n",
    "    {\"text\": \"Someone used my card in another state\", \"label\": \"FRAUD\"},\n",
    "    {\"text\": \"There's a suspicious withdrawal\", \"label\": \"FRAUD\"},\n",
    "    {\"text\": \"I think my account was hacked\", \"label\": \"FRAUD\"},\n",
    "    {\"text\": \"Unauthorized transfer from my account\", \"label\": \"FRAUD\"},\n",
    "    \n",
    "    # ACCOUNT_INQUIRY examples\n",
    "    {\"text\": \"What's my balance?\", \"label\": \"ACCOUNT_INQUIRY\"},\n",
    "    {\"text\": \"Can I get my transaction history?\", \"label\": \"ACCOUNT_INQUIRY\"},\n",
    "    {\"text\": \"I need last month's statement\", \"label\": \"ACCOUNT_INQUIRY\"},\n",
    "    {\"text\": \"Show me my recent deposits\", \"label\": \"ACCOUNT_INQUIRY\"},\n",
    "    {\"text\": \"Why was I charged a fee?\", \"label\": \"ACCOUNT_INQUIRY\"},\n",
    "    \n",
    "    # GENERAL examples\n",
    "    {\"text\": \"What are your hours?\", \"label\": \"GENERAL\"},\n",
    "    {\"text\": \"Where's the nearest branch?\", \"label\": \"GENERAL\"},\n",
    "    {\"text\": \"Do you have a mobile app?\", \"label\": \"GENERAL\"},\n",
    "    {\"text\": \"How do I update my address?\", \"label\": \"GENERAL\"}\n",
    "]\n",
    "\n",
    "print(f\"Example library size: {len(example_library)} examples\")\n",
    "print(f\"Token limit challenge: Can only include ~15 examples in prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a52c1a",
   "metadata": {},
   "source": [
    "### Selection Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Random selection\n",
    "def select_random(examples: List[Dict], n: int = 15) -> List[Dict]:\n",
    "    \"\"\"Randomly select n examples\"\"\"\n",
    "    import random\n",
    "    return random.sample(examples, min(n, len(examples)))\n",
    "\n",
    "# Strategy 2: Balanced selection (equal per class)\n",
    "def select_balanced(examples: List[Dict], n_per_class: int = 3) -> List[Dict]:\n",
    "    \"\"\"Select n examples from each class\"\"\"\n",
    "    selected = []\n",
    "    labels = set(ex['label'] for ex in examples)\n",
    "    \n",
    "    for label in labels:\n",
    "        class_examples = [ex for ex in examples if ex['label'] == label]\n",
    "        selected.extend(class_examples[:n_per_class])\n",
    "    \n",
    "    return selected\n",
    "\n",
    "# Strategy 3: Diverse selection (maximize variety within class)\n",
    "def select_diverse(examples: List[Dict], n_per_class: int = 3) -> List[Dict]:\n",
    "    \"\"\"Select diverse examples from each class using length variation\"\"\"\n",
    "    selected = []\n",
    "    labels = set(ex['label'] for ex in examples)\n",
    "    \n",
    "    for label in labels:\n",
    "        class_examples = [ex for ex in examples if ex['label'] == label]\n",
    "        # Sort by length to get variety (short, medium, long)\n",
    "        class_examples_sorted = sorted(class_examples, key=lambda x: len(x['text']))\n",
    "        \n",
    "        # Pick from beginning, middle, end to maximize diversity\n",
    "        if len(class_examples_sorted) >= n_per_class:\n",
    "            indices = [0, len(class_examples_sorted)//2, len(class_examples_sorted)-1]\n",
    "            for i in indices[:n_per_class]:\n",
    "                selected.append(class_examples_sorted[i])\n",
    "        else:\n",
    "            selected.extend(class_examples_sorted)\n",
    "    \n",
    "    return selected\n",
    "\n",
    "print(\"âœ“ Selection strategies defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb29e7",
   "metadata": {},
   "source": [
    "### Student Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the three strategies and compare accuracy\n",
    "# Hint: Use the test_queries from Challenge 1 as your test set\n",
    "\n",
    "# Strategy 1: Random\n",
    "# Strategy 2: Balanced  \n",
    "# Strategy 3: Diverse\n",
    "\n",
    "# Which performs best? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f8d1b",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Compare selection strategies\n",
    "\n",
    "def create_few_shot_prompt_from_examples(examples: List[Dict], query: str) -> str:\n",
    "    \"\"\"Create few-shot prompt from selected examples\"\"\"\n",
    "    prompt = \"\"\"Classify customer service inquiries into these categories:\n",
    "- CARD_SERVICES\n",
    "- LENDING\n",
    "- FRAUD\n",
    "- ACCOUNT_INQUIRY\n",
    "- GENERAL\n",
    "\n",
    "Examples:\n",
    "\n",
    "\"\"\"\n",
    "    for ex in examples:\n",
    "        prompt += f'Input: \"{ex[\"text\"]}\"\\n'\n",
    "        prompt += f'Output: {ex[\"label\"]}\\n\\n'\n",
    "    \n",
    "    prompt += f'Now classify:\\nInput: \"{query}\"\\nOutput:'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Test data with ground truth\n",
    "test_data = [\n",
    "    (\"My card was declined at the store\", \"CARD_SERVICES\"),\n",
    "    (\"I want to apply for a home loan\", \"LENDING\"),\n",
    "    (\"There's a charge I don't recognize\", \"FRAUD\"),\n",
    "    (\"What's my current balance?\", \"ACCOUNT_INQUIRY\"),\n",
    "    (\"Can I get a credit limit increase?\", \"CARD_SERVICES\"),\n",
    "    (\"What interest rate for auto loans?\", \"LENDING\"),\n",
    "    (\"Someone withdrew money without permission\", \"FRAUD\"),\n",
    "    (\"I need my tax documents\", \"ACCOUNT_INQUIRY\"),\n",
    "    (\"Where's your nearest ATM?\", \"GENERAL\"),\n",
    "    (\"My PIN is locked\", \"CARD_SERVICES\")\n",
    "]\n",
    "\n",
    "system_prompt = \"You are a classifier. Output only the category name.\"\n",
    "\n",
    "# Test each strategy\n",
    "strategies = {\n",
    "    \"Random\": select_random(example_library, 15),\n",
    "    \"Balanced\": select_balanced(example_library, 3),\n",
    "    \"Diverse\": select_diverse(example_library, 3)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"TESTING SELECTION STRATEGIES:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for strategy_name, selected_examples in strategies.items():\n",
    "    print(f\"\\n{strategy_name} Strategy ({len(selected_examples)} examples):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    for query, true_label in test_data:\n",
    "        prompt = create_few_shot_prompt_from_examples(selected_examples, query)\n",
    "        response = call_gpt4(prompt, system_prompt)\n",
    "        predicted_label = response['content'].strip()\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "        ground_truth.append(true_label)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_classification(predictions, ground_truth)\n",
    "    results[strategy_name] = metrics\n",
    "    \n",
    "    print(f\"Accuracy: {metrics['accuracy_pct']:.1f}% ({metrics['correct']}/{metrics['total']})\")\n",
    "    \n",
    "    # Show misclassifications\n",
    "    misclassified = [(test_data[i][0], predictions[i], ground_truth[i]) \n",
    "                     for i in range(len(predictions)) \n",
    "                     if predictions[i] != ground_truth[i]]\n",
    "    \n",
    "    if misclassified:\n",
    "        print(f\"Misclassifications: {len(misclassified)}\")\n",
    "        for query, pred, true in misclassified:\n",
    "            print(f\"  '{query[:40]}...' â†’ Predicted: {pred}, Actual: {true}\")\n",
    "    else:\n",
    "        print(\"No misclassifications!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nSTRATEGY COMPARISON:\")\n",
    "print(\"=\" * 80)\n",
    "for strategy_name, metrics in results.items():\n",
    "    print(f\"{strategy_name:15} - Accuracy: {metrics['accuracy_pct']:.1f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3de65",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "âœ“ **Balance matters** - Equal examples per class  \n",
    "âœ“ **Diversity within classes** - Show variations  \n",
    "âœ“ **Quality over quantity** - 3 good examples per class > 10 random  \n",
    "âœ“ **Consistency** - Deterministic selection preferable to random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f852671",
   "metadata": {},
   "source": [
    "## CHALLENGE 3: CONTRASTIVE EXAMPLES\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Use negative examples to sharpen classification boundaries\n",
    "\n",
    "### Background\n",
    "\n",
    "The bank's loan risk classifier struggles with **edge cases** - applications that seem risky but aren't, or seem safe but aren't. Contrastive learning (showing both positive and negative examples) helps the model learn boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are intentionally ambiguous/tricky\n",
    "edge_case_applications = [\n",
    "    {\n",
    "        \"description\": \"Recent college graduate, employed 6 months, $45K salary, requesting $200K mortgage\",\n",
    "        \"true_risk\": \"HIGH_RISK\"  # New to workforce, loan too large\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Self-employed 10 years, income varies $60K-$120K annually, excellent credit score 780\",\n",
    "        \"true_risk\": \"LOW_RISK\"  # Established business, great credit\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Salaried $90K, 3 years employed, credit score 620, requesting $15K personal loan\",\n",
    "        \"true_risk\": \"HIGH_RISK\"  # Low credit score is the issue\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Retired, fixed income $50K/year, no debt, owns home outright, requesting $10K\",\n",
    "        \"true_risk\": \"LOW_RISK\"  # Stable, low debt-to-income\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Employed 5 years $75K, credit score 720, has 3 existing loans totaling $80K\",\n",
    "        \"true_risk\": \"HIGH_RISK\"  # Debt burden too high\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b500f",
   "metadata": {},
   "source": [
    "### Approach 1: Positive Examples Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITHOUT contrastive learning - only positive examples\n",
    "\n",
    "positive_only_prompt = \"\"\"\n",
    "Classify loan applications as HIGH_RISK or LOW_RISK.\n",
    "\n",
    "HIGH_RISK examples:\n",
    "- \"Unemployed, poor credit, requesting large loan\"\n",
    "- \"Multiple missed payments, high debt-to-income ratio\"\n",
    "- \"No credit history, first job, large loan request\"\n",
    "\n",
    "LOW_RISK examples:\n",
    "- \"Stable employment 15 years, excellent credit, low debt\"\n",
    "- \"High income, low loan amount, perfect payment history\"\n",
    "- \"Owns assets, no debt, conservative loan request\"\n",
    "\n",
    "Classify: {description}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_positive = \"You are a loan risk assessor. Output only HIGH_RISK or LOW_RISK.\"\n",
    "\n",
    "print(\"POSITIVE-ONLY APPROACH:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "positive_predictions = []\n",
    "for app in edge_case_applications:\n",
    "    response = call_gpt4(\n",
    "        positive_only_prompt.format(description=app['description']),\n",
    "        system_prompt_positive\n",
    "    )\n",
    "    prediction = response['content'].strip()\n",
    "    positive_predictions.append(prediction)\n",
    "    \n",
    "    is_correct = prediction == app['true_risk']\n",
    "    marker = \"âœ“\" if is_correct else \"âœ—\"\n",
    "    \n",
    "    print(f\"\\n{marker} {app['description'][:60]}...\")\n",
    "    print(f\"  Predicted: {prediction}, Actual: {app['true_risk']}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "ground_truth = [app['true_risk'] for app in edge_case_applications]\n",
    "metrics_positive = evaluate_classification(positive_predictions, ground_truth)\n",
    "print(f\"\\nAccuracy: {metrics_positive['accuracy_pct']:.1f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef00e2b",
   "metadata": {},
   "source": [
    "### Student Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a contrastive learning prompt\n",
    "# Requirements:\n",
    "# - Include examples that look similar but have different risk levels\n",
    "# - Explain why the classification differs\n",
    "# - Help model learn decision boundaries\n",
    "\n",
    "contrastive_prompt = \"\"\"\n",
    "[WRITE YOUR CONTRASTIVE LEARNING PROMPT HERE]\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Test and compare to positive-only approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aceeab",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Contrastive learning with boundary examples\n",
    "\n",
    "contrastive_prompt = \"\"\"\n",
    "Classify loan applications as HIGH_RISK or LOW_RISK.\n",
    "\n",
    "CONTRASTIVE EXAMPLES (learn the boundaries):\n",
    "\n",
    "Example 1a: \"Self-employed 2 years, income varies $30K-$80K, credit score 680\"\n",
    "Risk: HIGH_RISK\n",
    "Reason: Recent self-employment, high income volatility, marginal credit\n",
    "\n",
    "Example 1b: \"Self-employed 10 years, income varies $60K-$120K, credit score 780\"\n",
    "Risk: LOW_RISK  \n",
    "Reason: Established business, higher income range, excellent credit\n",
    "\n",
    "Example 2a: \"Recent graduate, 6 months employed, $50K salary, requesting $200K\"\n",
    "Risk: HIGH_RISK\n",
    "Reason: Short employment history, loan far exceeds annual income\n",
    "\n",
    "Example 2b: \"Recent graduate, 2 years employed, $55K salary, requesting $25K\"\n",
    "Risk: LOW_RISK\n",
    "Reason: Reasonable employment duration, loan is manageable relative to income\n",
    "\n",
    "Example 3a: \"Employed 5 years, $80K salary, credit score 625, requesting $20K\"\n",
    "Risk: HIGH_RISK\n",
    "Reason: Credit score below acceptable threshold (650+) despite good income\n",
    "\n",
    "Example 3b: \"Employed 5 years, $80K salary, credit score 720, requesting $20K\"\n",
    "Risk: LOW_RISK\n",
    "Reason: Good credit, stable employment, appropriate loan size\n",
    "\n",
    "Example 4a: \"Retired, $40K fixed income, no savings, requesting $15K\"\n",
    "Risk: HIGH_RISK\n",
    "Reason: Fixed income with no buffer, loan is significant portion of annual income\n",
    "\n",
    "Example 4b: \"Retired, $50K fixed income, no debt, owns home, requesting $10K\"\n",
    "Risk: LOW_RISK\n",
    "Reason: Stable income, assets, low debt burden, conservative loan\n",
    "\n",
    "KEY DECISION FACTORS:\n",
    "- Credit score: <650 = high risk concern\n",
    "- Employment: <2 years = risk factor\n",
    "- Debt-to-income: Existing debt >40% of income = high risk\n",
    "- Loan size: >4x annual income = high risk\n",
    "\n",
    "Now classify: {description}\n",
    "Output format: [HIGH_RISK or LOW_RISK]\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_contrastive = \"\"\"You are a loan risk assessor trained on contrastive examples.\n",
    "You carefully consider boundary cases.\n",
    "You output only HIGH_RISK or LOW_RISK.\"\"\"\n",
    "\n",
    "print(\"CONTRASTIVE LEARNING APPROACH:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "contrastive_predictions = []\n",
    "for app in edge_case_applications:\n",
    "    response = call_gpt4(\n",
    "        contrastive_prompt.format(description=app['description']),\n",
    "        system_prompt_contrastive\n",
    "    )\n",
    "    prediction = response['content'].strip().replace('[','').replace(']','')\n",
    "    contrastive_predictions.append(prediction)\n",
    "    \n",
    "    is_correct = prediction == app['true_risk']\n",
    "    marker = \"âœ“\" if is_correct else \"âœ—\"\n",
    "    \n",
    "    print(f\"\\n{marker} {app['description'][:60]}...\")\n",
    "    print(f\"  Predicted: {prediction}, Actual: {app['true_risk']}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "metrics_contrastive = evaluate_classification(contrastive_predictions, ground_truth)\n",
    "print(f\"\\nAccuracy: {metrics_contrastive['accuracy_pct']:.1f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75889354",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both approaches\n",
    "\n",
    "print(\"\\nCOMPARISON:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Positive-only accuracy:  {metrics_positive['accuracy_pct']:.1f}% ({metrics_positive['correct']}/{metrics_positive['total']})\")\n",
    "print(f\"Contrastive accuracy:    {metrics_contrastive['accuracy_pct']:.1f}% ({metrics_contrastive['correct']}/{metrics_contrastive['total']})\")\n",
    "print(f\"Improvement:             +{metrics_contrastive['accuracy_pct'] - metrics_positive['accuracy_pct']:.1f}%\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nWHY CONTRASTIVE LEARNING WORKS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ“ Shows what makes similar cases different\")\n",
    "print(\"âœ“ Teaches decision boundaries explicitly\")\n",
    "print(\"âœ“ Provides reasoning for classifications\")\n",
    "print(\"âœ“ Helps model discriminate edge cases\")\n",
    "print(\"âœ“ Reduces false positives and false negatives\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b481d12",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "âœ“ **Contrastive pairs** - Show similar inputs with different outputs  \n",
    "âœ“ **Boundary learning** - Teach what separates classes  \n",
    "âœ“ **Reasoning** - Include WHY examples differ  \n",
    "âœ“ **Edge cases** - Perfect for ambiguous situations\n",
    "\n",
    "ðŸ’¡ **When to Use Contrastive Learning:**\n",
    "- Classifications with fuzzy boundaries\n",
    "- High stakes where false positives/negatives are costly\n",
    "- Complex decision criteria\n",
    "- Models struggling with edge cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e340f648",
   "metadata": {},
   "source": [
    "## LAB SUMMARY\n",
    "\n",
    "### Few-Shot Learning Techniques Mastered\n",
    "\n",
    "| Challenge | Technique | Key Benefit | Best For |\n",
    "|-----------|-----------|-------------|----------|\n",
    "| 1 | Basic few-shot | Simple pattern teaching | Clear, distinct categories |\n",
    "| 2 | Balanced selection | Equal class representation | Multi-class problems |\n",
    "| 3 | Contrastive learning | Sharp decision boundaries | Edge cases, ambiguous inputs |\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "Before deploying few-shot learning:\n",
    "\n",
    "- [ ] Examples are high-quality (unambiguous, diverse)\n",
    "- [ ] All classes have equal representation\n",
    "- [ ] Contrastive pairs for boundary cases (if needed)\n",
    "- [ ] Tested multiple example counts\n",
    "- [ ] Measured accuracy vs. token cost trade-off\n",
    "- [ ] Examples documented and version-controlled\n",
    "- [ ] Edge cases covered\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
