{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da398b14",
   "metadata": {},
   "source": [
    "# LAB 2.5: ADVANCED PROMPT CHAINING WITH CONTEXT\n",
    "\n",
    "**Course:** Advanced Prompt Engineering Training  \n",
    "**Session:** Session 2 - Advanced Context Engineering  \n",
    "**Duration:** 50 minutes  \n",
    "**Difficulty:** ⭐⭐⭐⭐⭐  \n",
    "**Type:** Hands-on Multi-Step Workflow Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc3d8e3",
   "metadata": {},
   "source": [
    "## LAB OVERVIEW\n",
    "\n",
    "This lab focuses on **chaining multiple LLM calls** where each step refines context and passes results to the next. You'll learn to:\n",
    "\n",
    "- Build sequential processing chains\n",
    "- Implement parallel execution for efficiency\n",
    "- Create conditional branching logic\n",
    "- Design context refinement workflows\n",
    "- Orchestrate production multi-step pipelines\n",
    "\n",
    "**Scenario:** You're building a loan underwriting workflow. The process requires multiple steps:\n",
    "\n",
    "1. **Extract** key information from application\n",
    "2. **Verify** data consistency across documents\n",
    "3. **Calculate** financial ratios (DTI, DSCR, LTV)\n",
    "4. **Assess** risk based on calculations\n",
    "5. **Generate** final recommendation with explanation\n",
    "\n",
    "**Challenge:** Each step depends on previous steps, but you can't fit everything in one prompt. Use chaining to break down the complex task while maintaining context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afce0c",
   "metadata": {},
   "source": [
    "## LEARNING OBJECTIVES\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "✓ Design sequential prompt chains  \n",
    "✓ Implement parallel processing for speed  \n",
    "✓ Build conditional branching logic  \n",
    "✓ Create context refinement workflows  \n",
    "✓ Orchestrate production chain pipelines  \n",
    "✓ Handle errors and retries in chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ebecd7",
   "metadata": {},
   "source": [
    "## SETUP INSTRUCTIONS\n",
    "\n",
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 2.5: Advanced Prompt Chaining with Context\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional, Callable\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282fd12",
   "metadata": {},
   "source": [
    "### Step 2: Configure Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "MODEL = \"gpt-4\"\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def call_gpt4(prompt: str, system_prompt: str = \"You are a helpful AI assistant.\") -> Dict:\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        return {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"total_tokens\": response.usage.total_tokens,\n",
    "            \"success\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"content\": \"\", \"error\": str(e), \"success\": False}\n",
    "\n",
    "print(f\"✓ Model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5743942",
   "metadata": {},
   "source": [
    "### Step 3: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan application data for testing chains\n",
    "\n",
    "loan_application = {\n",
    "    \"applicant\": \"Martinez Tech Ventures LLC\",\n",
    "    \"loan_amount\": 500000,\n",
    "    \"property_value\": 800000,\n",
    "    \"annual_revenue\": 850000,\n",
    "    \"annual_expenses\": 680000,\n",
    "    \"existing_debt_payment\": 4000,\n",
    "    \"credit_score\": 720,\n",
    "    \"years_in_business\": 4,\n",
    "    \"industry\": \"Software Development\"\n",
    "}\n",
    "\n",
    "print(\"✓ Sample data loaded\")\n",
    "print(f\"\\nApplication Summary:\")\n",
    "print(f\"  Applicant: {loan_application['applicant']}\")\n",
    "print(f\"  Loan Amount: ${loan_application['loan_amount']:,}\")\n",
    "print(f\"  Property Value: ${loan_application['property_value']:,}\")\n",
    "print(f\"  Credit Score: {loan_application['credit_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f9c58",
   "metadata": {},
   "source": [
    "## PROMPT CHAINING FUNDAMENTALS\n",
    "\n",
    "### Why Chain Prompts?\n",
    "\n",
    "**Single Monolithic Prompt:**\n",
    "```python\n",
    "# BAD: Everything in one massive prompt\n",
    "prompt = f\"\"\"\n",
    "Extract info, verify consistency, calculate ratios, assess risk, \n",
    "generate recommendation for: {all_data}\n",
    "\"\"\"\n",
    "# Problem: 10,000+ tokens, unclear logic, hard to debug\n",
    "```\n",
    "\n",
    "**Chained Prompts:**\n",
    "```python\n",
    "# GOOD: Break into steps\n",
    "step1 = extract_information(data)\n",
    "step2 = verify_consistency(step1)\n",
    "step3 = calculate_ratios(step2)\n",
    "step4 = assess_risk(step3)\n",
    "step5 = generate_recommendation(step4)\n",
    "# Benefit: Clear, debuggable, efficient\n",
    "```\n",
    "\n",
    "### Chain Types\n",
    "\n",
    "| Type | Description | Use Case |\n",
    "|------|-------------|----------|\n",
    "| **Sequential** | A → B → C → D | Linear workflows |\n",
    "| **Parallel** | A → [B, C, D] → E | Independent tasks |\n",
    "| **Conditional** | A → if X then B else C | Decision trees |\n",
    "| **Refinement** | A → B → refine(A,B) → C | Iterative improvement |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2450340",
   "metadata": {},
   "source": [
    "## CHALLENGE 1: SEQUENTIAL CHAINING\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Difficulty:** ⭐⭐⭐☆☆  \n",
    "**Objective:** Build a linear multi-step chain\n",
    "\n",
    "### Background\n",
    "\n",
    "Sequential chaining passes output from one step as input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Sequential Chain\n",
    "\n",
    "class SequentialChain:\n",
    "    \"\"\"Linear prompt chain\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.steps_executed = []\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def step_extract(self, data: Dict) -> Dict:\n",
    "        \"\"\"Step 1: Extract key information\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Extract key financial metrics from this loan application.\n",
    "Return as JSON with: loan_amount, ltv_ratio, annual_revenue, annual_profit\n",
    "\n",
    "Application: {json.dumps(data, indent=2)}\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt, \"You are a data extraction specialist.\")\n",
    "        self.total_tokens += result.get('total_tokens', 0)\n",
    "        \n",
    "        if result['success']:\n",
    "            try:\n",
    "                # Parse JSON from response\n",
    "                import re\n",
    "                json_match = re.search(r'\\{.*\\}', result['content'], re.DOTALL)\n",
    "                extracted = json.loads(json_match.group()) if json_match else {}\n",
    "                \n",
    "                self.steps_executed.append({\n",
    "                    'step': 'extract',\n",
    "                    'tokens': result['total_tokens'],\n",
    "                    'output': extracted\n",
    "                })\n",
    "                return extracted\n",
    "            except:\n",
    "                return {}\n",
    "        return {}\n",
    "    \n",
    "    def step_calculate(self, extracted: Dict, original: Dict) -> Dict:\n",
    "        \"\"\"Step 2: Calculate financial ratios\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Calculate these ratios:\n",
    "1. LTV (Loan-to-Value) = loan_amount / property_value\n",
    "2. DSCR (Debt Service Coverage) = (revenue - expenses) / (debt_payment * 12)\n",
    "3. Profit Margin = (revenue - expenses) / revenue\n",
    "\n",
    "Data:\n",
    "- Loan: ${original['loan_amount']}\n",
    "- Property: ${original['property_value']}\n",
    "- Revenue: ${original['annual_revenue']}\n",
    "- Expenses: ${original['annual_expenses']}\n",
    "- Monthly Debt: ${original['existing_debt_payment']}\n",
    "\n",
    "Return as JSON: {{\"ltv\": 0.xx, \"dscr\": 0.xx, \"profit_margin\": 0.xx}}\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt, \"You are a financial analyst.\")\n",
    "        self.total_tokens += result.get('total_tokens', 0)\n",
    "        \n",
    "        if result['success']:\n",
    "            try:\n",
    "                import re\n",
    "                json_match = re.search(r'\\{.*\\}', result['content'], re.DOTALL)\n",
    "                ratios = json.loads(json_match.group()) if json_match else {}\n",
    "                \n",
    "                self.steps_executed.append({\n",
    "                    'step': 'calculate',\n",
    "                    'tokens': result['total_tokens'],\n",
    "                    'output': ratios\n",
    "                })\n",
    "                return ratios\n",
    "            except:\n",
    "                return {}\n",
    "        return {}\n",
    "    \n",
    "    def step_assess(self, ratios: Dict, original: Dict) -> str:\n",
    "        \"\"\"Step 3: Assess risk level\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Assess loan risk based on these metrics:\n",
    "\n",
    "Ratios:\n",
    "- LTV: {ratios.get('ltv', 0):.1%} (target: <75%)\n",
    "- DSCR: {ratios.get('dscr', 0):.2f}x (target: >1.25x)\n",
    "- Profit Margin: {ratios.get('profit_margin', 0):.1%} (target: >10%)\n",
    "\n",
    "Applicant:\n",
    "- Credit Score: {original['credit_score']} (min: 680)\n",
    "- Years in Business: {original['years_in_business']} (min: 2)\n",
    "\n",
    "Classify as: LOW_RISK, MEDIUM_RISK, or HIGH_RISK\n",
    "\n",
    "Return one word only.\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt, \"You are a risk analyst.\")\n",
    "        self.total_tokens += result.get('total_tokens', 0)\n",
    "        \n",
    "        risk = result['content'].strip() if result['success'] else \"UNKNOWN\"\n",
    "        \n",
    "        self.steps_executed.append({\n",
    "            'step': 'assess',\n",
    "            'tokens': result['total_tokens'],\n",
    "            'output': risk\n",
    "        })\n",
    "        return risk\n",
    "    \n",
    "    def step_recommend(self, risk: str, ratios: Dict) -> str:\n",
    "        \"\"\"Step 4: Generate recommendation\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Generate a loan recommendation.\n",
    "\n",
    "Risk Level: {risk}\n",
    "LTV: {ratios.get('ltv', 0):.1%}\n",
    "DSCR: {ratios.get('dscr', 0):.2f}x\n",
    "\n",
    "Recommendation should include:\n",
    "1. Decision (APPROVE, APPROVE_WITH_CONDITIONS, DENY)\n",
    "2. Reasoning (2-3 sentences)\n",
    "3. Conditions (if applicable)\n",
    "\n",
    "Be concise and professional.\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt, \"You are a senior underwriter.\")\n",
    "        self.total_tokens += result.get('total_tokens', 0)\n",
    "        \n",
    "        recommendation = result['content'] if result['success'] else \"Unable to generate recommendation\"\n",
    "        \n",
    "        self.steps_executed.append({\n",
    "            'step': 'recommend',\n",
    "            'tokens': result['total_tokens'],\n",
    "            'output': recommendation\n",
    "        })\n",
    "        return recommendation\n",
    "    \n",
    "    def execute(self, data: Dict) -> Dict:\n",
    "        \"\"\"Execute full chain\"\"\"\n",
    "        # Step 1: Extract\n",
    "        extracted = self.step_extract(data)\n",
    "        \n",
    "        # Step 2: Calculate\n",
    "        ratios = self.step_calculate(extracted, data)\n",
    "        \n",
    "        # Step 3: Assess\n",
    "        risk = self.step_assess(ratios, data)\n",
    "        \n",
    "        # Step 4: Recommend\n",
    "        recommendation = self.step_recommend(risk, ratios)\n",
    "        \n",
    "        return {\n",
    "            'extracted': extracted,\n",
    "            'ratios': ratios,\n",
    "            'risk': risk,\n",
    "            'recommendation': recommendation,\n",
    "            'steps_executed': len(self.steps_executed),\n",
    "            'total_tokens': self.total_tokens\n",
    "        }\n",
    "\n",
    "print(\"✓ SequentialChain class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36188ca4",
   "metadata": {},
   "source": [
    "### Test Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f15df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sequential chain\n",
    "print(\"SEQUENTIAL CHAIN:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "chain = SequentialChain()\n",
    "result = chain.execute(loan_application)\n",
    "\n",
    "print(f\"\\nAPPLICATION: {loan_application['applicant']}\")\n",
    "print(f\"\\nRATIOS:\")\n",
    "for key, value in result['ratios'].items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key.upper()}: {value:.2%}\" if value < 1 else f\"  {key.upper()}: {value:.2f}x\")\n",
    "\n",
    "print(f\"\\nRISK LEVEL: {result['risk']}\")\n",
    "print(f\"\\nRECOMMENDATION:\")\n",
    "print(result['recommendation'])\n",
    "\n",
    "print(f\"\\nCHAIN METRICS:\")\n",
    "print(f\"  Steps: {result['steps_executed']}\")\n",
    "print(f\"  Total Tokens: {result['total_tokens']}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40746490",
   "metadata": {},
   "source": [
    "## CHALLENGE 2: PARALLEL PROCESSING CHAINS\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Difficulty:** ⭐⭐⭐⭐☆  \n",
    "**Objective:** Execute independent tasks in parallel\n",
    "\n",
    "### Background\n",
    "\n",
    "Some tasks don't depend on each other and can run simultaneously for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Parallel Processing\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "class ParallelChain:\n",
    "    \"\"\"Execute independent tasks in parallel\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def analyze_credit(self, data: Dict) -> Dict:\n",
    "        \"\"\"Parallel task 1: Credit analysis\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Analyze creditworthiness:\n",
    "- Credit Score: {data['credit_score']}\n",
    "- Years in Business: {data['years_in_business']}\n",
    "- Industry: {data['industry']}\n",
    "\n",
    "Return: STRONG, ACCEPTABLE, or WEAK\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        return {\n",
    "            'task': 'credit',\n",
    "            'assessment': result['content'].strip() if result['success'] else 'UNKNOWN',\n",
    "            'tokens': result.get('total_tokens', 0)\n",
    "        }\n",
    "    \n",
    "    def analyze_financials(self, data: Dict) -> Dict:\n",
    "        \"\"\"Parallel task 2: Financial analysis\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Analyze financial strength:\n",
    "- Revenue: ${data['annual_revenue']}\n",
    "- Expenses: ${data['annual_expenses']}\n",
    "- Profit: ${data['annual_revenue'] - data['annual_expenses']}\n",
    "\n",
    "Return: STRONG, ACCEPTABLE, or WEAK\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        return {\n",
    "            'task': 'financials',\n",
    "            'assessment': result['content'].strip() if result['success'] else 'UNKNOWN',\n",
    "            'tokens': result.get('total_tokens', 0)\n",
    "        }\n",
    "    \n",
    "    def analyze_collateral(self, data: Dict) -> Dict:\n",
    "        \"\"\"Parallel task 3: Collateral analysis\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Analyze collateral adequacy:\n",
    "- Loan: ${data['loan_amount']}\n",
    "- Property Value: ${data['property_value']}\n",
    "- LTV: {data['loan_amount']/data['property_value']:.1%}\n",
    "\n",
    "Return: STRONG, ACCEPTABLE, or WEAK\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        return {\n",
    "            'task': 'collateral',\n",
    "            'assessment': result['content'].strip() if result['success'] else 'UNKNOWN',\n",
    "            'tokens': result.get('total_tokens', 0)\n",
    "        }\n",
    "    \n",
    "    def synthesize(self, parallel_results: List[Dict]) -> str:\n",
    "        \"\"\"Combine parallel results\"\"\"\n",
    "        assessments = {r['task']: r['assessment'] for r in parallel_results}\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Synthesize overall assessment from these analyses:\n",
    "\n",
    "Credit: {assessments.get('credit', 'UNKNOWN')}\n",
    "Financials: {assessments.get('financials', 'UNKNOWN')}\n",
    "Collateral: {assessments.get('collateral', 'UNKNOWN')}\n",
    "\n",
    "Provide overall recommendation (APPROVE/DENY) with reasoning.\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        return result['content'] if result['success'] else 'Unable to synthesize'\n",
    "    \n",
    "    def execute(self, data: Dict) -> Dict:\n",
    "        \"\"\"Execute parallel tasks\"\"\"\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        # Execute parallel tasks\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            futures = {\n",
    "                executor.submit(self.analyze_credit, data): 'credit',\n",
    "                executor.submit(self.analyze_financials, data): 'financials',\n",
    "                executor.submit(self.analyze_collateral, data): 'collateral'\n",
    "            }\n",
    "            \n",
    "            parallel_results = []\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                parallel_results.append(future.result())\n",
    "        \n",
    "        parallel_time = time.time() - start\n",
    "        \n",
    "        # Synthesize results\n",
    "        synthesis = self.synthesize(parallel_results)\n",
    "        \n",
    "        total_time = time.time() - start\n",
    "        total_tokens = sum(r['tokens'] for r in parallel_results)\n",
    "        \n",
    "        return {\n",
    "            'parallel_results': parallel_results,\n",
    "            'synthesis': synthesis,\n",
    "            'parallel_time': parallel_time,\n",
    "            'total_time': total_time,\n",
    "            'total_tokens': total_tokens\n",
    "        }\n",
    "\n",
    "print(\"✓ ParallelChain class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d00758",
   "metadata": {},
   "source": [
    "### Test Parallel Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a977f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parallel chain\n",
    "print(\"PARALLEL PROCESSING CHAIN:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "parallel = ParallelChain()\n",
    "result = parallel.execute(loan_application)\n",
    "\n",
    "print(f\"\\nPARALLEL ANALYSES:\")\n",
    "for analysis in result['parallel_results']:\n",
    "    print(f\"  {analysis['task'].upper()}: {analysis['assessment']}\")\n",
    "\n",
    "print(f\"\\nSYNTHESIS:\")\n",
    "print(result['synthesis'])\n",
    "\n",
    "print(f\"\\nPERFORMANCE:\")\n",
    "print(f\"  Parallel execution: {result['parallel_time']:.2f}s\")\n",
    "print(f\"  Total time: {result['total_time']:.2f}s\")\n",
    "print(f\"  Total tokens: {result['total_tokens']}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7170c09",
   "metadata": {},
   "source": [
    "## CHALLENGE 3: CONDITIONAL BRANCHING\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Difficulty:** ⭐⭐⭐⭐☆  \n",
    "**Objective:** Build decision trees in chains\n",
    "\n",
    "### Background\n",
    "\n",
    "Different inputs require different processing paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Conditional Branching\n",
    "\n",
    "class ConditionalChain:\n",
    "    \"\"\"Chain with conditional branching logic\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.execution_path = []\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def classify_application(self, data: Dict) -> str:\n",
    "        \"\"\"Classify application type\"\"\"\n",
    "        loan_size = data['loan_amount']\n",
    "        \n",
    "        if loan_size < 100000:\n",
    "            category = \"SMALL_BUSINESS\"\n",
    "        elif loan_size < 500000:\n",
    "            category = \"MEDIUM_BUSINESS\"\n",
    "        else:\n",
    "            category = \"LARGE_COMMERCIAL\"\n",
    "        \n",
    "        self.execution_path.append(f\"Classified as: {category}\")\n",
    "        return category\n",
    "    \n",
    "    def process_small_business(self, data: Dict) -> str:\n",
    "        \"\"\"Simplified process for small loans\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Quick assessment for small business loan:\n",
    "- Amount: ${data['loan_amount']}\n",
    "- Credit: {data['credit_score']}\n",
    "- Business Age: {data['years_in_business']} years\n",
    "\n",
    "Approve if credit > 680 and business age > 2 years.\n",
    "Return: APPROVED or DENIED with brief reason.\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        self.execution_path.append(\"Used simplified process\")\n",
    "        self.total_tokens += result.get('total_tokens', 0)\n",
    "        return result['content'] if result['success'] else 'Error'\n",
    "    \n",
    "    def process_medium_business(self, data: Dict) -> str:\n",
    "        \"\"\"Standard process for medium loans\"\"\"\n",
    "        # Step 1: Financial check\n",
    "        prompt1 = f\"\"\"\n",
    "Check financial viability:\n",
    "Revenue: ${data['annual_revenue']}\n",
    "Expenses: ${data['annual_expenses']}\n",
    "Debt: ${data['existing_debt_payment']}/month\n",
    "\n",
    "Is DSCR > 1.25? Return YES or NO.\n",
    "\"\"\"\n",
    "        result1 = call_gpt4(prompt1)\n",
    "        self.total_tokens += result1.get('total_tokens', 0)\n",
    "        \n",
    "        viable = 'YES' in result1['content'].upper() if result1['success'] else False\n",
    "        \n",
    "        if not viable:\n",
    "            self.execution_path.append(\"Failed financial check\")\n",
    "            return \"DENIED: Insufficient debt service coverage\"\n",
    "        \n",
    "        # Step 2: Full assessment\n",
    "        prompt2 = f\"\"\"\n",
    "Full assessment for ${data['loan_amount']} loan.\n",
    "Credit: {data['credit_score']}, Business: {data['years_in_business']}yr\n",
    "Financials: Viable\n",
    "\n",
    "Recommendation with conditions?\n",
    "\"\"\"\n",
    "        result2 = call_gpt4(prompt2)\n",
    "        self.execution_path.append(\"Completed full assessment\")\n",
    "        self.total_tokens += result2.get('total_tokens', 0)\n",
    "        return result2['content'] if result2['success'] else 'Error'\n",
    "    \n",
    "    def process_large_commercial(self, data: Dict) -> str:\n",
    "        \"\"\"Enhanced process for large loans\"\"\"\n",
    "        # Step 1: Initial screening\n",
    "        if data['credit_score'] < 700:\n",
    "            self.execution_path.append(\"Failed credit threshold\")\n",
    "            return \"DENIED: Large commercial loans require credit score ≥ 700\"\n",
    "        \n",
    "        # Step 2: Detailed analysis\n",
    "        prompt = f\"\"\"\n",
    "Comprehensive analysis for ${data['loan_amount']:,} commercial loan:\n",
    "\n",
    "Financials:\n",
    "- Revenue: ${data['annual_revenue']:,}\n",
    "- Expenses: ${data['annual_expenses']:,}  \n",
    "- Profit: ${data['annual_revenue'] - data['annual_expenses']:,}\n",
    "\n",
    "Credit: {data['credit_score']}\n",
    "Property: ${data['property_value']:,}\n",
    "\n",
    "Provide detailed recommendation with:\n",
    "1. Approval decision\n",
    "2. Required conditions\n",
    "3. Interest rate recommendation\n",
    "4. Monitoring requirements\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        self.execution_path.append(\"Completed enhanced due diligence\")\n",
    "        self.total_tokens += result.get('total_tokens', 0)\n",
    "        return result['content'] if result['success'] else 'Error'\n",
    "    \n",
    "    def execute(self, data: Dict) -> Dict:\n",
    "        \"\"\"Execute conditional chain\"\"\"\n",
    "        # Classify\n",
    "        category = self.classify_application(data)\n",
    "        \n",
    "        # Branch based on classification\n",
    "        if category == \"SMALL_BUSINESS\":\n",
    "            result = self.process_small_business(data)\n",
    "        elif category == \"MEDIUM_BUSINESS\":\n",
    "            result = self.process_medium_business(data)\n",
    "        else:\n",
    "            result = self.process_large_commercial(data)\n",
    "        \n",
    "        return {\n",
    "            'category': category,\n",
    "            'result': result,\n",
    "            'execution_path': self.execution_path,\n",
    "            'total_tokens': self.total_tokens\n",
    "        }\n",
    "\n",
    "print(\"✓ ConditionalChain class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71d0b5",
   "metadata": {},
   "source": [
    "### Test Conditional Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c36be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conditional chain\n",
    "print(\"CONDITIONAL BRANCHING CHAIN:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test with different loan sizes\n",
    "test_cases = [\n",
    "    {**loan_application, 'loan_amount': 75000, 'applicant': 'Small Loan'},\n",
    "    {**loan_application, 'loan_amount': 300000, 'applicant': 'Medium Loan'},\n",
    "    {**loan_application, 'loan_amount': 1000000, 'applicant': 'Large Loan'}\n",
    "]\n",
    "\n",
    "for test_data in test_cases:\n",
    "    print(f\"\\n{test_data['applicant']} (${test_data['loan_amount']:,}):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    chain = ConditionalChain()\n",
    "    result = chain.execute(test_data)\n",
    "    \n",
    "    print(f\"Category: {result['category']}\")\n",
    "    print(f\"Path: {' → '.join(result['execution_path'])}\")\n",
    "    print(f\"Result: {result['result'][:150]}...\")\n",
    "    print(f\"Tokens: {result['total_tokens']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdebfda",
   "metadata": {},
   "source": [
    "## CHALLENGE 4: CONTEXT REFINEMENT CHAINS\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Difficulty:** ⭐⭐⭐⭐☆  \n",
    "**Objective:** Iteratively refine output quality\n",
    "\n",
    "### Background\n",
    "\n",
    "Some tasks benefit from refinement: initial draft → critique → improved version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b27fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Context Refinement Chain\n",
    "\n",
    "class RefinementChain:\n",
    "    \"\"\"Iterative refinement workflow\"\"\"\n",
    "    \n",
    "    def __init__(self, max_iterations: int = 2):\n",
    "        self.max_iterations = max_iterations\n",
    "        self.iterations = []\n",
    "    \n",
    "    def generate_initial(self, data: Dict) -> str:\n",
    "        \"\"\"Generate initial recommendation\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Generate loan recommendation for:\n",
    "- Applicant: {data['applicant']}\n",
    "- Amount: ${data['loan_amount']:,}\n",
    "- Credit: {data['credit_score']}\n",
    "- LTV: {data['loan_amount']/data['property_value']:.1%}\n",
    "\n",
    "Provide recommendation.\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        output = result['content'] if result['success'] else ''\n",
    "        \n",
    "        self.iterations.append({\n",
    "            'iteration': 0,\n",
    "            'type': 'initial',\n",
    "            'output': output,\n",
    "            'tokens': result.get('total_tokens', 0)\n",
    "        })\n",
    "        return output\n",
    "    \n",
    "    def critique(self, recommendation: str) -> Dict:\n",
    "        \"\"\"Critique current version\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Critique this loan recommendation:\n",
    "\n",
    "{recommendation}\n",
    "\n",
    "Identify:\n",
    "1. Missing information\n",
    "2. Unclear statements\n",
    "3. Areas needing more detail\n",
    "\n",
    "Return JSON: {{\"issues\": [\"issue1\", \"issue2\", ...], \"score\": 0-10}}\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        \n",
    "        if result['success']:\n",
    "            try:\n",
    "                import re\n",
    "                json_match = re.search(r'\\{.*\\}', result['content'], re.DOTALL)\n",
    "                critique = json.loads(json_match.group()) if json_match else {'issues': [], 'score': 5}\n",
    "            except:\n",
    "                critique = {'issues': [], 'score': 5}\n",
    "        else:\n",
    "            critique = {'issues': [], 'score': 5}\n",
    "        \n",
    "        self.iterations.append({\n",
    "            'type': 'critique',\n",
    "            'output': critique,\n",
    "            'tokens': result.get('total_tokens', 0)\n",
    "        })\n",
    "        return critique\n",
    "    \n",
    "    def refine(self, original: str, critique: Dict) -> str:\n",
    "        \"\"\"Refine based on critique\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Improve this recommendation based on critique:\n",
    "\n",
    "ORIGINAL:\n",
    "{original}\n",
    "\n",
    "ISSUES TO ADDRESS:\n",
    "{json.dumps(critique.get('issues', []), indent=2)}\n",
    "\n",
    "Provide improved version.\n",
    "\"\"\"\n",
    "        result = call_gpt4(prompt)\n",
    "        output = result['content'] if result['success'] else original\n",
    "        \n",
    "        self.iterations.append({\n",
    "            'type': 'refinement',\n",
    "            'output': output,\n",
    "            'tokens': result.get('total_tokens', 0)\n",
    "        })\n",
    "        return output\n",
    "    \n",
    "    def execute(self, data: Dict) -> Dict:\n",
    "        \"\"\"Execute refinement chain\"\"\"\n",
    "        # Initial generation\n",
    "        output = self.generate_initial(data)\n",
    "        \n",
    "        # Refinement iterations\n",
    "        for i in range(self.max_iterations):\n",
    "            critique = self.critique(output)\n",
    "            \n",
    "            # Stop if quality is good enough\n",
    "            if critique.get('score', 0) >= 8:\n",
    "                break\n",
    "            \n",
    "            output = self.refine(output, critique)\n",
    "        \n",
    "        total_tokens = sum(iter['tokens'] for iter in self.iterations)\n",
    "        \n",
    "        return {\n",
    "            'final_output': output,\n",
    "            'iterations': len([i for i in self.iterations if i['type'] != 'critique']),\n",
    "            'refinement_steps': self.iterations,\n",
    "            'total_tokens': total_tokens\n",
    "        }\n",
    "\n",
    "print(\"✓ RefinementChain class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8961877",
   "metadata": {},
   "source": [
    "### Test Refinement Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test refinement chain\n",
    "print(\"CONTEXT REFINEMENT CHAIN:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "refiner = RefinementChain(max_iterations=2)\n",
    "result = refiner.execute(loan_application)\n",
    "\n",
    "print(f\"\\nREFINEMENT PROCESS:\")\n",
    "for i, step in enumerate(result['refinement_steps']):\n",
    "    print(f\"\\nStep {i+1}: {step['type'].upper()}\")\n",
    "    if step['type'] == 'critique':\n",
    "        print(f\"  Score: {step['output'].get('score', 'N/A')}/10\")\n",
    "        print(f\"  Issues: {len(step['output'].get('issues', []))}\")\n",
    "    else:\n",
    "        print(f\"  Output: {str(step['output'])[:100]}...\")\n",
    "    print(f\"  Tokens: {step['tokens']}\")\n",
    "\n",
    "print(f\"\\nFINAL OUTPUT:\")\n",
    "print(result['final_output'])\n",
    "\n",
    "print(f\"\\nMETRICS:\")\n",
    "print(f\"  Refinement iterations: {result['iterations']}\")\n",
    "print(f\"  Total tokens: {result['total_tokens']}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157d21a",
   "metadata": {},
   "source": [
    "## CHALLENGE 5: PRODUCTION CHAIN ORCHESTRATOR\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Difficulty:** ⭐⭐⭐⭐⭐  \n",
    "**Objective:** Build complete chain management system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Production Chain Orchestrator\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class ChainType(Enum):\n",
    "    SEQUENTIAL = \"sequential\"\n",
    "    PARALLEL = \"parallel\"\n",
    "    CONDITIONAL = \"conditional\"\n",
    "    REFINEMENT = \"refinement\"\n",
    "\n",
    "class ChainOrchestrator:\n",
    "    \"\"\"Production chain management system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chains = {\n",
    "            ChainType.SEQUENTIAL: SequentialChain(),\n",
    "            ChainType.PARALLEL: ParallelChain(),\n",
    "            ChainType.CONDITIONAL: ConditionalChain(),\n",
    "            ChainType.REFINEMENT: RefinementChain()\n",
    "        }\n",
    "        self.execution_log = []\n",
    "    \n",
    "    def execute_chain(\n",
    "        self,\n",
    "        chain_type: ChainType,\n",
    "        data: Dict,\n",
    "        **kwargs\n",
    "    ) -> Dict:\n",
    "        \"\"\"Execute specified chain type\"\"\"\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        chain = self.chains[chain_type]\n",
    "        result = chain.execute(data)\n",
    "        \n",
    "        execution_time = time.time() - start\n",
    "        \n",
    "        log_entry = {\n",
    "            'chain_type': chain_type.value,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'execution_time': execution_time,\n",
    "            'success': True,\n",
    "            'tokens': result.get('total_tokens', 0)\n",
    "        }\n",
    "        self.execution_log.append(log_entry)\n",
    "        \n",
    "        result['execution_time'] = execution_time\n",
    "        result['chain_type'] = chain_type.value\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get orchestrator statistics\"\"\"\n",
    "        if not self.execution_log:\n",
    "            return {'total_executions': 0}\n",
    "        \n",
    "        return {\n",
    "            'total_executions': len(self.execution_log),\n",
    "            'total_tokens': sum(log['tokens'] for log in self.execution_log),\n",
    "            'avg_execution_time': sum(log['execution_time'] for log in self.execution_log) / len(self.execution_log),\n",
    "            'chains_used': list(set(log['chain_type'] for log in self.execution_log))\n",
    "        }\n",
    "\n",
    "print(\"✓ ChainOrchestrator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48425b1b",
   "metadata": {},
   "source": [
    "### Test Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test orchestrator\n",
    "print(\"PRODUCTION CHAIN ORCHESTRATOR:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "orchestrator = ChainOrchestrator()\n",
    "\n",
    "# Execute different chains\n",
    "print(\"\\nExecuting chains...\")\n",
    "\n",
    "results = {}\n",
    "for chain_type in ChainType:\n",
    "    print(f\"\\n  {chain_type.value}...\", end='')\n",
    "    result = orchestrator.execute_chain(chain_type, loan_application)\n",
    "    results[chain_type.value] = result\n",
    "    print(f\" ✓ ({result['execution_time']:.2f}s, {result.get('total_tokens', 0)} tokens)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95682e",
   "metadata": {},
   "source": [
    "### Chain Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c56d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary\n",
    "print(\"\\nCHAIN COMPARISON:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Chain': ct.value,\n",
    "        'Time (s)': f\"{results[ct.value]['execution_time']:.2f}\",\n",
    "        'Tokens': results[ct.value].get('total_tokens', 0),\n",
    "        'Steps': results[ct.value].get('steps_executed', results[ct.value].get('iterations', 'N/A'))\n",
    "    }\n",
    "    for ct in ChainType\n",
    "])\n",
    "\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39030cc6",
   "metadata": {},
   "source": [
    "### Orchestrator Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9972639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orchestrator stats\n",
    "print(\"\\nORCHESTRATOR STATISTICS:\")\n",
    "print(\"=\" * 80)\n",
    "stats = orchestrator.get_stats()\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7073a",
   "metadata": {},
   "source": [
    "## LAB SUMMARY\n",
    "\n",
    "### Chain Patterns Mastered\n",
    "\n",
    "| Pattern | Best For | Complexity | Token Efficiency |\n",
    "|---------|----------|------------|------------------|\n",
    "| **Sequential** | Linear workflows | ⭐⭐⭐☆☆ | High |\n",
    "| **Parallel** | Independent tasks | ⭐⭐⭐⭐☆ | High |\n",
    "| **Conditional** | Decision trees | ⭐⭐⭐⭐☆ | Highest |\n",
    "| **Refinement** | Quality improvement | ⭐⭐⭐⭐☆ | Medium |\n",
    "\n",
    "### When to Use Each Pattern\n",
    "\n",
    "```\n",
    "Use Sequential when:\n",
    "- Steps have clear dependencies\n",
    "- Output of step N is input to step N+1\n",
    "- Example: Extract → Calculate → Assess → Recommend\n",
    "\n",
    "Use Parallel when:\n",
    "- Tasks are independent\n",
    "- Speed matters\n",
    "- Example: Credit check + Financial analysis + Collateral check\n",
    "\n",
    "Use Conditional when:\n",
    "- Different inputs need different processing\n",
    "- Want to optimize based on criteria\n",
    "- Example: Small/Medium/Large loan routing\n",
    "\n",
    "Use Refinement when:\n",
    "- Output quality is critical\n",
    "- Initial attempt may be insufficient\n",
    "- Example: Report generation, recommendations\n",
    "```\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "- [x] Identify which chain pattern fits your workflow\n",
    "- [x] Design clear step boundaries\n",
    "- [x] Handle errors at each step\n",
    "- [x] Log execution for debugging\n",
    "- [x] Monitor token usage per step\n",
    "- [x] Set timeouts for each step\n",
    "- [x] Implement retries for failures\n",
    "- [x] Test with edge cases\n",
    "- [x] Measure end-to-end performance\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "✓ **Sequential chains** - Simple, linear, debuggable workflows  \n",
    "✓ **Parallel processing** - 3x speed improvement for independent tasks  \n",
    "✓ **Conditional branching** - Route processing based on input characteristics  \n",
    "✓ **Refinement loops** - Iteratively improve output quality  \n",
    "✓ **Production orchestration** - Unified system for all chain types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6c19d",
   "metadata": {},
   "source": [
    "## NEXT STEPS\n",
    "\n",
    "**Lab 2.6: Context-Aware Q&A System (Capstone)** - Bringing all Session 2 techniques together in a complete production system.\n",
    "\n",
    "**Apply these techniques to:**\n",
    "- Complex multi-step workflows\n",
    "- Loan underwriting and approval processes\n",
    "- Document analysis pipelines\n",
    "- Quality assurance systems\n",
    "- Any task requiring multiple LLM calls with context passing\n",
    "\n",
    "---\n",
    "\n",
    "**End of Lab 2.5**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
