{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598f761b",
   "metadata": {},
   "source": [
    "# LAB 1.2: PROMPT DEBUGGING AND OPTIMIZATION\n",
    "\n",
    "**Course:** Advanced Prompt Engineering Training  \n",
    "**Session:** Session 1 - Prompt Engineering Fundamentals Review  \n",
    "**Duration:** 50 minutes  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ  \n",
    "**Type:** Hands-on Debugging & A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c53b4f9",
   "metadata": {},
   "source": [
    "## LAB OVERVIEW\n",
    "\n",
    "This lab focuses on **systematic prompt debugging and optimization**. You'll work with broken or suboptimal prompts used in BFSI fraud detection scenarios and learn to:\n",
    "\n",
    "- Identify root causes of prompt failures\n",
    "- Apply systematic debugging techniques\n",
    "- Optimize prompts for accuracy, consistency, and cost\n",
    "- Conduct rigorous A/B testing\n",
    "- Measure and compare prompt performance\n",
    "\n",
    "**Scenario:** You're a prompt engineer at a financial institution. The fraud detection team has been using AI to analyze suspicious transactions, but they're getting inconsistent results, hallucinations, and high false positive rates. Your job is to debug and optimize their prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575ad76",
   "metadata": {},
   "source": [
    "## LEARNING OBJECTIVES\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "‚úì Diagnose common prompt failure patterns  \n",
    "‚úì Apply systematic debugging methodology  \n",
    "‚úì Optimize prompts for accuracy and consistency  \n",
    "‚úì Conduct quantitative A/B testing  \n",
    "‚úì Measure performance improvements objectively  \n",
    "‚úì Balance accuracy, cost, and latency trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e6628",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e776f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 1.2: Prompt Debugging and Optimization\n",
    "# Advanced Prompt Engineering Training - Session 1\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "print(\"‚úì Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd098acb",
   "metadata": {},
   "source": [
    "### Step 2: Configure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acbd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configuration\n",
    "MODEL = os.getenv(\"MODEL_NAME\")\n",
    "TEMPERATURE = 0  # Deterministic for consistent debugging\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found. Please set it in .env file\")\n",
    "\n",
    "if not MODEL:\n",
    "    raise ValueError(\"MODEL_NAME not found. Please set it in .env file\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(f\"‚úì Model: {MODEL}\")\n",
    "print(f\"‚úì Temperature: {TEMPERATURE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde27c2",
   "metadata": {},
   "source": [
    "### Step 3: Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt4(prompt, system_prompt=\"You are a helpful AI assistant.\", temperature=0):\n",
    "    \"\"\"\n",
    "    Wrapper for GPT-4 API calls with token tracking\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): User prompt\n",
    "        system_prompt (str): System prompt\n",
    "        temperature (float): Sampling temperature\n",
    "    \n",
    "    Returns:\n",
    "        dict: Response with content, tokens, and latency\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        latency = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "            \"completion_tokens\": response.usage.completion_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens,\n",
    "            \"latency\": latency\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": f\"Error: {str(e)}\",\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"latency\": 0\n",
    "        }\n",
    "\n",
    "def compare_prompts(prompt_a, prompt_b, test_cases, system_prompt=\"You are a helpful AI assistant.\"):\n",
    "    \"\"\"\n",
    "    A/B test two prompts against multiple test cases\n",
    "    \n",
    "    Args:\n",
    "        prompt_a (str): First prompt (baseline)\n",
    "        prompt_b (str): Second prompt (optimized)\n",
    "        test_cases (list): List of test inputs\n",
    "        system_prompt (str): System prompt\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Comparison results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        # Test Prompt A\n",
    "        response_a = call_gpt4(prompt_a.format(**test_case), system_prompt)\n",
    "        \n",
    "        # Test Prompt B\n",
    "        response_b = call_gpt4(prompt_b.format(**test_case), system_prompt)\n",
    "        \n",
    "        results.append({\n",
    "            \"test_case\": i + 1,\n",
    "            \"input\": str(test_case),\n",
    "            \"response_a\": response_a[\"content\"],\n",
    "            \"response_b\": response_b[\"content\"],\n",
    "            \"tokens_a\": response_a[\"total_tokens\"],\n",
    "            \"tokens_b\": response_b[\"total_tokens\"],\n",
    "            \"latency_a\": response_a[\"latency\"],\n",
    "            \"latency_b\": response_b[\"latency\"]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"‚úì Helper functions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d50f06",
   "metadata": {},
   "source": [
    "### Step 4: Test Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection\n",
    "test = call_gpt4(\"Say 'Ready for debugging' if you receive this.\")\n",
    "print(f\"Response: {test['content']}\")\n",
    "print(f\"Tokens used: {test['total_tokens']}\")\n",
    "print(f\"Latency: {test['latency']:.2f}s\")\n",
    "print(\"\\n‚úì Connection verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf65da53",
   "metadata": {},
   "source": [
    "## DEBUGGING METHODOLOGY\n",
    "\n",
    "### The 5-Step Debugging Process\n",
    "\n",
    "When a prompt fails or underperforms, follow this systematic approach:\n",
    "\n",
    "```\n",
    "1. IDENTIFY THE PROBLEM\n",
    "   - What is the actual vs. expected output?\n",
    "   - Is it a consistency issue, accuracy issue, or format issue?\n",
    "   - Does it fail on all inputs or specific cases?\n",
    "\n",
    "2. ISOLATE THE ROOT CAUSE\n",
    "   - Vague instructions?\n",
    "   - Missing context?\n",
    "   - Conflicting constraints?\n",
    "   - Model limitations?\n",
    "\n",
    "3. HYPOTHESIZE A FIX\n",
    "   - What specific change should address the root cause?\n",
    "   - Will this change introduce new problems?\n",
    "\n",
    "4. TEST THE FIX\n",
    "   - Run the improved prompt on test cases\n",
    "   - Compare against baseline quantitatively\n",
    "\n",
    "5. VALIDATE & ITERATE\n",
    "   - Does it work consistently across edge cases?\n",
    "   - Are there side effects?\n",
    "   - Can it be further optimized?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151fc02a",
   "metadata": {},
   "source": [
    "## CHALLENGE 1: VAGUE INSTRUCTIONS\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Problem Type:** Unclear output format and inconsistent results\n",
    "\n",
    "### Background\n",
    "\n",
    "The fraud team wrote a prompt to analyze transactions, but results are wildly inconsistent - sometimes one sentence, sometimes paragraphs, sometimes missing key information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde2ed0",
   "metadata": {},
   "source": [
    "### Broken Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BROKEN PROMPT - DO NOT USE AS-IS\n",
    "\n",
    "broken_prompt_v1 = \"\"\"\n",
    "Analyze this transaction for fraud:\n",
    "\n",
    "Transaction: {transaction_details}\n",
    "\n",
    "Is it fraudulent?\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_v1 = \"You are a fraud detection AI.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2c65c",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suspicious transaction test cases\n",
    "test_transactions = [\n",
    "    {\n",
    "        \"transaction_details\": \"Card ending 4523, $2,450 purchase at 'Electronics Warehouse', location: Lagos Nigeria, cardholder location: New York, time: 3:47 AM\"\n",
    "    },\n",
    "    {\n",
    "        \"transaction_details\": \"Card ending 7891, $12.50 purchase at 'Starbucks', location: Seattle WA, cardholder location: Seattle WA, time: 8:15 AM\"\n",
    "    },\n",
    "    {\n",
    "        \"transaction_details\": \"Card ending 3344, $8,900 purchase at 'Luxury Watches International', location: Dubai UAE, cardholder location: London UK, time: 2:30 PM\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead812c1",
   "metadata": {},
   "source": [
    "### Problem Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the broken prompt\n",
    "print(\"BROKEN PROMPT OUTPUT:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test in enumerate(test_transactions):\n",
    "    response = call_gpt4(broken_prompt_v1.format(**test), system_prompt_v1)\n",
    "    print(f\"\\nTest Case {i+1}:\")\n",
    "    print(f\"Input: {test['transaction_details']}\")\n",
    "    print(f\"Output: {response['content']}\")\n",
    "    print(f\"Tokens: {response['total_tokens']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9cdfa",
   "metadata": {},
   "source": [
    "**Problems with this prompt:**\n",
    "1. ‚ùå No output format specified (yes/no? explanation? confidence score?)\n",
    "2. ‚ùå No analysis structure (what factors to consider?)\n",
    "3. ‚ùå Results vary wildly in length and detail\n",
    "4. ‚ùå No guidance on edge cases (what if data is ambiguous?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a7336",
   "metadata": {},
   "source": [
    "### Student Exercise\n",
    "\n",
    "Debug and optimize this prompt to produce consistent, structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9493cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write an improved version of the prompt\n",
    "# Requirements:\n",
    "# - Consistent output format\n",
    "# - Structured analysis\n",
    "# - Specific fraud indicators to check\n",
    "# - Clear decision (Fraudulent / Suspicious / Legitimate)\n",
    "\n",
    "improved_prompt_v1 = \"\"\"\n",
    "[WRITE YOUR IMPROVED PROMPT HERE]\n",
    "\"\"\"\n",
    "\n",
    "improved_system_prompt_v1 = \"\"\"\n",
    "[WRITE YOUR IMPROVED SYSTEM PROMPT HERE]\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Test your improved prompt\n",
    "# for test in test_transactions:\n",
    "#     response = call_gpt4(improved_prompt_v1.format(**test), improved_system_prompt_v1)\n",
    "#     print(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a396fd",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50943b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Structured, Explicit Prompt\n",
    "\n",
    "optimized_prompt_v1 = \"\"\"\n",
    "Analyze this transaction for fraud indicators using the structured format below.\n",
    "\n",
    "TRANSACTION DATA:\n",
    "{transaction_details}\n",
    "\n",
    "ANALYSIS REQUIRED:\n",
    "\n",
    "1. LOCATION RISK:\n",
    "   - Is purchase location far from cardholder location?\n",
    "   - Assessment: [Low/Medium/High]\n",
    "\n",
    "2. AMOUNT RISK:\n",
    "   - Is amount unusual for this merchant type?\n",
    "   - Assessment: [Low/Medium/High]\n",
    "\n",
    "3. TIMING RISK:\n",
    "   - Is transaction time suspicious (late night, unusual hours)?\n",
    "   - Assessment: [Low/Medium/High]\n",
    "\n",
    "4. MERCHANT RISK:\n",
    "   - Is merchant type high-risk (electronics, jewelry, international)?\n",
    "   - Assessment: [Low/Medium/High]\n",
    "\n",
    "FINAL DECISION:\n",
    "Based on the above factors, classify as:\n",
    "- FRAUDULENT (3+ high-risk factors)\n",
    "- SUSPICIOUS (2 high-risk factors, recommend review)\n",
    "- LEGITIMATE (0-1 high-risk factors)\n",
    "\n",
    "Provide your analysis now in exactly this format.\n",
    "\"\"\"\n",
    "\n",
    "optimized_system_prompt_v1 = \"\"\"You are a fraud detection analyst. \n",
    "You analyze transactions using specific risk factors.\n",
    "You always provide structured analysis in the exact format requested.\n",
    "You never deviate from the analysis template.\"\"\"\n",
    "\n",
    "# Test optimized prompt\n",
    "print(\"OPTIMIZED PROMPT OUTPUT:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test in enumerate(test_transactions):\n",
    "    response = call_gpt4(optimized_prompt_v1.format(**test), optimized_system_prompt_v1)\n",
    "    print(f\"\\nTest Case {i+1}:\")\n",
    "    print(f\"Input: {test['transaction_details'][:80]}...\")\n",
    "    print(f\"Output:\\n{response['content']}\")\n",
    "    print(f\"Tokens: {response['total_tokens']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a57b2",
   "metadata": {},
   "source": [
    "### Improvement Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare broken vs optimized\n",
    "comparison = compare_prompts(\n",
    "    broken_prompt_v1, \n",
    "    optimized_prompt_v1, \n",
    "    test_transactions,\n",
    "    optimized_system_prompt_v1\n",
    ")\n",
    "\n",
    "print(\"\\nPERFORMANCE COMPARISON:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Average tokens - Broken: {comparison['tokens_a'].mean():.0f}\")\n",
    "print(f\"Average tokens - Optimized: {comparison['tokens_b'].mean():.0f}\")\n",
    "print(f\"Token reduction: {((comparison['tokens_a'].mean() - comparison['tokens_b'].mean()) / comparison['tokens_a'].mean() * 100):.1f}%\")\n",
    "print(f\"\\nAverage latency - Broken: {comparison['latency_a'].mean():.2f}s\")\n",
    "print(f\"Average latency - Optimized: {comparison['latency_b'].mean():.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc42cc",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "‚úì **Explicit structure** - Template ensures consistency  \n",
    "‚úì **Defined criteria** - Clear factors to evaluate  \n",
    "‚úì **Decision framework** - Objective thresholds (3+ high = fraudulent)  \n",
    "‚úì **System prompt alignment** - Reinforces structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb862e",
   "metadata": {},
   "source": [
    "## CHALLENGE 2: MISSING CONTEXT\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Problem Type:** Insufficient information leading to poor decisions\n",
    "\n",
    "### Background\n",
    "\n",
    "The fraud team's prompt isn't considering the customer's transaction history, leading to false positives (legitimate unusual purchases flagged as fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02824986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BROKEN PROMPT - Lacks historical context\n",
    "\n",
    "broken_prompt_v2 = \"\"\"\n",
    "Transaction: {current_transaction}\n",
    "\n",
    "Is this fraudulent? Yes or No.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_v2 = \"You are a fraud detector.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases with transaction history\n",
    "test_cases_with_history = [\n",
    "    {\n",
    "        \"current_transaction\": \"$3,500 purchase at 'Apple Store', Tokyo Japan\",\n",
    "        \"cardholder_location\": \"San Francisco, CA\",\n",
    "        \"recent_history\": \"Last 5 transactions: $45 Whole Foods SF, $12 Starbucks SF, $89 Gas Station SF, $156 Amazon, $2,100 Apple Store SF\"\n",
    "    },\n",
    "    {\n",
    "        \"current_transaction\": \"$450 purchase at 'Designer Handbags Online', location unknown\",\n",
    "        \"cardholder_location\": \"Miami, FL\",\n",
    "        \"recent_history\": \"Last 5 transactions: $12 McDonald's Miami, $35 Grocery Miami, $8 Coffee Miami, $15 Parking Miami, $28 Pharmacy Miami\"\n",
    "    },\n",
    "    {\n",
    "        \"current_transaction\": \"$8,000 wire transfer to 'International Consulting Services Ltd'\",\n",
    "        \"cardholder_location\": \"Chicago, IL\",\n",
    "        \"recent_history\": \"Last 5 transactions: $7,500 wire to 'Global Business Partners', $6,200 wire to 'Overseas Contractors Inc', $5,800 wire to 'International Trade Co', $9,100 wire to 'Worldwide Suppliers', $7,300 wire to 'Foreign Consulting Group'\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d55321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test broken prompt (no history context)\n",
    "print(\"BROKEN PROMPT (No History Context):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test in enumerate(test_cases_with_history):\n",
    "    # Only passing current transaction - ignoring history\n",
    "    response = call_gpt4(\n",
    "        broken_prompt_v2.format(current_transaction=test['current_transaction']),\n",
    "        system_prompt_v2\n",
    "    )\n",
    "    print(f\"\\nTest Case {i+1}:\")\n",
    "    print(f\"Current: {test['current_transaction']}\")\n",
    "    print(f\"History (NOT PROVIDED TO MODEL): {test['recent_history']}\")\n",
    "    print(f\"Decision: {response['content']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68558c0",
   "metadata": {},
   "source": [
    "### Student Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a context-aware prompt\n",
    "# Requirements:\n",
    "# - Include transaction history in analysis\n",
    "# - Distinguish pattern breaks from consistent behavior\n",
    "# - Lower false positives while maintaining fraud detection\n",
    "\n",
    "improved_prompt_v2 = \"\"\"\n",
    "[WRITE YOUR CONTEXT-AWARE PROMPT HERE]\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Test your improved prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a0028",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Context-Aware Analysis\n",
    "\n",
    "optimized_prompt_v2 = \"\"\"\n",
    "Analyze this transaction in the context of the customer's recent behavior.\n",
    "\n",
    "CURRENT TRANSACTION:\n",
    "{current_transaction}\n",
    "\n",
    "CARDHOLDER LOCATION:\n",
    "{cardholder_location}\n",
    "\n",
    "RECENT TRANSACTION HISTORY:\n",
    "{recent_history}\n",
    "\n",
    "ANALYSIS FRAMEWORK:\n",
    "\n",
    "1. PATTERN CONSISTENCY:\n",
    "   - Is this transaction consistent with recent spending patterns?\n",
    "   - Similar merchant types, amounts, or locations in history?\n",
    "   - Assessment: [Consistent / Deviation / Major Deviation]\n",
    "\n",
    "2. BEHAVIORAL CONTEXT:\n",
    "   - Does history suggest business expenses, travel, or specific interests?\n",
    "   - Is there an established pattern this fits into?\n",
    "   - Context: [Describe pattern if exists]\n",
    "\n",
    "3. ANOMALY EVALUATION:\n",
    "   - If this IS unusual, is it explainable? (e.g., travel, gift, one-time purchase)\n",
    "   - Is the deviation suspicious or just atypical?\n",
    "   - Risk Level: [Low / Medium / High]\n",
    "\n",
    "4. FRAUD INDICATORS:\n",
    "   - Sudden pattern break with high-risk characteristics?\n",
    "   - Transaction type known for fraud (wire transfers, gift cards, crypto)?\n",
    "   - Multiple red flags?\n",
    "\n",
    "DECISION:\n",
    "- FRAUDULENT: Clear fraud indicators, major pattern break, high risk\n",
    "- SUSPICIOUS: Unusual but explainable, recommend verification with customer\n",
    "- LEGITIMATE: Consistent with patterns OR reasonable deviation\n",
    "\n",
    "Provide your structured analysis.\n",
    "\"\"\"\n",
    "\n",
    "optimized_system_prompt_v2 = \"\"\"You are a senior fraud analyst with expertise in behavioral analysis.\n",
    "You always consider transaction history and spending patterns.\n",
    "You distinguish between unusual-but-legitimate and genuinely fraudulent activity.\n",
    "You minimize false positives while maintaining security.\"\"\"\n",
    "\n",
    "# Test optimized prompt\n",
    "print(\"OPTIMIZED PROMPT (With Context):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test in enumerate(test_cases_with_history):\n",
    "    response = call_gpt4(optimized_prompt_v2.format(**test), optimized_system_prompt_v2)\n",
    "    print(f\"\\nTest Case {i+1}:\")\n",
    "    print(f\"Current: {test['current_transaction']}\")\n",
    "    print(f\"\\nAnalysis:\\n{response['content']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed9286",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "‚úì **Context is king** - Historical patterns dramatically improve accuracy  \n",
    "‚úì **Pattern recognition** - Distinguish breaks from consistency  \n",
    "‚úì **Behavioral analysis** - Understand customer profiles  \n",
    "‚úì **Explainability** - Show WHY a decision makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cab0c",
   "metadata": {},
   "source": [
    "## CHALLENGE 3: HALLUCINATION ISSUES\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Problem Type:** Model inventing facts not present in input\n",
    "\n",
    "### Background\n",
    "\n",
    "The fraud team noticed the AI sometimes \"invents\" transaction details that weren't provided - extremely dangerous in financial compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bff751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BROKEN PROMPT - Encourages hallucination\n",
    "\n",
    "broken_prompt_v3 = \"\"\"\n",
    "Analyze this transaction for fraud. Consider all relevant factors including \n",
    "the customer's age, income level, credit score, and previous fraud history.\n",
    "\n",
    "Transaction: {transaction}\n",
    "\n",
    "Provide a comprehensive fraud analysis.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_v3 = \"You are a fraud detection expert.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04991d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions with LIMITED information\n",
    "limited_info_transactions = [\n",
    "    {\n",
    "        \"transaction\": \"Card 9876, $450 purchase, merchant: Online Gaming Site\"\n",
    "    },\n",
    "    {\n",
    "        \"transaction\": \"Card 5544, $2,100 purchase, merchant: Cash4Gold, location: Unknown\"\n",
    "    },\n",
    "    {\n",
    "        \"transaction\": \"Card 3322, $85 purchase, merchant: Gas Station, location: Highway 101\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate hallucination\n",
    "print(\"HALLUCINATION DEMONSTRATION:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test in enumerate(limited_info_transactions):\n",
    "    response = call_gpt4(broken_prompt_v3.format(**test), system_prompt_v3)\n",
    "    print(f\"\\nTest Case {i+1}:\")\n",
    "    print(f\"Input: {test['transaction']}\")\n",
    "    print(f\"Output:\\n{response['content']}\")\n",
    "    print(\"\\n‚ö† HALLUCINATION CHECK: Did the model mention age, income, credit score, or fraud history?\")\n",
    "    print(\"   (These were NOT in the input!)\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f5197",
   "metadata": {},
   "source": [
    "### Student Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a hallucination-resistant prompt\n",
    "# Requirements:\n",
    "# - Only analyze data actually provided\n",
    "# - Explicitly acknowledge missing information\n",
    "# - Do NOT invent or assume missing details\n",
    "\n",
    "improved_prompt_v3 = \"\"\"\n",
    "[WRITE YOUR HALLUCINATION-RESISTANT PROMPT HERE]\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Test your prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6378d",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Grounded, Hallucination-Resistant Prompt\n",
    "\n",
    "optimized_prompt_v3 = \"\"\"\n",
    "Analyze this transaction for fraud using ONLY the information provided below.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. Use ONLY the transaction data provided\n",
    "2. Do NOT assume or invent information not given\n",
    "3. If important information is missing, explicitly state \"Information not available\"\n",
    "4. Base your analysis solely on what is present\n",
    "\n",
    "TRANSACTION DATA:\n",
    "{transaction}\n",
    "\n",
    "ANALYSIS USING ONLY PROVIDED DATA:\n",
    "\n",
    "1. MERCHANT RISK:\n",
    "   - Merchant type: [from transaction]\n",
    "   - Risk level based on merchant: [Low/Medium/High]\n",
    "\n",
    "2. AMOUNT ANALYSIS:\n",
    "   - Transaction amount: [from transaction]\n",
    "   - General risk for this amount: [Low/Medium/High]\n",
    "\n",
    "3. LOCATION RISK (if provided):\n",
    "   - Location: [from transaction or \"Not provided\"]\n",
    "   - Risk assessment: [Only if location given]\n",
    "\n",
    "4. DATA LIMITATIONS:\n",
    "   - What critical information is MISSING?\n",
    "   - List: [customer history, location, time, etc.]\n",
    "\n",
    "FRAUD ASSESSMENT:\n",
    "Based ONLY on available data:\n",
    "- Risk Level: [Low/Medium/High/INSUFFICIENT DATA]\n",
    "- Recommendation: [If insufficient data, state \"Require additional information\"]\n",
    "\n",
    "Provide analysis now using ONLY the data given.\n",
    "\"\"\"\n",
    "\n",
    "optimized_system_prompt_v3 = \"\"\"You are a fraud analyst bound by strict data integrity rules.\n",
    "You NEVER assume or invent information not explicitly provided.\n",
    "You ALWAYS acknowledge data limitations.\n",
    "You NEVER make up customer details, history, or context.\n",
    "If data is insufficient, you say so clearly.\"\"\"\n",
    "\n",
    "# Test optimized prompt\n",
    "print(\"HALLUCINATION-RESISTANT PROMPT:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test in enumerate(limited_info_transactions):\n",
    "    response = call_gpt4(optimized_prompt_v3.format(**test), optimized_system_prompt_v3)\n",
    "    print(f\"\\nTest Case {i+1}:\")\n",
    "    print(f\"Input: {test['transaction']}\")\n",
    "    print(f\"\\nAnalysis:\\n{response['content']}\")\n",
    "    print(\"\\n‚úì VERIFICATION: Did model only use provided data?\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425b699",
   "metadata": {},
   "source": [
    "### Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269beaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly test for hallucination\n",
    "def check_for_hallucination(input_data, output_text):\n",
    "    \"\"\"\n",
    "    Check if output contains information not in input\n",
    "    \"\"\"\n",
    "    hallucination_keywords = [\n",
    "        \"age\", \"income\", \"credit score\", \"fraud history\", \n",
    "        \"previous\", \"customer profile\", \"demographics\"\n",
    "    ]\n",
    "    \n",
    "    found_hallucinations = []\n",
    "    for keyword in hallucination_keywords:\n",
    "        if keyword.lower() in output_text.lower() and keyword.lower() not in input_data.lower():\n",
    "            found_hallucinations.append(keyword)\n",
    "    \n",
    "    return found_hallucinations\n",
    "\n",
    "# Test both prompts\n",
    "print(\"\\nHALLUCINATION TEST:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test = limited_info_transactions[0]\n",
    "\n",
    "# Broken prompt\n",
    "response_broken = call_gpt4(broken_prompt_v3.format(**test), system_prompt_v3)\n",
    "hallucinations_broken = check_for_hallucination(test['transaction'], response_broken['content'])\n",
    "\n",
    "# Optimized prompt  \n",
    "response_optimized = call_gpt4(optimized_prompt_v3.format(**test), optimized_system_prompt_v3)\n",
    "hallucinations_optimized = check_for_hallucination(test['transaction'], response_optimized['content'])\n",
    "\n",
    "print(f\"Broken Prompt Hallucinations: {hallucinations_broken if hallucinations_broken else 'None detected'}\")\n",
    "print(f\"Optimized Prompt Hallucinations: {hallucinations_optimized if hallucinations_optimized else 'None detected'}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac9769",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "‚úì **Explicit constraints** - \"Use ONLY provided data\"  \n",
    "‚úì **Acknowledge gaps** - State what's missing  \n",
    "‚úì **System prompt alignment** - Reinforce no hallucination  \n",
    "‚úì **Validation critical** - Test for invented information\n",
    "\n",
    "üí° **Why This Matters in BFSI:**\n",
    "- Regulatory compliance requires auditable facts\n",
    "- Hallucinated data = legal liability\n",
    "- Financial decisions must be based on truth\n",
    "- Trust and accuracy are non-negotiable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976553f2",
   "metadata": {},
   "source": [
    "## LAB SUMMARY\n",
    "\n",
    "### Key Debugging Principles\n",
    "\n",
    "1. **Always test systematically** - Use A/B comparisons\n",
    "2. **Measure objectively** - Tokens, latency, accuracy, cost\n",
    "3. **Iterate incrementally** - Change one thing at a time\n",
    "4. **Validate thoroughly** - Test edge cases after changes\n",
    "5. **Document improvements** - Track what works and why\n",
    "\n",
    "### Production Readiness\n",
    "\n",
    "Your prompts are production-ready when:\n",
    "\n",
    "‚úÖ Deterministic (temperature=0 for BFSI)  \n",
    "‚úÖ Grounded (no hallucination)  \n",
    "‚úÖ Consistent (same input ‚Üí same output)  \n",
    "‚úÖ Efficient (optimized token usage)  \n",
    "‚úÖ Accurate (validated against test suite)  \n",
    "‚úÖ Auditable (clear reasoning trail)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
