{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f6a048",
   "metadata": {},
   "source": [
    "# LAB 2.3: MULTI-DOCUMENT CONTEXT MANAGEMENT\n",
    "\n",
    "**Course:** Advanced Prompt Engineering Training  \n",
    "**Session:** Session 2 - Advanced Context Engineering  \n",
    "**Duration:** 50 minutes  \n",
    "**Type:** Hands-on Multi-Source Information Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c2c41",
   "metadata": {},
   "source": [
    "## LAB OVERVIEW\n",
    "\n",
    "This lab focuses on **managing context from multiple documents** for comprehensive analysis. You'll learn to:\n",
    "\n",
    "- Chunk and index multiple documents efficiently\n",
    "- Track cross-document references\n",
    "- Rank document relevance for specific queries\n",
    "- Synthesize information from disparate sources\n",
    "- Build production multi-document analysis systems\n",
    "\n",
    "**Scenario:** You're building a commercial loan underwriting system. Each application consists of multiple documents:\n",
    "- **Application Form** (5 pages) - Basic applicant info\n",
    "- **Tax Returns** (3 years, 60 pages total) - Income verification\n",
    "- **Bank Statements** (6 months, 30 pages) - Cash flow analysis\n",
    "- **Business Plan** (20 pages) - Growth projections\n",
    "- **Property Appraisal** (15 pages) - Collateral assessment\n",
    "- **Credit Report** (10 pages) - Credit history\n",
    "\n",
    "**Total:** 140 pages across 6 distinct documents\n",
    "\n",
    "**Challenge:** Answer questions that require information from multiple documents while staying within token limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b295ca",
   "metadata": {},
   "source": [
    "## LEARNING OBJECTIVES\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "✓ Chunk documents while preserving source metadata  \n",
    "✓ Build cross-document reference systems  \n",
    "✓ Rank document relevance for queries  \n",
    "✓ Synthesize information from multiple sources  \n",
    "✓ Handle conflicting information across documents  \n",
    "✓ Build production multi-document systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5e8fc",
   "metadata": {},
   "source": [
    "## SETUP INSTRUCTIONS\n",
    "\n",
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 2.3: Multi-Document Context Management\n",
    "# Advanced Prompt Engineering Training - Session 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8862b74",
   "metadata": {},
   "source": [
    "### Step 2: Configure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d00041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if API key exists\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found. Please set it in .env file\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Configuration\n",
    "MODEL = os.getenv(\"MODEL_NAME\")\n",
    "TEMPERATURE = 0  # Deterministic for BFSI applications\n",
    "\n",
    "if not MODEL:\n",
    "    raise ValueError(\"MODEL_NAME not found. Please set it in .env file\")\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(MODEL)\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Count tokens in text\"\"\"\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "print(f\"✓ Model: {MODEL}\")\n",
    "print(f\"✓ Tokenizer: {encoding.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775656e",
   "metadata": {},
   "source": [
    "### Step 3: Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e526957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt4(\n",
    "    prompt: str,\n",
    "    system_prompt: str = \"You are a helpful AI assistant.\",\n",
    "    temperature: float = 0\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Call GPT-4 API\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): User prompt\n",
    "        system_prompt (str): System prompt\n",
    "        temperature (float): Sampling temperature\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Response with metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "            \"completion_tokens\": response.usage.completion_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens,\n",
    "            \"success\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": \"\",\n",
    "            \"error\": str(e),\n",
    "            \"success\": False\n",
    "        }\n",
    "\n",
    "def generate_chunk_id(content: str) -> str:\n",
    "    \"\"\"Generate unique ID for chunk\"\"\"\n",
    "    return hashlib.md5(content.encode()).hexdigest()[:12]\n",
    "\n",
    "print(\"✓ Helper functions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953ce62",
   "metadata": {},
   "source": [
    "### Step 4: Load Sample Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realistic multi-document loan application dataset\n",
    "\n",
    "loan_documents = {\n",
    "    \"application_form\": {\n",
    "        \"title\": \"Commercial Loan Application\",\n",
    "        \"type\": \"application\",\n",
    "        \"date\": \"2024-02-01\",\n",
    "        \"pages\": 5,\n",
    "        \"content\": \"\"\"\n",
    "COMMERCIAL LOAN APPLICATION\n",
    "\n",
    "Applicant Information:\n",
    "Name: TechStart Solutions, LLC\n",
    "Business Type: Limited Liability Company\n",
    "Industry: Software Development (NAICS 541511)\n",
    "Years in Business: 3.5 years\n",
    "Federal Tax ID: 98-7654321\n",
    "\n",
    "Primary Contact:\n",
    "Name: Jennifer Martinez\n",
    "Title: CEO & Founder\n",
    "Phone: (555) 123-4567\n",
    "Email: jennifer@techstartsolutions.com\n",
    "\n",
    "Loan Request:\n",
    "Requested Amount: $750,000\n",
    "Purpose: Commercial real estate acquisition and renovation\n",
    "Property Address: 1234 Innovation Drive, Austin, TX 78701\n",
    "Property Type: Office building\n",
    "Purchase Price: $1,200,000\n",
    "Down Payment: $450,000 (37.5%)\n",
    "Loan-to-Value Ratio: 62.5%\n",
    "\n",
    "Financial Summary:\n",
    "Annual Revenue (2023): $2,400,000\n",
    "Annual Revenue (2022): $1,800,000\n",
    "Annual Revenue (2021): $1,200,000\n",
    "Current Employees: 18 full-time\n",
    "Monthly Operating Expenses: $180,000\n",
    "Current Business Debt: $350,000 (equipment loans)\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"tax_returns_2023\": {\n",
    "        \"title\": \"Business Tax Return - 2023\",\n",
    "        \"type\": \"tax_return\",\n",
    "        \"date\": \"2024-04-15\",\n",
    "        \"pages\": 22,\n",
    "        \"content\": \"\"\"\n",
    "FORM 1120 - U.S. CORPORATION INCOME TAX RETURN\n",
    "Tax Year: 2023\n",
    "Business Name: TechStart Solutions, LLC\n",
    "\n",
    "INCOME:\n",
    "Gross Receipts: $2,580,000\n",
    "Returns and Allowances: ($180,000)\n",
    "Net Receipts: $2,400,000\n",
    "Cost of Goods Sold: $960,000\n",
    "Gross Profit: $1,440,000\n",
    "\n",
    "DEDUCTIONS:\n",
    "Salaries and Wages: $840,000\n",
    "Rent: $120,000\n",
    "Taxes and Licenses: $48,000\n",
    "Interest: $28,000\n",
    "Depreciation: $65,000\n",
    "Other Deductions: $189,000\n",
    "Total Deductions: $1,290,000\n",
    "\n",
    "TAXABLE INCOME: $150,000\n",
    "Tax Liability: $31,500\n",
    "Payments: $35,000\n",
    "Refund Due: $3,500\n",
    "\n",
    "BALANCE SHEET (End of Year):\n",
    "Assets:\n",
    "  Cash: $280,000\n",
    "  Accounts Receivable: $420,000\n",
    "  Equipment: $385,000\n",
    "  Other Assets: $115,000\n",
    "  Total Assets: $1,200,000\n",
    "\n",
    "Liabilities:\n",
    "  Accounts Payable: $180,000\n",
    "  Notes Payable: $350,000\n",
    "  Other Liabilities: $70,000\n",
    "  Total Liabilities: $600,000\n",
    "\n",
    "Equity: $600,000\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"tax_returns_2022\": {\n",
    "        \"title\": \"Business Tax Return - 2022\",\n",
    "        \"type\": \"tax_return\",\n",
    "        \"date\": \"2023-04-15\",\n",
    "        \"pages\": 20,\n",
    "        \"content\": \"\"\"\n",
    "FORM 1120 - U.S. CORPORATION INCOME TAX RETURN\n",
    "Tax Year: 2022\n",
    "\n",
    "INCOME:\n",
    "Gross Receipts: $1,950,000\n",
    "Returns and Allowances: ($150,000)\n",
    "Net Receipts: $1,800,000\n",
    "Cost of Goods Sold: $720,000\n",
    "Gross Profit: $1,080,000\n",
    "\n",
    "DEDUCTIONS:\n",
    "Salaries and Wages: $630,000\n",
    "Rent: $108,000\n",
    "Taxes and Licenses: $36,000\n",
    "Interest: $22,000\n",
    "Depreciation: $55,000\n",
    "Other Deductions: $134,000\n",
    "Total Deductions: $985,000\n",
    "\n",
    "TAXABLE INCOME: $95,000\n",
    "Tax Liability: $19,950\n",
    "\n",
    "BALANCE SHEET (End of Year):\n",
    "Total Assets: $980,000\n",
    "Total Liabilities: $480,000\n",
    "Equity: $500,000\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"bank_statements\": {\n",
    "        \"title\": \"Business Bank Statements (Last 6 Months)\",\n",
    "        \"type\": \"bank_statement\",\n",
    "        \"date\": \"2024-02-01\",\n",
    "        \"pages\": 30,\n",
    "        \"content\": \"\"\"\n",
    "BUSINESS CHECKING ACCOUNT SUMMARY\n",
    "Account: TechStart Solutions Operating Account\n",
    "Period: August 2023 - January 2024\n",
    "\n",
    "MONTHLY SUMMARY:\n",
    "\n",
    "January 2024:\n",
    "Beginning Balance: $285,000\n",
    "Deposits: $245,000 (client payments, contracts)\n",
    "Withdrawals: $195,000 (payroll $140k, rent $10k, vendors $45k)\n",
    "Ending Balance: $335,000\n",
    "\n",
    "December 2023:\n",
    "Beginning Balance: $220,000\n",
    "Deposits: $280,000\n",
    "Withdrawals: $215,000 (payroll $145k, rent $10k, vendors $50k, bonuses $10k)\n",
    "Ending Balance: $285,000\n",
    "\n",
    "November 2023:\n",
    "Beginning Balance: $195,000\n",
    "Deposits: $235,000\n",
    "Withdrawals: $210,000\n",
    "Ending Balance: $220,000\n",
    "\n",
    "October 2023:\n",
    "Beginning Balance: $180,000\n",
    "Deposits: $255,000\n",
    "Withdrawals: $240,000\n",
    "Ending Balance: $195,000\n",
    "\n",
    "September 2023:\n",
    "Beginning Balance: $165,000\n",
    "Deposits: $220,000\n",
    "Withdrawals: $205,000\n",
    "Ending Balance: $180,000\n",
    "\n",
    "August 2023:\n",
    "Beginning Balance: $155,000\n",
    "Deposits: $210,000\n",
    "Withdrawals: $200,000\n",
    "Ending Balance: $165,000\n",
    "\n",
    "AVERAGE MONTHLY:\n",
    "Average Deposits: $240,833\n",
    "Average Withdrawals: $210,833\n",
    "Average Ending Balance: $230,000\n",
    "Net Monthly Cash Flow: +$30,000\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"business_plan\": {\n",
    "        \"title\": \"TechStart Solutions - Business Plan & Projections\",\n",
    "        \"type\": \"business_plan\",\n",
    "        \"date\": \"2024-01-15\",\n",
    "        \"pages\": 20,\n",
    "        \"content\": \"\"\"\n",
    "TECHSTART SOLUTIONS LLC\n",
    "STRATEGIC BUSINESS PLAN 2024-2026\n",
    "\n",
    "EXECUTIVE SUMMARY:\n",
    "TechStart Solutions is a rapidly growing software development firm specializing in\n",
    "enterprise cloud solutions. Founded in 2020, we have grown from 4 employees to 18,\n",
    "serving Fortune 500 clients.\n",
    "\n",
    "MARKET OPPORTUNITY:\n",
    "The enterprise cloud solutions market is projected to grow 25% annually through 2028.\n",
    "Our niche focus on healthcare and financial services positions us in high-growth,\n",
    "high-margin sectors.\n",
    "\n",
    "FINANCIAL PROJECTIONS:\n",
    "\n",
    "2024 Projected Revenue: $3,200,000 (33% growth)\n",
    "  - Existing Contracts: $2,400,000\n",
    "  - New Business Pipeline: $800,000\n",
    "  \n",
    "2025 Projected Revenue: $4,200,000 (31% growth)\n",
    "2026 Projected Revenue: $5,400,000 (29% growth)\n",
    "\n",
    "PROFITABILITY TARGETS:\n",
    "2024 Net Margin: 12% ($384,000 profit)\n",
    "2025 Net Margin: 14% ($588,000 profit)\n",
    "2026 Net Margin: 16% ($864,000 profit)\n",
    "\n",
    "STAFFING PLAN:\n",
    "Current: 18 employees\n",
    "2024: 24 employees (+6)\n",
    "2025: 32 employees (+8)\n",
    "2026: 40 employees (+8)\n",
    "\n",
    "REAL ESTATE ACQUISITION:\n",
    "Purpose: Purchase and renovate 1234 Innovation Drive\n",
    "  - Current office rent: $10,000/month ($120,000/year)\n",
    "  - Mortgage payment (projected): $5,800/month ($69,600/year)\n",
    "  - Annual savings: $50,400\n",
    "  - Additional benefit: Equity building, tax deductions, asset appreciation\n",
    "\n",
    "DEBT SERVICE COVERAGE:\n",
    "Projected Monthly Loan Payment: $5,800\n",
    "Projected Monthly EBITDA (2024): $40,000\n",
    "Debt Service Coverage Ratio: 6.9x (Excellent)\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"property_appraisal\": {\n",
    "        \"title\": \"Commercial Property Appraisal Report\",\n",
    "        \"type\": \"appraisal\",\n",
    "        \"date\": \"2024-01-20\",\n",
    "        \"pages\": 15,\n",
    "        \"content\": \"\"\"\n",
    "COMMERCIAL REAL ESTATE APPRAISAL\n",
    "\n",
    "Property Address: 1234 Innovation Drive, Austin, TX 78701\n",
    "Appraisal Date: January 20, 2024\n",
    "Appraiser: Austin Commercial Appraisers, LLC (License #TX-2024-8877)\n",
    "\n",
    "PROPERTY DESCRIPTION:\n",
    "Building Type: Two-story office building\n",
    "Year Built: 2015\n",
    "Total Square Footage: 8,500 sq ft\n",
    "Lot Size: 0.45 acres\n",
    "Zoning: Commercial Office (CO-1)\n",
    "Parking: 24 spaces\n",
    "\n",
    "CONDITION ASSESSMENT:\n",
    "Overall Condition: Good to Excellent\n",
    "Exterior: Well-maintained brick and glass facade\n",
    "Interior: Modern finishes, open floor plan\n",
    "Recent Updates: HVAC system upgraded 2022, roof replaced 2021\n",
    "Deferred Maintenance: Minimal (<$15,000 estimated)\n",
    "\n",
    "MARKET ANALYSIS:\n",
    "Comparable Sale 1: 1100 Tech Blvd - $138/sq ft\n",
    "Comparable Sale 2: 1500 Innovation Lane - $142/sq ft\n",
    "Comparable Sale 3: 1890 Commerce Ave - $135/sq ft\n",
    "Average Comparable: $138/sq ft\n",
    "\n",
    "VALUATION:\n",
    "Approach 1 - Sales Comparison: $1,173,000 (8,500 sq ft × $138/sq ft)\n",
    "Approach 2 - Income Capitalization: $1,210,000\n",
    "Approach 3 - Cost Approach: $1,195,000\n",
    "\n",
    "FINAL APPRAISED VALUE: $1,200,000\n",
    "\n",
    "MARKETABILITY: Good - Austin tech corridor, high demand\n",
    "RECOMMENDED LOAN-TO-VALUE: Maximum 75% ($900,000)\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"credit_report\": {\n",
    "        \"title\": \"Business Credit Report\",\n",
    "        \"type\": \"credit_report\",\n",
    "        \"date\": \"2024-02-01\",\n",
    "        \"pages\": 10,\n",
    "        \"content\": \"\"\"\n",
    "BUSINESS CREDIT REPORT\n",
    "Business Name: TechStart Solutions, LLC\n",
    "Report Date: February 1, 2024\n",
    "Reporting Bureau: Equifax Business\n",
    "\n",
    "CREDIT SCORE: 782 (Excellent)\n",
    "Risk Rating: Low Risk\n",
    "Delinquency Score: 95/100\n",
    "\n",
    "CREDIT SUMMARY:\n",
    "Total Trade Lines: 8\n",
    "Active Accounts: 6\n",
    "Closed Accounts: 2\n",
    "Total Credit Limit: $485,000\n",
    "Total Balance: $350,000\n",
    "Credit Utilization: 72%\n",
    "\n",
    "PAYMENT HISTORY (24 Months):\n",
    "On-Time Payments: 100%\n",
    "30-Day Late: 0\n",
    "60-Day Late: 0\n",
    "90+ Day Late: 0\n",
    "Collections: 0\n",
    "Public Records: 0\n",
    "\n",
    "ACTIVE CREDIT ACCOUNTS:\n",
    "\n",
    "1. Equipment Loan - Regional Bank\n",
    "   Balance: $180,000\n",
    "   Monthly Payment: $5,200\n",
    "   Status: Current, never late\n",
    "   \n",
    "2. Equipment Loan - Tech Finance Co\n",
    "   Balance: $170,000\n",
    "   Monthly Payment: $4,800\n",
    "   Status: Current, never late\n",
    "\n",
    "3. Business Credit Card - Chase\n",
    "   Limit: $50,000\n",
    "   Balance: $18,000\n",
    "   Status: Current\n",
    "   \n",
    "4. Business Credit Card - AmEx\n",
    "   Limit: $35,000\n",
    "   Balance: $12,000\n",
    "   Status: Current\n",
    "\n",
    "5. Line of Credit - Community Bank\n",
    "   Limit: $100,000\n",
    "   Balance: $0 (unused)\n",
    "   Status: Current\n",
    "\n",
    "OWNER PERSONAL GUARANTEE:\n",
    "Jennifer Martinez - Personal FICO: 745 (Good)\n",
    "Personal DTI: 28% (Low)\n",
    "\n",
    "RECOMMENDED LENDING DECISION:\n",
    "Business demonstrates excellent credit management\n",
    "Payment history perfect over 24 months\n",
    "Low risk for commercial lending up to $1,000,000\n",
    "\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"✓ Sample documents loaded: {len(loan_documents)} documents\")\n",
    "for doc_id, doc in loan_documents.items():\n",
    "    tokens = count_tokens(doc['content'])\n",
    "    print(f\"  - {doc['title']}: {tokens} tokens ({doc['pages']} pages)\")\n",
    "\n",
    "total_tokens = sum(count_tokens(doc['content']) for doc in loan_documents.values())\n",
    "print(f\"\\n✓ Total document collection: {total_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ce02d",
   "metadata": {},
   "source": [
    "## CHALLENGE 1: DOCUMENT CHUNKING & INDEXING\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Chunk documents while preserving metadata\n",
    "\n",
    "### Background\n",
    "\n",
    "Each document needs to be chunked for efficient retrieval, with metadata tracking the source.\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d7caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Document Chunking System\n",
    "\n",
    "class DocumentChunk:\n",
    "    \"\"\"\n",
    "    Single chunk from a document with full metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        chunk_id: str,\n",
    "        doc_id: str,\n",
    "        doc_title: str,\n",
    "        doc_type: str,\n",
    "        content: str,\n",
    "        chunk_index: int,\n",
    "        total_chunks: int,\n",
    "        metadata: Dict = None\n",
    "    ):\n",
    "        self.chunk_id = chunk_id\n",
    "        self.doc_id = doc_id\n",
    "        self.doc_title = doc_title\n",
    "        self.doc_type = doc_type\n",
    "        self.content = content\n",
    "        self.chunk_index = chunk_index  # Position in document (0-indexed)\n",
    "        self.total_chunks = total_chunks\n",
    "        self.metadata = metadata or {}\n",
    "        self.token_count = count_tokens(content)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Chunk({self.chunk_id}, {self.doc_title}, {self.chunk_index+1}/{self.total_chunks}, {self.token_count} tokens)\"\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Export chunk to dictionary\"\"\"\n",
    "        return {\n",
    "            \"chunk_id\": self.chunk_id,\n",
    "            \"doc_id\": self.doc_id,\n",
    "            \"doc_title\": self.doc_title,\n",
    "            \"doc_type\": self.doc_type,\n",
    "            \"content\": self.content,\n",
    "            \"chunk_index\": self.chunk_index,\n",
    "            \"total_chunks\": self.total_chunks,\n",
    "            \"token_count\": self.token_count,\n",
    "            \"metadata\": self.metadata\n",
    "        }\n",
    "\n",
    "class DocumentChunker:\n",
    "    \"\"\"\n",
    "    Chunk documents while preserving source metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 800, overlap: int = 100):\n",
    "        \"\"\"\n",
    "        Initialize chunker\n",
    "        \n",
    "        Args:\n",
    "            chunk_size (int): Target tokens per chunk\n",
    "            overlap (int): Overlapping tokens between chunks\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.overlap = overlap\n",
    "        self.all_chunks = []\n",
    "    \n",
    "    def chunk_document(self, doc_id: str, document: Dict) -> List[DocumentChunk]:\n",
    "        \"\"\"\n",
    "        Chunk a document into pieces\n",
    "        \n",
    "        Args:\n",
    "            doc_id (str): Document identifier\n",
    "            document (Dict): Document data with 'content', 'title', 'type', etc.\n",
    "        \n",
    "        Returns:\n",
    "            List[DocumentChunk]: Document chunks\n",
    "        \"\"\"\n",
    "        content = document['content']\n",
    "        \n",
    "        # Split by paragraphs first (preserves structure)\n",
    "        paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_tokens = 0\n",
    "        \n",
    "        for paragraph in paragraphs:\n",
    "            para_tokens = count_tokens(paragraph)\n",
    "            \n",
    "            # If single paragraph exceeds chunk size, split it\n",
    "            if para_tokens > self.chunk_size:\n",
    "                # Save current chunk if exists\n",
    "                if current_chunk:\n",
    "                    chunks.append('\\n\\n'.join(current_chunk))\n",
    "                    current_chunk = []\n",
    "                    current_tokens = 0\n",
    "                \n",
    "                # Split large paragraph by sentences\n",
    "                sentences = paragraph.split('. ')\n",
    "                for sentence in sentences:\n",
    "                    sent_tokens = count_tokens(sentence)\n",
    "                    if current_tokens + sent_tokens > self.chunk_size:\n",
    "                        if current_chunk:\n",
    "                            chunks.append('. '.join(current_chunk) + '.')\n",
    "                        current_chunk = [sentence]\n",
    "                        current_tokens = sent_tokens\n",
    "                    else:\n",
    "                        current_chunk.append(sentence)\n",
    "                        current_tokens += sent_tokens\n",
    "                \n",
    "                if current_chunk:\n",
    "                    chunks.append('. '.join(current_chunk))\n",
    "                    current_chunk = []\n",
    "                    current_tokens = 0\n",
    "            \n",
    "            # Normal paragraph processing\n",
    "            elif current_tokens + para_tokens > self.chunk_size:\n",
    "                # Save current chunk and start new one\n",
    "                if current_chunk:\n",
    "                    chunks.append('\\n\\n'.join(current_chunk))\n",
    "                current_chunk = [paragraph]\n",
    "                current_tokens = para_tokens\n",
    "            else:\n",
    "                current_chunk.append(paragraph)\n",
    "                current_tokens += para_tokens\n",
    "        \n",
    "        # Don't forget last chunk\n",
    "        if current_chunk:\n",
    "            chunks.append('\\n\\n'.join(current_chunk))\n",
    "        \n",
    "        # Create DocumentChunk objects\n",
    "        total_chunks = len(chunks)\n",
    "        chunk_objects = []\n",
    "        \n",
    "        for i, chunk_content in enumerate(chunks):\n",
    "            chunk_id = f\"{doc_id}_chunk_{i}\"\n",
    "            \n",
    "            chunk_obj = DocumentChunk(\n",
    "                chunk_id=chunk_id,\n",
    "                doc_id=doc_id,\n",
    "                doc_title=document['title'],\n",
    "                doc_type=document['type'],\n",
    "                content=chunk_content,\n",
    "                chunk_index=i,\n",
    "                total_chunks=total_chunks,\n",
    "                metadata={\n",
    "                    'date': document.get('date'),\n",
    "                    'pages': document.get('pages')\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            chunk_objects.append(chunk_obj)\n",
    "            self.all_chunks.append(chunk_obj)\n",
    "        \n",
    "        return chunk_objects\n",
    "    \n",
    "    def chunk_all_documents(self, documents: Dict) -> Dict[str, List[DocumentChunk]]:\n",
    "        \"\"\"\n",
    "        Chunk all documents in collection\n",
    "        \n",
    "        Args:\n",
    "            documents (Dict): Document collection\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, List[DocumentChunk]]: Chunked documents by doc_id\n",
    "        \"\"\"\n",
    "        chunked_docs = {}\n",
    "        \n",
    "        for doc_id, document in documents.items():\n",
    "            chunks = self.chunk_document(doc_id, document)\n",
    "            chunked_docs[doc_id] = chunks\n",
    "        \n",
    "        return chunked_docs\n",
    "    \n",
    "    def get_all_chunks(self) -> List[DocumentChunk]:\n",
    "        \"\"\"Get all chunks across all documents\"\"\"\n",
    "        return self.all_chunks\n",
    "    \n",
    "    def get_chunk_stats(self) -> Dict:\n",
    "        \"\"\"Get chunking statistics\"\"\"\n",
    "        if not self.all_chunks:\n",
    "            return {\"total_chunks\": 0}\n",
    "        \n",
    "        token_counts = [chunk.token_count for chunk in self.all_chunks]\n",
    "        doc_types = defaultdict(int)\n",
    "        for chunk in self.all_chunks:\n",
    "            doc_types[chunk.doc_type] += 1\n",
    "        \n",
    "        return {\n",
    "            \"total_chunks\": len(self.all_chunks),\n",
    "            \"total_tokens\": sum(token_counts),\n",
    "            \"avg_tokens_per_chunk\": np.mean(token_counts),\n",
    "            \"min_tokens\": min(token_counts),\n",
    "            \"max_tokens\": max(token_counts),\n",
    "            \"chunks_by_type\": dict(doc_types)\n",
    "        }\n",
    "\n",
    "print(\"✓ DocumentChunk and DocumentChunker classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0783bd",
   "metadata": {},
   "source": [
    "### Test Document Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test document chunker\n",
    "print(\"DOCUMENT CHUNKING TEST:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "chunker = DocumentChunker(chunk_size=600, overlap=100)\n",
    "\n",
    "# Chunk all documents\n",
    "chunked_collection = chunker.chunk_all_documents(loan_documents)\n",
    "\n",
    "print(f\"\\nCHUNKING RESULTS:\")\n",
    "print(\"-\" * 80)\n",
    "for doc_id, chunks in chunked_collection.items():\n",
    "    print(f\"\\n{doc_id}:\")\n",
    "    print(f\"  Document: {chunks[0].doc_title}\")\n",
    "    print(f\"  Chunks created: {len(chunks)}\")\n",
    "    for chunk in chunks:\n",
    "        print(f\"    - {chunk.chunk_id}: {chunk.token_count} tokens\")\n",
    "\n",
    "# Get overall statistics\n",
    "stats = chunker.get_chunk_stats()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OVERALL STATISTICS:\")\n",
    "print(\"-\" * 80)\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.1f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365fb620",
   "metadata": {},
   "source": [
    "## CHALLENGE 2: CROSS-DOCUMENT REFERENCE TRACKING\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Track which documents reference the same entities\n",
    "\n",
    "### Background\n",
    "\n",
    "Documents often reference the same facts (revenue, dates, amounts). Tracking cross-references helps identify discrepancies or confirm consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Cross-Document Reference Tracker\n",
    "\n",
    "class CrossDocumentTracker:\n",
    "    \"\"\"\n",
    "    Track entities and facts across multiple documents\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.entity_index = defaultdict(list)  # entity -> [(doc_id, chunk_id, mention)]\n",
    "        self.doc_entities = defaultdict(set)  # doc_id -> set of entities\n",
    "    \n",
    "    def extract_entities_from_chunk(self, chunk: DocumentChunk) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract key entities from chunk (simplified version)\n",
    "        \n",
    "        Args:\n",
    "            chunk (DocumentChunk): Document chunk\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: Extracted entities\n",
    "        \"\"\"\n",
    "        import re\n",
    "        \n",
    "        entities = []\n",
    "        text = chunk.content\n",
    "        \n",
    "        # Extract monetary amounts\n",
    "        money_pattern = r'\\$[\\d,]+(?:\\.\\d{2})?'\n",
    "        money_entities = re.findall(money_pattern, text)\n",
    "        entities.extend([f\"AMOUNT:{m}\" for m in money_entities])\n",
    "        \n",
    "        # Extract percentages\n",
    "        pct_pattern = r'\\d+(?:\\.\\d+)?%'\n",
    "        pct_entities = re.findall(pct_pattern, text)\n",
    "        entities.extend([f\"PERCENTAGE:{p}\" for p in pct_entities])\n",
    "        \n",
    "        # Extract years\n",
    "        year_pattern = r'\\b(20\\d{2})\\b'\n",
    "        year_entities = re.findall(year_pattern, text)\n",
    "        entities.extend([f\"YEAR:{y}\" for y in year_entities])\n",
    "        \n",
    "        # Extract key financial terms\n",
    "        financial_terms = [\n",
    "            'revenue', 'profit', 'income', 'assets', 'liabilities',\n",
    "            'loan', 'credit', 'debt', 'equity', 'payment'\n",
    "        ]\n",
    "        for term in financial_terms:\n",
    "            if term.lower() in text.lower():\n",
    "                entities.append(f\"TERM:{term.upper()}\")\n",
    "        \n",
    "        return list(set(entities))  # Remove duplicates\n",
    "    \n",
    "    def index_chunk(self, chunk: DocumentChunk) -> None:\n",
    "        \"\"\"\n",
    "        Index entities from a chunk\n",
    "        \n",
    "        Args:\n",
    "            chunk (DocumentChunk): Chunk to index\n",
    "        \"\"\"\n",
    "        entities = self.extract_entities_from_chunk(chunk)\n",
    "        \n",
    "        for entity in entities:\n",
    "            self.entity_index[entity].append({\n",
    "                'doc_id': chunk.doc_id,\n",
    "                'doc_title': chunk.doc_title,\n",
    "                'chunk_id': chunk.chunk_id,\n",
    "                'doc_type': chunk.doc_type\n",
    "            })\n",
    "            self.doc_entities[chunk.doc_id].add(entity)\n",
    "    \n",
    "    def index_all_chunks(self, chunks: List[DocumentChunk]) -> None:\n",
    "        \"\"\"Index all chunks\"\"\"\n",
    "        for chunk in chunks:\n",
    "            self.index_chunk(chunk)\n",
    "    \n",
    "    def find_cross_document_entities(self, min_docs: int = 2) -> Dict[str, List]:\n",
    "        \"\"\"\n",
    "        Find entities mentioned in multiple documents\n",
    "        \n",
    "        Args:\n",
    "            min_docs (int): Minimum number of documents\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, List]: Entities and their document sources\n",
    "        \"\"\"\n",
    "        cross_doc_entities = {}\n",
    "        \n",
    "        for entity, mentions in self.entity_index.items():\n",
    "            # Get unique documents\n",
    "            unique_docs = set(m['doc_id'] for m in mentions)\n",
    "            \n",
    "            if len(unique_docs) >= min_docs:\n",
    "                cross_doc_entities[entity] = mentions\n",
    "        \n",
    "        return cross_doc_entities\n",
    "    \n",
    "    def find_related_documents(self, doc_id: str, min_shared: int = 3) -> List[Tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        Find documents related to given document\n",
    "        \n",
    "        Args:\n",
    "            doc_id (str): Source document ID\n",
    "            min_shared (int): Minimum shared entities\n",
    "        \n",
    "        Returns:\n",
    "            List[Tuple[str, int]]: Related docs with shared entity count\n",
    "        \"\"\"\n",
    "        if doc_id not in self.doc_entities:\n",
    "            return []\n",
    "        \n",
    "        source_entities = self.doc_entities[doc_id]\n",
    "        related = defaultdict(int)\n",
    "        \n",
    "        # Count shared entities with other documents\n",
    "        for entity in source_entities:\n",
    "            for mention in self.entity_index[entity]:\n",
    "                other_doc = mention['doc_id']\n",
    "                if other_doc != doc_id:\n",
    "                    related[other_doc] += 1\n",
    "        \n",
    "        # Filter and sort\n",
    "        related_docs = [(doc, count) for doc, count in related.items() if count >= min_shared]\n",
    "        related_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return related_docs\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get cross-document statistics\"\"\"\n",
    "        cross_doc = self.find_cross_document_entities(min_docs=2)\n",
    "        \n",
    "        return {\n",
    "            \"total_entities\": len(self.entity_index),\n",
    "            \"cross_document_entities\": len(cross_doc),\n",
    "            \"documents_indexed\": len(self.doc_entities),\n",
    "            \"avg_entities_per_doc\": np.mean([len(entities) for entities in self.doc_entities.values()])\n",
    "        }\n",
    "\n",
    "print(\"✓ CrossDocumentTracker class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b9d2c",
   "metadata": {},
   "source": [
    "### Test Cross-Document Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cross-document tracker\n",
    "print(\"CROSS-DOCUMENT REFERENCE TRACKING:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tracker = CrossDocumentTracker()\n",
    "\n",
    "# Index all chunks\n",
    "all_chunks = chunker.get_all_chunks()\n",
    "tracker.index_all_chunks(all_chunks)\n",
    "\n",
    "# Get statistics\n",
    "stats = tracker.get_stats()\n",
    "print(\"\\nTRACKING STATISTICS:\")\n",
    "print(\"-\" * 80)\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.1f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Find cross-document entities\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CROSS-DOCUMENT ENTITIES (mentioned in 2+ documents):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "cross_doc_entities = tracker.find_cross_document_entities(min_docs=2)\n",
    "\n",
    "# Show some examples\n",
    "for entity, mentions in list(cross_doc_entities.items())[:10]:\n",
    "    doc_titles = set(m['doc_title'] for m in mentions)\n",
    "    print(f\"\\n{entity}:\")\n",
    "    print(f\"  Appears in {len(doc_titles)} documents:\")\n",
    "    for title in list(doc_titles)[:3]:\n",
    "        print(f\"    - {title}\")\n",
    "\n",
    "# Find documents related to application form\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DOCUMENTS RELATED TO APPLICATION FORM:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "related = tracker.find_related_documents('application_form', min_shared=3)\n",
    "for doc_id, shared_count in related:\n",
    "    doc_title = loan_documents[doc_id]['title']\n",
    "    print(f\"  {doc_title}: {shared_count} shared entities\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73589b",
   "metadata": {},
   "source": [
    "## CHALLENGE 3: DOCUMENT RELEVANCE RANKING\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Rank documents by relevance to a query\n",
    "\n",
    "### Background\n",
    "\n",
    "Given a query, determine which documents are most relevant and should be loaded into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab49b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Document Relevance Ranker\n",
    "\n",
    "class DocumentRelevanceRanker:\n",
    "    \"\"\"\n",
    "    Rank documents and chunks by relevance to query\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chunks: List[DocumentChunk]):\n",
    "        \"\"\"\n",
    "        Initialize ranker with chunks\n",
    "        \n",
    "        Args:\n",
    "            chunks (List[DocumentChunk]): All available chunks\n",
    "        \"\"\"\n",
    "        self.chunks = chunks\n",
    "        self.doc_types_keywords = {\n",
    "            'application': ['applicant', 'request', 'loan amount', 'down payment', 'ltv'],\n",
    "            'tax_return': ['income', 'revenue', 'deduction', 'profit', 'tax', 'receipts'],\n",
    "            'bank_statement': ['balance', 'deposit', 'withdrawal', 'cash flow', 'monthly'],\n",
    "            'business_plan': ['projection', 'growth', 'strategy', 'forecast', 'plan'],\n",
    "            'appraisal': ['property', 'value', 'appraisal', 'comparable', 'market'],\n",
    "            'credit_report': ['credit', 'score', 'payment', 'delinquency', 'trade']\n",
    "        }\n",
    "    \n",
    "    def calculate_keyword_score(self, query: str, chunk: DocumentChunk) -> float:\n",
    "        \"\"\"\n",
    "        Calculate keyword overlap score\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            chunk (DocumentChunk): Document chunk\n",
    "        \n",
    "        Returns:\n",
    "            float: Keyword score (0-1)\n",
    "        \"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        content_words = set(chunk.content.lower().split())\n",
    "        \n",
    "        if not query_words:\n",
    "            return 0.0\n",
    "        \n",
    "        overlap = len(query_words & content_words)\n",
    "        return overlap / len(query_words)\n",
    "    \n",
    "    def calculate_doc_type_score(self, query: str, chunk: DocumentChunk) -> float:\n",
    "        \"\"\"\n",
    "        Calculate document type relevance\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            chunk (DocumentChunk): Document chunk\n",
    "        \n",
    "        Returns:\n",
    "            float: Type relevance score (0-1)\n",
    "        \"\"\"\n",
    "        query_lower = query.lower()\n",
    "        doc_type = chunk.doc_type\n",
    "        \n",
    "        if doc_type not in self.doc_types_keywords:\n",
    "            return 0.5  # Neutral score\n",
    "        \n",
    "        keywords = self.doc_types_keywords[doc_type]\n",
    "        matches = sum(1 for kw in keywords if kw in query_lower)\n",
    "        \n",
    "        if matches > 0:\n",
    "            return min(1.0, matches / 3)  # Max score at 3 keyword matches\n",
    "        \n",
    "        return 0.3  # Small baseline score\n",
    "    \n",
    "    def calculate_relevance_score(\n",
    "        self,\n",
    "        query: str,\n",
    "        chunk: DocumentChunk,\n",
    "        keyword_weight: float = 0.6,\n",
    "        type_weight: float = 0.4\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate overall relevance score\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            chunk (DocumentChunk): Document chunk\n",
    "            keyword_weight (float): Weight for keyword matching\n",
    "            type_weight (float): Weight for document type\n",
    "        \n",
    "        Returns:\n",
    "            float: Overall relevance score (0-1)\n",
    "        \"\"\"\n",
    "        keyword_score = self.calculate_keyword_score(query, chunk)\n",
    "        type_score = self.calculate_doc_type_score(query, chunk)\n",
    "        \n",
    "        return (keyword_weight * keyword_score) + (type_weight * type_score)\n",
    "    \n",
    "    def rank_chunks(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k: int = 5,\n",
    "        min_score: float = 0.1\n",
    "    ) -> List[Tuple[DocumentChunk, float]]:\n",
    "        \"\"\"\n",
    "        Rank chunks by relevance to query\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            top_k (int): Number of top chunks to return\n",
    "            min_score (float): Minimum relevance score threshold\n",
    "        \n",
    "        Returns:\n",
    "            List[Tuple[DocumentChunk, float]]: Ranked chunks with scores\n",
    "        \"\"\"\n",
    "        scored_chunks = []\n",
    "        \n",
    "        for chunk in self.chunks:\n",
    "            score = self.calculate_relevance_score(query, chunk)\n",
    "            if score >= min_score:\n",
    "                scored_chunks.append((chunk, score))\n",
    "        \n",
    "        # Sort by score (descending)\n",
    "        scored_chunks.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return scored_chunks[:top_k]\n",
    "    \n",
    "    def get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        max_tokens: int = 3000\n",
    "    ) -> List[DocumentChunk]:\n",
    "        \"\"\"\n",
    "        Get relevant chunks within token budget\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            max_tokens (int): Maximum tokens to return\n",
    "        \n",
    "        Returns:\n",
    "            List[DocumentChunk]: Relevant chunks within budget\n",
    "        \"\"\"\n",
    "        # Get ranked chunks\n",
    "        ranked = self.rank_chunks(query, top_k=20)  # Get more candidates\n",
    "        \n",
    "        # Select chunks within budget\n",
    "        selected = []\n",
    "        current_tokens = 0\n",
    "        \n",
    "        for chunk, score in ranked:\n",
    "            if current_tokens + chunk.token_count <= max_tokens:\n",
    "                selected.append(chunk)\n",
    "                current_tokens += chunk.token_count\n",
    "            else:\n",
    "                break  # Budget exceeded\n",
    "        \n",
    "        return selected\n",
    "\n",
    "print(\"✓ DocumentRelevanceRanker class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572ed9c",
   "metadata": {},
   "source": [
    "### Test Document Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test document ranker\n",
    "print(\"DOCUMENT RELEVANCE RANKING:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ranker = DocumentRelevanceRanker(all_chunks)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What is the applicant's annual revenue?\",\n",
    "    \"Does the applicant have good credit?\",\n",
    "    \"What is the property value?\",\n",
    "    \"Can they afford the loan payment?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get top 3 relevant chunks\n",
    "    ranked = ranker.rank_chunks(query, top_k=3, min_score=0.15)\n",
    "    \n",
    "    print(f\"\\nTop {len(ranked)} relevant chunks:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, (chunk, score) in enumerate(ranked, 1):\n",
    "        print(f\"\\n{i}. {chunk.doc_title} (Score: {score:.3f})\")\n",
    "        print(f\"   Chunk: {chunk.chunk_id}\")\n",
    "        print(f\"   Type: {chunk.doc_type}\")\n",
    "        print(f\"   Tokens: {chunk.token_count}\")\n",
    "        print(f\"   Preview: {chunk.content[:150]}...\")\n",
    "\n",
    "# Test budget-constrained retrieval\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BUDGET-CONSTRAINED RETRIEVAL:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query = \"Analyze the company's financial health and ability to repay the loan.\"\n",
    "max_tokens = 2000\n",
    "\n",
    "relevant_chunks = ranker.get_relevant_documents(query, max_tokens=max_tokens)\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(f\"Token Budget: {max_tokens}\")\n",
    "print(f\"Chunks Selected: {len(relevant_chunks)}\")\n",
    "print(f\"Total Tokens: {sum(c.token_count for c in relevant_chunks)}\")\n",
    "\n",
    "print(\"\\nSelected Documents:\")\n",
    "for chunk in relevant_chunks:\n",
    "    print(f\"  - {chunk.doc_title} ({chunk.token_count} tokens)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fc645",
   "metadata": {},
   "source": [
    "## CHALLENGE 4: SYNTHESIS FROM MULTIPLE SOURCES\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Answer questions requiring information from multiple documents\n",
    "\n",
    "### Background\n",
    "\n",
    "Many queries require synthesizing information from 2+ documents with proper attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Multi-Document Synthesizer\n",
    "\n",
    "class MultiDocumentSynthesizer:\n",
    "    \"\"\"\n",
    "    Synthesize answers from multiple document sources\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ranker: DocumentRelevanceRanker):\n",
    "        \"\"\"\n",
    "        Initialize synthesizer\n",
    "        \n",
    "        Args:\n",
    "            ranker (DocumentRelevanceRanker): Document ranker\n",
    "        \"\"\"\n",
    "        self.ranker = ranker\n",
    "    \n",
    "    def answer_query(\n",
    "        self,\n",
    "        query: str,\n",
    "        max_context_tokens: int = 3000,\n",
    "        include_sources: bool = True\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Answer query using multiple documents\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            max_context_tokens (int): Maximum tokens for context\n",
    "            include_sources (bool): Whether to cite sources\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Answer with metadata\n",
    "        \"\"\"\n",
    "        # Get relevant chunks\n",
    "        relevant_chunks = self.ranker.get_relevant_documents(query, max_context_tokens)\n",
    "        \n",
    "        if not relevant_chunks:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"No relevant documents found\",\n",
    "                \"answer\": \"\"\n",
    "            }\n",
    "        \n",
    "        # Build context from chunks\n",
    "        context_parts = []\n",
    "        sources_used = []\n",
    "        \n",
    "        for chunk in relevant_chunks:\n",
    "            source_label = f\"[{chunk.doc_type.upper()}: {chunk.doc_title}]\"\n",
    "            context_parts.append(f\"{source_label}\\n{chunk.content}\")\n",
    "            \n",
    "            sources_used.append({\n",
    "                'doc_id': chunk.doc_id,\n",
    "                'doc_title': chunk.doc_title,\n",
    "                'doc_type': chunk.doc_type,\n",
    "                'chunk_id': chunk.chunk_id\n",
    "            })\n",
    "        \n",
    "        context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # Build prompt\n",
    "        if include_sources:\n",
    "            prompt = f\"\"\"\n",
    "Based on the following document excerpts, answer the question.\n",
    "Cite your sources by referencing the document type and title.\n",
    "\n",
    "DOCUMENTS:\n",
    "{context}\n",
    "\n",
    "QUESTION: {query}\n",
    "\n",
    "Provide a clear answer with source citations.\n",
    "\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "Based on the following information, answer the question concisely.\n",
    "\n",
    "INFORMATION:\n",
    "{context}\n",
    "\n",
    "QUESTION: {query}\n",
    "\"\"\"\n",
    "        \n",
    "        # Get answer from LLM\n",
    "        response = call_gpt4(\n",
    "            prompt,\n",
    "            \"You are a loan underwriting analyst. Provide accurate answers based on document evidence.\"\n",
    "        )\n",
    "        \n",
    "        if response['success']:\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"answer\": response['content'],\n",
    "                \"sources\": sources_used,\n",
    "                \"chunks_used\": len(relevant_chunks),\n",
    "                \"context_tokens\": count_tokens(context),\n",
    "                \"total_tokens\": response['total_tokens']\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": response.get('error'),\n",
    "                \"answer\": \"\"\n",
    "            }\n",
    "    \n",
    "    def verify_consistency(\n",
    "        self,\n",
    "        entity: str,\n",
    "        expected_value: str = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Check if an entity has consistent values across documents\n",
    "        \n",
    "        Args:\n",
    "            entity (str): Entity to check (e.g., \"annual revenue\")\n",
    "            expected_value (str): Optional expected value\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Consistency check results\n",
    "        \"\"\"\n",
    "        query = f\"What is the {entity}?\"\n",
    "        \n",
    "        # Get answer\n",
    "        result = self.answer_query(query, max_context_tokens=2000)\n",
    "        \n",
    "        if result['success']:\n",
    "            # Extract sources that mentioned this\n",
    "            sources = [s['doc_title'] for s in result['sources']]\n",
    "            \n",
    "            return {\n",
    "                \"entity\": entity,\n",
    "                \"value_found\": result['answer'],\n",
    "                \"sources\": sources,\n",
    "                \"source_count\": len(sources),\n",
    "                \"consistent\": True if len(set(sources)) > 1 else False\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"entity\": entity,\n",
    "            \"error\": \"Could not verify\"\n",
    "        }\n",
    "\n",
    "print(\"✓ MultiDocumentSynthesizer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b34042",
   "metadata": {},
   "source": [
    "### Test Multi-Document Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71527f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multi-document synthesizer\n",
    "print(\"MULTI-DOCUMENT SYNTHESIS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "synthesizer = MultiDocumentSynthesizer(ranker)\n",
    "\n",
    "# Test queries requiring multiple documents\n",
    "synthesis_queries = [\n",
    "    \"Does the applicant's stated annual revenue in the application match their tax returns?\",\n",
    "    \"What is the debt service coverage ratio based on the business plan and loan request?\",\n",
    "    \"Is the property value from the appraisal consistent with the loan-to-value ratio in the application?\"\n",
    "]\n",
    "\n",
    "for query in synthesis_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    result = synthesizer.answer_query(query, max_context_tokens=2500)\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"\\nANSWER:\")\n",
    "        print(result['answer'])\n",
    "        \n",
    "        print(f\"\\nSOURCES USED ({result['chunks_used']} chunks, {result['context_tokens']} tokens):\")\n",
    "        sources_seen = set()\n",
    "        for source in result['sources']:\n",
    "            source_key = f\"{source['doc_type']}: {source['doc_title']}\"\n",
    "            if source_key not in sources_seen:\n",
    "                print(f\"  - {source_key}\")\n",
    "                sources_seen.add(source_key)\n",
    "        \n",
    "        print(f\"\\nTOKENS: {result['total_tokens']} total\")\n",
    "    else:\n",
    "        print(f\"\\nERROR: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0850d13",
   "metadata": {},
   "source": [
    "### Test Consistency Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test consistency verification\n",
    "print(\"CONSISTENCY VERIFICATION:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "entities_to_verify = [\n",
    "    \"annual revenue for 2023\",\n",
    "    \"total business debt\",\n",
    "    \"credit score\"\n",
    "]\n",
    "\n",
    "for entity in entities_to_verify:\n",
    "    result = synthesizer.verify_consistency(entity)\n",
    "    \n",
    "    print(f\"\\n{entity.upper()}:\")\n",
    "    if 'error' not in result:\n",
    "        print(f\"  Value: {result['value_found'][:100]}...\")\n",
    "        print(f\"  Found in {result['source_count']} source(s)\")\n",
    "        print(f\"  Consistent: {'Yes' if result['consistent'] else 'Needs verification'}\")\n",
    "    else:\n",
    "        print(f\"  Error: {result['error']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e032c",
   "metadata": {},
   "source": [
    "## CHALLENGE 5: PRODUCTION MULTI-DOCUMENT MANAGER\n",
    "\n",
    "**Time:** 10 minutes  \n",
    "**Objective:** Build complete production system\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Production Multi-Document Manager\n",
    "\n",
    "class ProductionDocumentManager:\n",
    "    \"\"\"\n",
    "    Production-ready multi-document management system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        documents: Dict,\n",
    "        chunk_size: int = 600,\n",
    "        max_context_tokens: int = 3000\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize document manager\n",
    "        \n",
    "        Args:\n",
    "            documents (Dict): Document collection\n",
    "            chunk_size (int): Target chunk size in tokens\n",
    "            max_context_tokens (int): Maximum context tokens\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.max_context_tokens = max_context_tokens\n",
    "        \n",
    "        # Initialize subsystems\n",
    "        self.chunker = DocumentChunker(chunk_size=chunk_size)\n",
    "        self.chunked_docs = self.chunker.chunk_all_documents(documents)\n",
    "        self.all_chunks = self.chunker.get_all_chunks()\n",
    "        \n",
    "        self.tracker = CrossDocumentTracker()\n",
    "        self.tracker.index_all_chunks(self.all_chunks)\n",
    "        \n",
    "        self.ranker = DocumentRelevanceRanker(self.all_chunks)\n",
    "        self.synthesizer = MultiDocumentSynthesizer(self.ranker)\n",
    "        \n",
    "        self.query_count = 0\n",
    "        self.cache = {}  # Simple query cache\n",
    "    \n",
    "    def query(\n",
    "        self,\n",
    "        question: str,\n",
    "        use_cache: bool = True,\n",
    "        include_sources: bool = True\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Answer question using document collection\n",
    "        \n",
    "        Args:\n",
    "            question (str): User question\n",
    "            use_cache (bool): Whether to use cached results\n",
    "            include_sources (bool): Whether to include source citations\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Answer with metadata\n",
    "        \"\"\"\n",
    "        self.query_count += 1\n",
    "        \n",
    "        # Check cache\n",
    "        if use_cache and question in self.cache:\n",
    "            cached = self.cache[question].copy()\n",
    "            cached['from_cache'] = True\n",
    "            return cached\n",
    "        \n",
    "        # Get answer\n",
    "        result = self.synthesizer.answer_query(\n",
    "            question,\n",
    "            max_context_tokens=self.max_context_tokens,\n",
    "            include_sources=include_sources\n",
    "        )\n",
    "        \n",
    "        # Add query metadata\n",
    "        result['query_number'] = self.query_count\n",
    "        result['from_cache'] = False\n",
    "        \n",
    "        # Cache result\n",
    "        if use_cache and result['success']:\n",
    "            self.cache[question] = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_document_summary(self, doc_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Get summary of a specific document\n",
    "        \n",
    "        Args:\n",
    "            doc_id (str): Document identifier\n",
    "        \n",
    "        Returns:\n",
    "            str: Document summary\n",
    "        \"\"\"\n",
    "        if doc_id not in self.documents:\n",
    "            return f\"Document {doc_id} not found\"\n",
    "        \n",
    "        doc = self.documents[doc_id]\n",
    "        chunks = self.chunked_docs.get(doc_id, [])\n",
    "        \n",
    "        return f\"\"\"\n",
    "Document: {doc['title']}\n",
    "Type: {doc['type']}\n",
    "Pages: {doc['pages']}\n",
    "Date: {doc['date']}\n",
    "Chunks: {len(chunks)}\n",
    "Total Tokens: {sum(c.token_count for c in chunks)}\n",
    "\"\"\"\n",
    "    \n",
    "    def list_documents(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        List all documents in collection\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Document listing\n",
    "        \"\"\"\n",
    "        doc_list = []\n",
    "        \n",
    "        for doc_id, doc in self.documents.items():\n",
    "            chunks = self.chunked_docs.get(doc_id, [])\n",
    "            doc_list.append({\n",
    "                'doc_id': doc_id,\n",
    "                'title': doc['title'],\n",
    "                'type': doc['type'],\n",
    "                'pages': doc['pages'],\n",
    "                'date': doc['date'],\n",
    "                'chunks': len(chunks),\n",
    "                'tokens': sum(c.token_count for c in chunks)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(doc_list)\n",
    "    \n",
    "    def find_related_docs(self, doc_id: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Find documents related to given document\n",
    "        \n",
    "        Args:\n",
    "            doc_id (str): Source document ID\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: Related document IDs\n",
    "        \"\"\"\n",
    "        related = self.tracker.find_related_documents(doc_id, min_shared=3)\n",
    "        return [doc_id for doc_id, _ in related]\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get comprehensive system statistics\"\"\"\n",
    "        return {\n",
    "            \"total_documents\": len(self.documents),\n",
    "            \"total_chunks\": len(self.all_chunks),\n",
    "            \"total_tokens\": sum(c.token_count for c in self.all_chunks),\n",
    "            \"queries_processed\": self.query_count,\n",
    "            \"cache_size\": len(self.cache),\n",
    "            \"avg_tokens_per_chunk\": np.mean([c.token_count for c in self.all_chunks]),\n",
    "            **self.tracker.get_stats()\n",
    "        }\n",
    "\n",
    "print(\"✓ ProductionDocumentManager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8aba26",
   "metadata": {},
   "source": [
    "### Test Production Document Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4698c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test production document manager\n",
    "print(\"PRODUCTION MULTI-DOCUMENT MANAGER:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize manager\n",
    "manager = ProductionDocumentManager(\n",
    "    loan_documents,\n",
    "    chunk_size=600,\n",
    "    max_context_tokens=2500\n",
    ")\n",
    "\n",
    "# List documents\n",
    "print(\"\\nDOCUMENT COLLECTION:\")\n",
    "print(\"-\" * 80)\n",
    "print(manager.list_documents().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c673b2",
   "metadata": {},
   "source": [
    "### Test Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1914ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "print(\"SAMPLE QUERIES:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_questions = [\n",
    "    \"What is the requested loan amount and purpose?\",\n",
    "    \"Is the company profitable? Show evidence from tax returns.\",\n",
    "    \"What are the monthly cash deposits based on bank statements?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Q: {question}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    result = manager.query(question)\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"\\nA: {result['answer'][:300]}...\")\n",
    "        print(f\"\\nMetadata:\")\n",
    "        print(f\"  Sources: {result['chunks_used']} chunks\")\n",
    "        print(f\"  Tokens: {result['total_tokens']}\")\n",
    "        print(f\"  Query #: {result['query_number']}\")\n",
    "    else:\n",
    "        print(f\"Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089564f",
   "metadata": {},
   "source": [
    "### System Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b20333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System statistics\n",
    "print(\"\\nSYSTEM STATISTICS:\")\n",
    "print(\"=\" * 80)\n",
    "stats = manager.get_stats()\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4eb97",
   "metadata": {},
   "source": [
    "## LAB SUMMARY\n",
    "\n",
    "### Token Efficiency Analysis\n",
    "\n",
    "```\n",
    "140-page document collection = ~70,000 tokens\n",
    "\n",
    "Single Query (\"What is the revenue?\"):\n",
    "├─ Naive (load all docs): 70,000 tokens\n",
    "├─ Basic (load one doc): ~10,000 tokens (85% savings)\n",
    "├─ Chunked (load relevant chunks): ~1,500 tokens (98% savings)\n",
    "└─ Optimized (rank + select): ~800 tokens (99% savings)\n",
    "\n",
    "Multi-Source Query (\"Does revenue match tax returns?\"):\n",
    "├─ Naive: 70,000 tokens\n",
    "├─ Load 2 full docs: ~20,000 tokens (71% savings)\n",
    "└─ Optimized (relevant chunks): ~1,800 tokens (97% savings)\n",
    "```\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "- [x] Implement document chunking with metadata\n",
    "- [x] Build cross-document entity tracker\n",
    "- [x] Create relevance ranking system\n",
    "- [x] Develop multi-source synthesis\n",
    "- [x] Add query caching\n",
    "- [x] Implement source citation\n",
    "- [x] Test consistency verification\n",
    "- [x] Monitor token usage per query\n",
    "- [x] Handle missing/conflicting information\n",
    "- [x] Document system architecture\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
