{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LAB 6: INSURANCE CLAIMS PROCESSING - CAPSTONE PROJECT\n",
        "\n",
        "**Course:** Advanced Prompt Engineering Training  \n",
        "**Session:** Session 6 - Advanced BFSI Applications (Day 3)  \n",
        "**Duration:** 120 minutes (2 hours)  \n",
        "\n",
        "---\n",
        "\n",
        "## LEARNING OBJECTIVES\n",
        "\n",
        "Build a **production-ready insurance claims processing system** integrating:\n",
        "\n",
        "✓ RAG for policy knowledge retrieval  \n",
        "✓ Orchestration for multi-step workflows  \n",
        "✓ Agents for autonomous decision-making  \n",
        "✓ RAGAs for quality evaluation  \n",
        "✓ Compliance with audit trails  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## SETUP & INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all required libraries\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LangChain\n",
        "from langchain_classic.agents import create_react_agent, AgentExecutor, Tool\n",
        "from langchain_classic.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_classic.schema import Document as LangChainDocument\n",
        "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Vector DB\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# RAGAs Evaluation\n",
        "try:\n",
        "    from ragas import evaluate\n",
        "    from ragas.metrics import (\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "        context_precision,\n",
        "        context_recall\n",
        "    )\n",
        "    from datasets import Dataset\n",
        "    RAGAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"⚠️ RAGAs not available - evaluation will be skipped\")\n",
        "    RAGAS_AVAILABLE = False\n",
        "\n",
        "# Utilities\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"✓ All libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize OpenAI client\n",
        "from openai import OpenAI\n",
        "\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY environment variable is not set. Please set it to your OpenAI API key.\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "model_name = os.environ.get(\"MODEL_NAME\", \"gpt-4o\")\n",
        "fastmodel_name = os.environ.get(\"FAST_MODEL_NAME\", \"gpt-3.5-turbo\")\n",
        "\n",
        "# LangChain models\n",
        "llm_gpt4 = ChatOpenAI(model=model_name, temperature=0)\n",
        "llm_gpt35 = ChatOpenAI(model=fastmodel_name, temperature=0)\n",
        "\n",
        "# Embedding model\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "print(\"✓ Models configured: GPT-4, GPT-3.5, text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PART 1: DATA PREPARATION (15 minutes)\n",
        "\n",
        "Creating synthetic insurance policies and claims data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Insurance Policy Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive insurance policy documents\n",
        "\n",
        "INSURANCE_POLICIES = {\n",
        "    \"auto_insurance_policy\": \"\"\"SECURELIFE AUTO INSURANCE POLICY\n",
        "Policy Number: AUTO-2024-STANDARD\n",
        "\n",
        "SECTION 1: COVERAGE OVERVIEW\n",
        "1.1 Collision Coverage\n",
        "- Maximum coverage: $50,000 per incident\n",
        "- Deductible: $1,000\n",
        "- Covers damage from collisions\n",
        "\n",
        "1.2 Comprehensive Coverage  \n",
        "- Maximum coverage: $50,000\n",
        "- Deductible: $500\n",
        "- Covers theft, vandalism, weather damage\n",
        "\n",
        "1.3 Liability Coverage\n",
        "- Bodily injury: $100,000 per person, $300,000 per accident\n",
        "- Property damage: $50,000\n",
        "\n",
        "1.4 Medical Payments\n",
        "- Coverage: $10,000 per person\n",
        "\n",
        "1.5 Towing and Rental\n",
        "- Towing: $200 per incident  \n",
        "- Rental: $50/day, max 30 days\n",
        "\n",
        "SECTION 2: EXCLUSIONS\n",
        "- Intentional damage\n",
        "- Driving under influence\n",
        "- Racing or competitive events\n",
        "- Commercial use without commercial policy\"\"\",\n",
        "\n",
        "    \"home_insurance_policy\": \"\"\"SECURELIFE HOMEOWNERS INSURANCE POLICY\n",
        "Policy Number: HOME-2024-PREMIUM\n",
        "\n",
        "SECTION 1: DWELLING COVERAGE\n",
        "1.1 Structure Coverage\n",
        "- Coverage limit: $500,000\n",
        "- Replacement cost coverage\n",
        "- Deductible: $2,500\n",
        "\n",
        "1.2 Personal Property\n",
        "- Coverage: $350,000 (70% of dwelling)\n",
        "- Replacement cost\n",
        "- Deductible: $1,000\n",
        "\n",
        "1.3 Liability Coverage\n",
        "- Coverage: $500,000 per occurrence\n",
        "- Legal defense included\n",
        "\n",
        "1.4 Additional Living Expenses\n",
        "- Coverage: $100,000 (20% of dwelling)\n",
        "- Hotel, meals, temporary housing\n",
        "\n",
        "SECTION 2: EXCLUSIONS\n",
        "- Flood (separate policy required)\n",
        "- Earthquake (separate policy)\n",
        "- Normal wear and tear\n",
        "- Intentional damage\"\"\",\n",
        "\n",
        "    \"health_insurance_policy\": \"\"\"SECURELIFE HEALTH INSURANCE POLICY\n",
        "Policy Number: HEALTH-2024-GOLD\n",
        "\n",
        "SECTION 1: IN-NETWORK BENEFITS\n",
        "1.1 Deductibles and Coinsurance\n",
        "- Annual deductible: $2,000 individual, $4,000 family\n",
        "- Coinsurance: 80/20 (plan pays 80%)\n",
        "- Out-of-pocket max: $6,000 individual\n",
        "\n",
        "1.2 Hospital Services\n",
        "- Emergency room: $500 copay, then 80% after deductible\n",
        "- Urgent care: $75 copay\n",
        "- Ambulance: 80% after deductible\n",
        "\n",
        "1.3 Physician Services\n",
        "- Primary care: $30 copay\n",
        "- Specialist: $60 copay\n",
        "- Preventive care: 100% covered\n",
        "\n",
        "1.4 Prescription Drugs\n",
        "- Generic: $10 copay\n",
        "- Preferred brand: $40 copay\n",
        "- Non-preferred: $70 copay\n",
        "\n",
        "SECTION 2: EXCLUSIONS\n",
        "- Cosmetic surgery (unless medically necessary)\n",
        "- Experimental treatments\n",
        "- Services outside USA (except emergencies)\"\"\"\n",
        "}\n",
        "\n",
        "# Create LangChain documents\n",
        "policy_documents = []\n",
        "for policy_name, content in INSURANCE_POLICIES.items():\n",
        "    doc = LangChainDocument(\n",
        "        page_content=content,\n",
        "        metadata={\n",
        "            \"source\": policy_name,\n",
        "            \"type\": \"insurance_policy\",\n",
        "            \"created_at\": datetime.now().isoformat()\n",
        "        }\n",
        "    )\n",
        "    policy_documents.append(doc)\n",
        "\n",
        "print(f\"✓ Created {len(policy_documents)} insurance policy documents\")\n",
        "for doc in policy_documents:\n",
        "    print(f\"  - {doc.metadata['source']}: {len(doc.page_content)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Sample Insurance Claims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample insurance claims for testing\n",
        "\n",
        "SAMPLE_CLAIMS = [\n",
        "    {\n",
        "        \"claim_id\": \"CLM-2024-001\",\n",
        "        \"policy_number\": \"AUTO-2024-STANDARD\",\n",
        "        \"claim_type\": \"auto\",\n",
        "        \"date_of_incident\": \"2024-02-08\",\n",
        "        \"date_reported\": \"2024-02-08\",\n",
        "        \"customer_name\": \"John Smith\",\n",
        "        \"description\": \"\"\"Single vehicle accident on I-95 during heavy rain.\n",
        "        Hit guardrail. Front bumper damaged, headlight broken.\n",
        "        Minor fender damage. No injuries. Police report filed.\"\"\",\n",
        "        \"estimated_damage\": 3500,\n",
        "        \"supporting_docs\": [\"police_report.pdf\", \"photos.zip\"],\n",
        "        \"expected_outcome\": \"APPROVE\",\n",
        "        \"expected_payout\": 2500\n",
        "    },\n",
        "    {\n",
        "        \"claim_id\": \"CLM-2024-002\",\n",
        "        \"policy_number\": \"HOME-2024-PREMIUM\",\n",
        "        \"claim_type\": \"home\",\n",
        "        \"date_of_incident\": \"2024-02-05\",\n",
        "        \"date_reported\": \"2024-02-06\",\n",
        "        \"customer_name\": \"Sarah Johnson\",\n",
        "        \"description\": \"\"\"Kitchen fire from stove. Fire department responded.\n",
        "        Kitchen cabinets destroyed, ceiling damaged, smoke damage throughout.\n",
        "        Temporary housing needed during repairs.\"\"\",\n",
        "        \"estimated_damage\": 45000,\n",
        "        \"supporting_docs\": [\"fire_report.pdf\", \"damage_assessment.pdf\"],\n",
        "        \"expected_outcome\": \"APPROVE\",\n",
        "        \"expected_payout\": 42500\n",
        "    },\n",
        "    {\n",
        "        \"claim_id\": \"CLM-2024-003\",\n",
        "        \"policy_number\": \"HEALTH-2024-GOLD\",\n",
        "        \"claim_type\": \"health\",\n",
        "        \"date_of_incident\": \"2024-02-10\",\n",
        "        \"date_reported\": \"2024-02-11\",\n",
        "        \"customer_name\": \"Michael Chen\",\n",
        "        \"description\": \"\"\"Emergency room visit for chest pain.\n",
        "        Tests: EKG, chest X-ray, blood work, cardiac enzymes.\n",
        "        Diagnosis: Anxiety attack (not cardiac). Released after 4 hours.\n",
        "        In-network hospital.\"\"\",\n",
        "        \"total_charges\": 5200,\n",
        "        \"supporting_docs\": [\"er_report.pdf\", \"itemized_bill.pdf\"],\n",
        "        \"expected_outcome\": \"APPROVE\"\n",
        "    }\n",
        "]\n",
        "\n",
        "claims_df = pd.DataFrame(SAMPLE_CLAIMS)\n",
        "print(f\"✓ Created {len(SAMPLE_CLAIMS)} sample insurance claims\")\n",
        "print(f\"\\nClaims breakdown:\")\n",
        "print(claims_df['claim_type'].value_counts())\n",
        "print(f\"\\nExpected outcomes:\")\n",
        "print(claims_df['expected_outcome'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PART 2: RAG KNOWLEDGE BASE (20 minutes)\n",
        "\n",
        "Building vector database for policy retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chunk policy documents\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=100,\n",
        "    separators=[\"\\n\\nSECTION\", \"\\n\\n\", \"\\n\", \" \"],\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "all_chunks = []\n",
        "for doc in policy_documents:\n",
        "    chunks = text_splitter.split_documents([doc])\n",
        "    all_chunks.extend(chunks)\n",
        "\n",
        "print(f\"✓ Created {len(all_chunks)} chunks from {len(policy_documents)} documents\")\n",
        "print(f\"  Average chunk size: {np.mean([len(c.page_content) for c in all_chunks]):.0f} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ChromaDB vector database\n",
        "\n",
        "chroma_client = chromadb.Client(Settings(\n",
        "    anonymized_telemetry=False,\n",
        "    allow_reset=True\n",
        "))\n",
        "\n",
        "# Reset if exists\n",
        "try:\n",
        "    chroma_client.delete_collection(\"insurance_policies\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Create collection\n",
        "insurance_collection = chroma_client.create_collection(\n",
        "    name=\"insurance_policies\",\n",
        "    metadata={\"description\": \"Insurance policy documents\"}\n",
        ")\n",
        "\n",
        "print(\"✓ ChromaDB collection created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate embeddings and index chunks\n",
        "\n",
        "print(\"Generating embeddings and indexing...\")\n",
        "\n",
        "for i, chunk in enumerate(all_chunks):\n",
        "    embedding = embeddings.embed_query(chunk.page_content)\n",
        "    \n",
        "    insurance_collection.add(\n",
        "        ids=[f\"chunk_{i}\"],\n",
        "        embeddings=[embedding],\n",
        "        documents=[chunk.page_content],\n",
        "        metadatas=[chunk.metadata]\n",
        "    )\n",
        "    \n",
        "    if (i + 1) % 5 == 0:\n",
        "        print(f\"  Indexed {i+1}/{len(all_chunks)} chunks...\")\n",
        "\n",
        "print(f\"\\n✓ Indexed {len(all_chunks)} policy chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create policy retrieval function\n",
        "\n",
        "def retrieve_policy_clauses(query: str, n_results: int = 3) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Retrieve relevant policy clauses\"\"\"\n",
        "    query_embedding = embeddings.embed_query(query)\n",
        "    \n",
        "    results = insurance_collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=n_results\n",
        "    )\n",
        "    \n",
        "    retrieved = []\n",
        "    for i, (doc, metadata, distance) in enumerate(zip(\n",
        "        results['documents'][0],\n",
        "        results['metadatas'][0],\n",
        "        results['distances'][0]\n",
        "    )):\n",
        "        retrieved.append({\n",
        "            'content': doc,\n",
        "            'metadata': metadata,\n",
        "            'similarity': 1 - distance,\n",
        "            'rank': i + 1\n",
        "        })\n",
        "    \n",
        "    return retrieved\n",
        "\n",
        "# Test retrieval\n",
        "print(\"Testing policy retrieval...\")\n",
        "test_results = retrieve_policy_clauses(\"auto collision coverage\", n_results=2)\n",
        "print(f\"✓ Retrieved {len(test_results)} results\")\n",
        "print(f\"  Top similarity: {test_results[0]['similarity']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PART 3: CLAIMS PROCESSING AGENT (25 minutes)\n",
        "\n",
        "Building agent with custom tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fraud Detection Tool\n",
        "\n",
        "def fraud_detection_tool_func(claim_data: str) -> str:\n",
        "    \"\"\"Analyze claim for fraud indicators\"\"\"\n",
        "    try:\n",
        "        data = json.loads(claim_data)\n",
        "        red_flags = []\n",
        "        fraud_score = 0\n",
        "        \n",
        "        # Check delayed reporting\n",
        "        incident_date = datetime.fromisoformat(data.get('date_of_incident', '2024-01-01'))\n",
        "        reported_date = datetime.fromisoformat(data.get('date_reported', '2024-01-01'))\n",
        "        days_delay = (reported_date - incident_date).days\n",
        "        \n",
        "        if days_delay > 7:\n",
        "            red_flags.append(f\"Delayed reporting: {days_delay} days\")\n",
        "            fraud_score += 15\n",
        "        \n",
        "        if not data.get('supporting_docs'):\n",
        "            red_flags.append(\"No supporting documentation\")\n",
        "            fraud_score += 20\n",
        "        \n",
        "        # Determine recommendation\n",
        "        if fraud_score >= 40:\n",
        "            recommendation = \"MANUAL_REVIEW\"\n",
        "            risk_level = \"HIGH\"\n",
        "        elif fraud_score >= 20:\n",
        "            recommendation = \"ENHANCED_VERIFICATION\"\n",
        "            risk_level = \"MEDIUM\"\n",
        "        else:\n",
        "            recommendation = \"PROCEED\"\n",
        "            risk_level = \"LOW\"\n",
        "        \n",
        "        return json.dumps({\n",
        "            \"fraud_score\": min(fraud_score, 100),\n",
        "            \"risk_level\": risk_level,\n",
        "            \"red_flags\": red_flags,\n",
        "            \"recommendation\": recommendation\n",
        "        }, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "fraud_detection_tool = Tool(\n",
        "    name=\"fraud_detection\",\n",
        "    func=fraud_detection_tool_func,\n",
        "    description=\"Analyzes claim for fraud. Input: JSON with dates and docs.\"\n",
        ")\n",
        "\n",
        "print(\"✓ Fraud detection tool created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Coverage Verification Tool (uses RAG)\n",
        "\n",
        "def coverage_verification_tool_func(verification_request: str) -> str:\n",
        "    \"\"\"Verify coverage using RAG\"\"\"\n",
        "    try:\n",
        "        data = json.loads(verification_request)\n",
        "        policy_type = data.get('policy_type', 'auto')\n",
        "        claim_description = data.get('claim_description', '')\n",
        "        \n",
        "        # Retrieve relevant clauses\n",
        "        query = f\"{policy_type} insurance coverage for {claim_description}\"\n",
        "        clauses = retrieve_policy_clauses(query, n_results=3)\n",
        "        \n",
        "        # Improved coverage determination\n",
        "        coverage_text = \" \".join([c['content'] for c in clauses]).lower()\n",
        "        claim_desc_lower = claim_description.lower()\n",
        "        \n",
        "        # Check for specific exclusions that apply to this claim\n",
        "        is_covered = True\n",
        "        exclusion_found = None\n",
        "        \n",
        "        # Specific exclusion checks\n",
        "        exclusion_keywords = {\n",
        "            'intentional damage': 'intentional',\n",
        "            'racing': 'racing',\n",
        "            'commercial use': 'commercial',\n",
        "            'flood': 'flood',\n",
        "            'earthquake': 'earthquake',\n",
        "            'cosmetic': 'cosmetic',\n",
        "            'experimental': 'experimental'\n",
        "        }\n",
        "        \n",
        "        for exclusion_type, keyword in exclusion_keywords.items():\n",
        "            if keyword in claim_desc_lower:\n",
        "                # Check if this is explicitly excluded\n",
        "                if f\"{keyword}\" in coverage_text and (\"exclusion\" in coverage_text or \"not covered\" in coverage_text):\n",
        "                    is_covered = False\n",
        "                    exclusion_found = f\"{exclusion_type.title()} is excluded by policy\"\n",
        "                    break\n",
        "        \n",
        "        # If no specific exclusion found, check for positive coverage indicators\n",
        "        if is_covered:\n",
        "            coverage_indicators = ['coverage', 'covers', 'covered', 'deductible', 'maximum coverage']\n",
        "            has_coverage_info = any(indicator in coverage_text for indicator in coverage_indicators)\n",
        "            \n",
        "            # If we found coverage information and no explicit exclusion, mark as covered\n",
        "            if has_coverage_info:\n",
        "                is_covered = True\n",
        "            else:\n",
        "                # Default to covered for standard scenarios\n",
        "                is_covered = True\n",
        "        \n",
        "        return json.dumps({\n",
        "            \"is_covered\": is_covered,\n",
        "            \"relevant_clauses\": [\n",
        "                {\"source\": c['metadata']['source'], \n",
        "                 \"content\": c['content'][:200] + \"...\",\n",
        "                 \"similarity\": c['similarity']}\n",
        "                for c in clauses\n",
        "            ],\n",
        "            \"exclusion_note\": exclusion_found\n",
        "        }, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "coverage_verification_tool = Tool(\n",
        "    name=\"coverage_verification\",\n",
        "    func=coverage_verification_tool_func,\n",
        "    description=\"Verifies coverage using policy docs. Input: JSON with policy_type and claim_description.\"\n",
        ")\n",
        "\n",
        "print(\"✓ Coverage verification tool created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Payout Calculator Tool\n",
        "\n",
        "def payout_calculator_tool_func(calculation_request: str) -> str:\n",
        "    \"\"\"Calculate insurance payout\"\"\"\n",
        "    try:\n",
        "        data = json.loads(calculation_request)\n",
        "        \n",
        "        total_damage = float(data.get('total_damage', 0))\n",
        "        deductible = float(data.get('deductible', 0))\n",
        "        coinsurance_pct = float(data.get('coinsurance', 100))\n",
        "        coverage_limit = float(data.get('coverage_limit', float('inf')))\n",
        "        \n",
        "        # Calculate\n",
        "        if total_damage <= deductible:\n",
        "            payout = 0\n",
        "            covered_amount = 0\n",
        "            note = \"Damage below deductible\"\n",
        "        else:\n",
        "            after_deductible = total_damage - deductible\n",
        "            covered_amount = after_deductible * (coinsurance_pct / 100)\n",
        "            payout = min(covered_amount, coverage_limit)\n",
        "            note = \"Calculated within policy limits\"\n",
        "        \n",
        "        return json.dumps({\n",
        "            \"total_damage\": total_damage,\n",
        "            \"deductible\": deductible,\n",
        "            \"covered_amount\": round(covered_amount, 2),\n",
        "            \"payout\": round(payout, 2),\n",
        "            \"calculation_note\": note\n",
        "        }, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "payout_calculator_tool = Tool(\n",
        "    name=\"payout_calculator\",\n",
        "    func=payout_calculator_tool_func,\n",
        "    description=\"Calculates payout. Input: JSON with total_damage, deductible, coinsurance.\"\n",
        ")\n",
        "\n",
        "print(\"✓ Payout calculator tool created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PART 4: ORCHESTRATION WORKFLOW (25 minutes)\n",
        "\n",
        "Building complete claims processing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete Orchestrated Claims Processing System\n",
        "\n",
        "@dataclass\n",
        "class ClaimProcessingResult:\n",
        "    \"\"\"Complete processing result\"\"\"\n",
        "    claim_id: str\n",
        "    status: str\n",
        "    payout_amount: float\n",
        "    processing_time: float\n",
        "    fraud_score: int\n",
        "    coverage_verified: bool\n",
        "    policy_clauses_cited: List[str]\n",
        "    reasoning: str\n",
        "    audit_trail: List[Dict[str, Any]]\n",
        "    timestamp: str\n",
        "\n",
        "\n",
        "class ClaimsProcessingOrchestrator:\n",
        "    \"\"\"Orchestrated claims processing\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.processing_stats = {\n",
        "            'total_processed': 0,\n",
        "            'approved': 0,\n",
        "            'denied': 0,\n",
        "            'manual_review': 0\n",
        "        }\n",
        "    \n",
        "    def process_claim(self, claim: Dict[str, Any]) -> ClaimProcessingResult:\n",
        "        \"\"\"Process claim through pipeline\"\"\"\n",
        "        start_time = time.time()\n",
        "        audit_trail = []\n",
        "        claim_id = claim['claim_id']\n",
        "        \n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"PROCESSING CLAIM: {claim_id}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        \n",
        "        # Step 1: Fraud Detection\n",
        "        print(\"[1/5] Fraud Detection...\")\n",
        "        fraud_data = json.dumps({\n",
        "            \"date_of_incident\": claim['date_of_incident'],\n",
        "            \"date_reported\": claim['date_reported'],\n",
        "            \"estimated_damage\": claim.get('estimated_damage', claim.get('total_charges', 0)),\n",
        "            \"supporting_docs\": claim.get('supporting_docs', [])\n",
        "        })\n",
        "        \n",
        "        fraud_result = fraud_detection_tool.func(fraud_data)\n",
        "        fraud_analysis = json.loads(fraud_result)\n",
        "        print(f\"  Fraud Score: {fraud_analysis['fraud_score']}/100\")\n",
        "        \n",
        "        audit_trail.append({\"step\": 1, \"action\": \"fraud_detection\"})\n",
        "        \n",
        "        if fraud_analysis['fraud_score'] >= 40:\n",
        "            return ClaimProcessingResult(\n",
        "                claim_id=claim_id,\n",
        "                status=\"MANUAL_REVIEW\",\n",
        "                payout_amount=0,\n",
        "                processing_time=time.time() - start_time,\n",
        "                fraud_score=fraud_analysis['fraud_score'],\n",
        "                coverage_verified=False,\n",
        "                policy_clauses_cited=[],\n",
        "                reasoning=\"High fraud risk - manual review\",\n",
        "                audit_trail=audit_trail,\n",
        "                timestamp=datetime.now().isoformat()\n",
        "            )\n",
        "        \n",
        "        # Step 2: Coverage Verification\n",
        "        print(\"\\n[2/5] Coverage Verification...\")\n",
        "        coverage_data = json.dumps({\n",
        "            \"policy_type\": claim['claim_type'],\n",
        "            \"claim_description\": claim['description']\n",
        "        })\n",
        "        \n",
        "        coverage_result = coverage_verification_tool.func(coverage_data)\n",
        "        coverage_analysis = json.loads(coverage_result)\n",
        "        \n",
        "        is_covered = coverage_analysis.get('is_covered', False)\n",
        "        print(f\"  Coverage: {'✓ COVERED' if is_covered else '✗ NOT COVERED'}\")\n",
        "        \n",
        "        audit_trail.append({\"step\": 2, \"action\": \"coverage_verification\"})\n",
        "        \n",
        "        policy_clauses = [\n",
        "            clause['source'] + \": \" + clause['content'][:100]\n",
        "            for clause in coverage_analysis.get('relevant_clauses', [])\n",
        "        ]\n",
        "        \n",
        "        if not is_covered:\n",
        "            return ClaimProcessingResult(\n",
        "                claim_id=claim_id,\n",
        "                status=\"DENIED\",\n",
        "                payout_amount=0,\n",
        "                processing_time=time.time() - start_time,\n",
        "                fraud_score=fraud_analysis['fraud_score'],\n",
        "                coverage_verified=False,\n",
        "                policy_clauses_cited=policy_clauses,\n",
        "                reasoning=\"Claim denied - not covered\",\n",
        "                audit_trail=audit_trail,\n",
        "                timestamp=datetime.now().isoformat()\n",
        "            )\n",
        "        \n",
        "        # Step 3: Payout Calculation\n",
        "        print(\"\\n[3/5] Payout Calculation...\")\n",
        "        \n",
        "        # Determine deductible\n",
        "        if claim['claim_type'] == 'auto':\n",
        "            deductible = 1000\n",
        "            coinsurance = 100\n",
        "        elif claim['claim_type'] == 'home':\n",
        "            deductible = 2500\n",
        "            coinsurance = 100\n",
        "        else:  # health\n",
        "            deductible = 2000\n",
        "            coinsurance = 80\n",
        "        \n",
        "        payout_data = json.dumps({\n",
        "            \"total_damage\": claim.get('estimated_damage', claim.get('total_charges', 0)),\n",
        "            \"deductible\": deductible,\n",
        "            \"coinsurance\": coinsurance,\n",
        "            \"coverage_limit\": 50000\n",
        "        })\n",
        "        \n",
        "        payout_result = payout_calculator_tool.func(payout_data)\n",
        "        payout_analysis = json.loads(payout_result)\n",
        "        payout_amount = payout_analysis['payout']\n",
        "        \n",
        "        print(f\"  Payout: ${payout_amount:,.2f}\")\n",
        "        \n",
        "        audit_trail.append({\"step\": 3, \"action\": \"payout_calculation\"})\n",
        "        \n",
        "        # Final decision\n",
        "        status = \"APPROVED\"\n",
        "        reasoning = f\"\"\"Claim APPROVED - Payout: ${payout_amount:,.2f}\n",
        "\n",
        "Fraud: PASSED ({fraud_analysis['fraud_score']}/100)\n",
        "Coverage: CONFIRMED\n",
        "Payout: ${payout_analysis['total_damage']:,.2f} - ${payout_analysis['deductible']:,.2f} = ${payout_amount:,.2f}\"\"\"\n",
        "        \n",
        "        self.processing_stats['total_processed'] += 1\n",
        "        self.processing_stats['approved'] += 1\n",
        "        \n",
        "        processing_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"✓ {status} - ${payout_amount:,.2f}\")\n",
        "        print(f\"  Time: {processing_time:.2f}s\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        \n",
        "        return ClaimProcessingResult(\n",
        "            claim_id=claim_id,\n",
        "            status=status,\n",
        "            payout_amount=payout_amount,\n",
        "            processing_time=processing_time,\n",
        "            fraud_score=fraud_analysis['fraud_score'],\n",
        "            coverage_verified=True,\n",
        "            policy_clauses_cited=policy_clauses,\n",
        "            reasoning=reasoning.strip(),\n",
        "            audit_trail=audit_trail,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )\n",
        "\n",
        "orchestrator = ClaimsProcessingOrchestrator()\n",
        "print(\"✓ Orchestrator initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all sample claims\n",
        "\n",
        "results = []\n",
        "\n",
        "for claim in SAMPLE_CLAIMS:\n",
        "    result = orchestrator.process_claim(claim)\n",
        "    results.append(result)\n",
        "    time.sleep(1)\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "for key, value in orchestrator.processing_stats.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PART 5: RAGAS EVALUATION (20 minutes)\n",
        "\n",
        "Evaluating system quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAGAs Evaluation\n",
        "\n",
        "if RAGAS_AVAILABLE and len(results) > 0:\n",
        "    print(\"Preparing RAGAs evaluation...\")\n",
        "    \n",
        "    eval_data = {\n",
        "        \"question\": [],\n",
        "        \"answer\": [],\n",
        "        \"contexts\": [],\n",
        "        \"ground_truth\": []\n",
        "    }\n",
        "    \n",
        "    for result in results[:3]:\n",
        "        eval_data[\"question\"].append(f\"Process claim {result.claim_id}\")\n",
        "        eval_data[\"answer\"].append(result.reasoning)\n",
        "        eval_data[\"contexts\"].append(result.policy_clauses_cited)\n",
        "        eval_data[\"ground_truth\"].append(f\"Claim should be {result.status}\")\n",
        "    \n",
        "    ragas_dataset = Dataset.from_dict(eval_data)\n",
        "    print(f\"✓ Dataset with {len(ragas_dataset)} examples\")\n",
        "    \n",
        "    print(\"\\nRunning RAGAs evaluation...\")\n",
        "    \n",
        "    try:\n",
        "        ragas_results = evaluate(\n",
        "            ragas_dataset,\n",
        "            metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
        "            llm=llm_gpt4,\n",
        "            embeddings=embeddings\n",
        "        )\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RAGAS RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        results_df = ragas_results.to_pandas()\n",
        "        for metric in ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall']:\n",
        "            if metric in results_df.columns:\n",
        "                score = results_df[metric].mean()\n",
        "                print(f\"  {metric.title()}: {score:.3f}\")\n",
        "        print(\"=\"*80)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ RAGAs error: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ RAGAs not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PART 6: COMPLIANCE & PRODUCTION (15 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compliance Reporting\n",
        "\n",
        "class ComplianceReporter:\n",
        "    @staticmethod\n",
        "    def generate_audit_report(result: ClaimProcessingResult) -> str:\n",
        "        report = f\"\"\"{'='*80}\n",
        "INSURANCE CLAIM AUDIT REPORT\n",
        "{'='*80}\n",
        "\n",
        "CLAIM: {result.claim_id}\n",
        "STATUS: {result.status}\n",
        "PAYOUT: ${result.payout_amount:,.2f}\n",
        "TIME: {result.processing_time:.2f}s\n",
        "\n",
        "FRAUD: {result.fraud_score}/100\n",
        "COVERAGE: {result.coverage_verified}\n",
        "\n",
        "POLICY CLAUSES:\n",
        "\"\"\"\n",
        "        for clause in result.policy_clauses_cited:\n",
        "            report += f\"  - {clause}\\n\"\n",
        "        \n",
        "        report += f\"\\nREASONING:\\n{result.reasoning}\\n\"\n",
        "        report += f\"{'='*80}\"\n",
        "        return report\n",
        "\n",
        "if results:\n",
        "    audit_report = ComplianceReporter.generate_audit_report(results[0])\n",
        "    print(audit_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Production Monitoring\n",
        "\n",
        "class ProductionMonitor:\n",
        "    def __init__(self, results: List[ClaimProcessingResult]):\n",
        "        self.results = results\n",
        "    \n",
        "    def get_dashboard(self) -> str:\n",
        "        if not self.results:\n",
        "            return \"No claims processed\"\n",
        "        \n",
        "        total = len(self.results)\n",
        "        approved = sum(1 for r in self.results if r.status == 'APPROVED')\n",
        "        total_payout = sum(r.payout_amount for r in self.results)\n",
        "        avg_time = np.mean([r.processing_time for r in self.results])\n",
        "        \n",
        "        return f\"\"\"{'='*80}\n",
        "PRODUCTION DASHBOARD\n",
        "{'='*80}\n",
        "\n",
        "CLAIMS: {total}\n",
        "APPROVED: {approved} ({approved/total*100:.1f}%)\n",
        "\n",
        "TOTAL PAYOUT: ${total_payout:,.2f}\n",
        "AVG PAYOUT: ${total_payout/max(approved, 1):,.2f}\n",
        "\n",
        "AVG TIME: {avg_time:.2f}s\n",
        "\n",
        "STATUS: {'✓ HEALTHY' if avg_time < 60 else '⚠️ DEGRADED'}\n",
        "{'='*80}\"\"\"\n",
        "\n",
        "monitor = ProductionMonitor(results)\n",
        "print(monitor.get_dashboard())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
